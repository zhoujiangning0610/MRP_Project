{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.utils import class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>System Setting</th>\n",
       "      <th>System Mode</th>\n",
       "      <th>Calendar Event</th>\n",
       "      <th>Program Mode</th>\n",
       "      <th>Cool Set Temp (C)</th>\n",
       "      <th>Heat Set Temp (C)</th>\n",
       "      <th>Current Temp (C)</th>\n",
       "      <th>...</th>\n",
       "      <th>Thermostat Humidity (%RH)</th>\n",
       "      <th>Thermostat Motion</th>\n",
       "      <th>Bedroom (C)</th>\n",
       "      <th>Bedroom2</th>\n",
       "      <th>3rd floor landing (C)</th>\n",
       "      <th>3rd floor landing2</th>\n",
       "      <th>3rd floor room (C)</th>\n",
       "      <th>3rd floor room2</th>\n",
       "      <th>Basement (C)</th>\n",
       "      <th>Basement2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-12-10</td>\n",
       "      <td>12:50:00</td>\n",
       "      <td>2020/12/10 12:50:00</td>\n",
       "      <td>heat</td>\n",
       "      <td>heatOff</td>\n",
       "      <td>auto</td>\n",
       "      <td>Home</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.3</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-12-10</td>\n",
       "      <td>12:55:00</td>\n",
       "      <td>2020/12/10 12:55:00</td>\n",
       "      <td>heat</td>\n",
       "      <td>heatOff</td>\n",
       "      <td>auto</td>\n",
       "      <td>Home</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.1</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-12-10</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>2020/12/10 13:00:00</td>\n",
       "      <td>heat</td>\n",
       "      <td>heatOff</td>\n",
       "      <td>auto</td>\n",
       "      <td>Home</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-12-10</td>\n",
       "      <td>13:05:00</td>\n",
       "      <td>2020/12/10 13:05:00</td>\n",
       "      <td>heat</td>\n",
       "      <td>heatOff</td>\n",
       "      <td>auto</td>\n",
       "      <td>Home</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.7</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-12-10</td>\n",
       "      <td>13:10:00</td>\n",
       "      <td>2020/12/10 13:10:00</td>\n",
       "      <td>heat</td>\n",
       "      <td>heatStage1On</td>\n",
       "      <td>auto</td>\n",
       "      <td>Home</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.6</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29671</th>\n",
       "      <td>2021-03-23</td>\n",
       "      <td>14:25:00</td>\n",
       "      <td>2021/3/23 14:25:00</td>\n",
       "      <td>heat</td>\n",
       "      <td>heatOff</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Home</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29672</th>\n",
       "      <td>2021-03-23</td>\n",
       "      <td>14:30:00</td>\n",
       "      <td>2021/3/23 14:30:00</td>\n",
       "      <td>heat</td>\n",
       "      <td>heatOff</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Home</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.1</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29673</th>\n",
       "      <td>2021-03-23</td>\n",
       "      <td>14:35:00</td>\n",
       "      <td>2021/3/23 14:35:00</td>\n",
       "      <td>heat</td>\n",
       "      <td>heatOff</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Home</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.1</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29674</th>\n",
       "      <td>2021-03-23</td>\n",
       "      <td>14:40:00</td>\n",
       "      <td>2021/3/23 14:40:00</td>\n",
       "      <td>heat</td>\n",
       "      <td>heatOff</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Home</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.1</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29675</th>\n",
       "      <td>2021-03-23</td>\n",
       "      <td>14:45:00</td>\n",
       "      <td>2021/3/23 14:45:00</td>\n",
       "      <td>heat</td>\n",
       "      <td>heatOff</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Home</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.1</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29676 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date      Time             DateTime System Setting   System Mode  \\\n",
       "0     2020-12-10  12:50:00  2020/12/10 12:50:00           heat       heatOff   \n",
       "1     2020-12-10  12:55:00  2020/12/10 12:55:00           heat       heatOff   \n",
       "2     2020-12-10  13:00:00  2020/12/10 13:00:00           heat       heatOff   \n",
       "3     2020-12-10  13:05:00  2020/12/10 13:05:00           heat       heatOff   \n",
       "4     2020-12-10  13:10:00  2020/12/10 13:10:00           heat  heatStage1On   \n",
       "...          ...       ...                  ...            ...           ...   \n",
       "29671 2021-03-23  14:25:00   2021/3/23 14:25:00           heat       heatOff   \n",
       "29672 2021-03-23  14:30:00   2021/3/23 14:30:00           heat       heatOff   \n",
       "29673 2021-03-23  14:35:00   2021/3/23 14:35:00           heat       heatOff   \n",
       "29674 2021-03-23  14:40:00   2021/3/23 14:40:00           heat       heatOff   \n",
       "29675 2021-03-23  14:45:00   2021/3/23 14:45:00           heat       heatOff   \n",
       "\n",
       "      Calendar Event Program Mode  Cool Set Temp (C)  Heat Set Temp (C)  \\\n",
       "0               auto         Home               21.0               21.0   \n",
       "1               auto         Home               21.0               21.0   \n",
       "2               auto         Home               21.0               21.0   \n",
       "3               auto         Home               21.0               21.0   \n",
       "4               auto         Home               21.0               21.0   \n",
       "...              ...          ...                ...                ...   \n",
       "29671            NaN         Home               21.0               21.0   \n",
       "29672            NaN         Home               21.0               21.0   \n",
       "29673            NaN         Home               21.0               21.0   \n",
       "29674            NaN         Home               21.0               21.0   \n",
       "29675            NaN         Home               21.0               21.0   \n",
       "\n",
       "       Current Temp (C)  ...  Thermostat Humidity (%RH)  Thermostat Motion  \\\n",
       "0                  21.3  ...                       30.0                1.0   \n",
       "1                  21.1  ...                       32.0                1.0   \n",
       "2                  20.9  ...                       32.0                0.0   \n",
       "3                  20.7  ...                       33.0                0.0   \n",
       "4                  20.6  ...                       33.0                1.0   \n",
       "...                 ...  ...                        ...                ...   \n",
       "29671              21.2  ...                       21.0                0.0   \n",
       "29672              21.1  ...                       21.0                0.0   \n",
       "29673              21.1  ...                       21.0                0.0   \n",
       "29674              21.1  ...                       21.0                0.0   \n",
       "29675              21.1  ...                       21.0                1.0   \n",
       "\n",
       "       Bedroom (C)  Bedroom2  3rd floor landing (C)  3rd floor landing2  \\\n",
       "0             21.6       0.0                   20.9                 0.0   \n",
       "1             21.6       0.0                   20.9                 0.0   \n",
       "2             21.6       0.0                   20.8                 0.0   \n",
       "3             21.6       0.0                   20.8                 0.0   \n",
       "4             21.6       0.0                   20.8                 0.0   \n",
       "...            ...       ...                    ...                 ...   \n",
       "29671         21.9       0.0                   21.8                 0.0   \n",
       "29672         21.9       0.0                   21.8                 0.0   \n",
       "29673         21.9       0.0                   21.8                 1.0   \n",
       "29674         21.9       0.0                   21.8                 1.0   \n",
       "29675         21.9       0.0                   21.8                 0.0   \n",
       "\n",
       "       3rd floor room (C)  3rd floor room2  Basement (C)  Basement2  \n",
       "0                    21.0              0.0          22.8        0.0  \n",
       "1                    20.9              0.0          22.7        1.0  \n",
       "2                    20.8              0.0          22.7        1.0  \n",
       "3                    20.8              0.0          22.8        0.0  \n",
       "4                    20.8              0.0          22.8        0.0  \n",
       "...                   ...              ...           ...        ...  \n",
       "29671                21.3              0.0          22.0        1.0  \n",
       "29672                21.3              0.0          22.1        0.0  \n",
       "29673                21.3              0.0          22.1        0.0  \n",
       "29674                21.3              0.0          22.1        0.0  \n",
       "29675                21.3              0.0          22.1        1.0  \n",
       "\n",
       "[29676 rows x 27 columns]"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_data = pd.read_excel(\"Clean_Data.xlsx\")\n",
    "house_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = preprocessing.OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                              0\n",
       "Time                              0\n",
       "DateTime                          0\n",
       "System Setting                    0\n",
       "System Mode                       0\n",
       "Calendar Event                29548\n",
       "Program Mode                      0\n",
       "Cool Set Temp (C)                 0\n",
       "Heat Set Temp (C)                 0\n",
       "Current Temp (C)                  0\n",
       "Current Humidity (%RH)            0\n",
       "Outdoor Temp (C)                  0\n",
       "Wind Speed (km/h)                 0\n",
       "Cool Stage 1 (sec)                0\n",
       "Heat Stage 1 (sec)                0\n",
       "Fan (sec)                         0\n",
       "Thermostat Temperature (C)        0\n",
       "Thermostat Humidity (%RH)         0\n",
       "Thermostat Motion                 0\n",
       "Bedroom (C)                       0\n",
       "Bedroom2                          0\n",
       "3rd floor landing (C)             0\n",
       "3rd floor landing2                0\n",
       "3rd floor room (C)                0\n",
       "3rd floor room2                   0\n",
       "Basement (C)                      0\n",
       "Basement2                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_data = house_data.fillna(method = \"bfill\")\n",
    "house_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_vars = ['Heat Set Temp (C)', 'Current Temp (C)', 'Current Humidity (%RH)', 'Outdoor Temp (C)','Thermostat Temperature (C)', 'Thermostat Humidity (%RH)']\n",
    "sc = StandardScaler()\n",
    "sc.fit(house_data[numerical_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Heat Set Temp (C)</th>\n",
       "      <th>Current Temp (C)</th>\n",
       "      <th>Current Humidity (%RH)</th>\n",
       "      <th>Outdoor Temp (C)</th>\n",
       "      <th>Thermostat Temperature (C)</th>\n",
       "      <th>Thermostat Humidity (%RH)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.632689</td>\n",
       "      <td>1.422976</td>\n",
       "      <td>1.387394</td>\n",
       "      <td>2.632689</td>\n",
       "      <td>1.422976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>1.387394</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>1.930176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.346315</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>1.424799</td>\n",
       "      <td>0.346315</td>\n",
       "      <td>1.930176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.424799</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.368465</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.424799</td>\n",
       "      <td>-1.368465</td>\n",
       "      <td>2.183776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29671</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.295068</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.859425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29672</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.388582</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29673</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.388582</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29674</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.388582</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29675</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.388582</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29676 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Heat Set Temp (C)  Current Temp (C)  Current Humidity (%RH)  \\\n",
       "0                    0.0          2.632689                1.422976   \n",
       "1                    0.0          1.489502                1.930176   \n",
       "2                    0.0          0.346315                1.930176   \n",
       "3                    0.0         -0.796872                2.183776   \n",
       "4                    0.0         -1.368465                2.183776   \n",
       "...                  ...               ...                     ...   \n",
       "29671                0.0          2.061095               -0.859425   \n",
       "29672                0.0          1.489502               -0.859425   \n",
       "29673                0.0          1.489502               -0.859425   \n",
       "29674                0.0          1.489502               -0.859425   \n",
       "29675                0.0          1.489502               -0.859425   \n",
       "\n",
       "       Outdoor Temp (C)  Thermostat Temperature (C)  Thermostat Humidity (%RH)  \n",
       "0              1.387394                    2.632689                   1.422976  \n",
       "1              1.387394                    1.489502                   1.930176  \n",
       "2              1.424799                    0.346315                   1.930176  \n",
       "3              1.424799                   -0.796872                   2.183776  \n",
       "4              1.424799                   -1.368465                   2.183776  \n",
       "...                 ...                         ...                        ...  \n",
       "29671          3.295068                    2.061095                  -0.859425  \n",
       "29672          3.388582                    1.489502                  -0.859425  \n",
       "29673          3.388582                    1.489502                  -0.859425  \n",
       "29674          3.388582                    1.489502                  -0.859425  \n",
       "29675          3.388582                    1.489502                  -0.859425  \n",
       "\n",
       "[29676 rows x 6 columns]"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_house_data = house_data[numerical_vars].copy()\n",
    "scaler_house_data[numerical_vars] = sc.transform(house_data[numerical_vars])\n",
    "scaler_house_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_auxHeat = house_data['Heat Stage 1 (sec)'].to_numpy()\n",
    "y_fan = house_data['Fan (sec)'].to_numpy()\n",
    "oe = OrdinalEncoder()\n",
    "y_auxHeat = oe.fit_transform(y_auxHeat.reshape(-1, 1))\n",
    "y_fan = oe.fit_transform(y_fan.reshape(-1, 1))\n",
    "y_auxHeat = y_auxHeat.reshape(y_auxHeat.shape[0], )\n",
    "y_fan = y_fan.reshape(y_fan.shape[0], )\n",
    "y_auxHeat = y_auxHeat.astype(int)\n",
    "y_auxHeat = y_auxHeat.astype(str)\n",
    "\n",
    "y_fan = y_fan.astype(int)\n",
    "y_fan = y_fan.astype(str)\n",
    "scaler_house_data['Heat Stage 1'] = y_auxHeat\n",
    "scaler_house_data['fan'] = y_fan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Heat Set Temp (C)</th>\n",
       "      <th>Current Temp (C)</th>\n",
       "      <th>Current Humidity (%RH)</th>\n",
       "      <th>Outdoor Temp (C)</th>\n",
       "      <th>Thermostat Temperature (C)</th>\n",
       "      <th>Thermostat Humidity (%RH)</th>\n",
       "      <th>Heat Stage 1</th>\n",
       "      <th>fan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.632689</td>\n",
       "      <td>1.422976</td>\n",
       "      <td>1.387394</td>\n",
       "      <td>2.632689</td>\n",
       "      <td>1.422976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>1.387394</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.346315</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>1.424799</td>\n",
       "      <td>0.346315</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.424799</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.368465</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.424799</td>\n",
       "      <td>-1.368465</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29671</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.295068</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29672</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.388582</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29673</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.388582</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29674</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.388582</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29675</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.388582</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29676 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Heat Set Temp (C)  Current Temp (C)  Current Humidity (%RH)  \\\n",
       "0                    0.0          2.632689                1.422976   \n",
       "1                    0.0          1.489502                1.930176   \n",
       "2                    0.0          0.346315                1.930176   \n",
       "3                    0.0         -0.796872                2.183776   \n",
       "4                    0.0         -1.368465                2.183776   \n",
       "...                  ...               ...                     ...   \n",
       "29671                0.0          2.061095               -0.859425   \n",
       "29672                0.0          1.489502               -0.859425   \n",
       "29673                0.0          1.489502               -0.859425   \n",
       "29674                0.0          1.489502               -0.859425   \n",
       "29675                0.0          1.489502               -0.859425   \n",
       "\n",
       "       Outdoor Temp (C)  Thermostat Temperature (C)  \\\n",
       "0              1.387394                    2.632689   \n",
       "1              1.387394                    1.489502   \n",
       "2              1.424799                    0.346315   \n",
       "3              1.424799                   -0.796872   \n",
       "4              1.424799                   -1.368465   \n",
       "...                 ...                         ...   \n",
       "29671          3.295068                    2.061095   \n",
       "29672          3.388582                    1.489502   \n",
       "29673          3.388582                    1.489502   \n",
       "29674          3.388582                    1.489502   \n",
       "29675          3.388582                    1.489502   \n",
       "\n",
       "       Thermostat Humidity (%RH) Heat Stage 1 fan  \n",
       "0                       1.422976            0   0  \n",
       "1                       1.930176            0   0  \n",
       "2                       1.930176            0   0  \n",
       "3                       2.183776            9   9  \n",
       "4                       2.183776           20  20  \n",
       "...                          ...          ...  ..  \n",
       "29671                  -0.859425            0   0  \n",
       "29672                  -0.859425            0   0  \n",
       "29673                  -0.859425            0   0  \n",
       "29674                  -0.859425            0   0  \n",
       "29675                  -0.859425            0   0  \n",
       "\n",
       "[29676 rows x 8 columns]"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_house_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Heat Set Temp (C)</th>\n",
       "      <th>Current Temp (C)</th>\n",
       "      <th>Current Humidity (%RH)</th>\n",
       "      <th>Outdoor Temp (C)</th>\n",
       "      <th>Thermostat Temperature (C)</th>\n",
       "      <th>Thermostat Humidity (%RH)</th>\n",
       "      <th>Heat Stage 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.632689</td>\n",
       "      <td>1.422976</td>\n",
       "      <td>1.387394</td>\n",
       "      <td>2.632689</td>\n",
       "      <td>1.422976</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>1.387394</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.346315</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>1.424799</td>\n",
       "      <td>0.346315</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.424799</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.368465</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.424799</td>\n",
       "      <td>-1.368465</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29671</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.295068</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29672</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.388582</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29673</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.388582</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29674</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.388582</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29675</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.388582</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29676 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Heat Set Temp (C)  Current Temp (C)  Current Humidity (%RH)  \\\n",
       "0                    0.0          2.632689                1.422976   \n",
       "1                    0.0          1.489502                1.930176   \n",
       "2                    0.0          0.346315                1.930176   \n",
       "3                    0.0         -0.796872                2.183776   \n",
       "4                    0.0         -1.368465                2.183776   \n",
       "...                  ...               ...                     ...   \n",
       "29671                0.0          2.061095               -0.859425   \n",
       "29672                0.0          1.489502               -0.859425   \n",
       "29673                0.0          1.489502               -0.859425   \n",
       "29674                0.0          1.489502               -0.859425   \n",
       "29675                0.0          1.489502               -0.859425   \n",
       "\n",
       "       Outdoor Temp (C)  Thermostat Temperature (C)  \\\n",
       "0              1.387394                    2.632689   \n",
       "1              1.387394                    1.489502   \n",
       "2              1.424799                    0.346315   \n",
       "3              1.424799                   -0.796872   \n",
       "4              1.424799                   -1.368465   \n",
       "...                 ...                         ...   \n",
       "29671          3.295068                    2.061095   \n",
       "29672          3.388582                    1.489502   \n",
       "29673          3.388582                    1.489502   \n",
       "29674          3.388582                    1.489502   \n",
       "29675          3.388582                    1.489502   \n",
       "\n",
       "       Thermostat Humidity (%RH) Heat Stage 1  \n",
       "0                       1.422976            0  \n",
       "1                       1.930176            0  \n",
       "2                       1.930176            0  \n",
       "3                       2.183776            9  \n",
       "4                       2.183776           20  \n",
       "...                          ...          ...  \n",
       "29671                  -0.859425            0  \n",
       "29672                  -0.859425            0  \n",
       "29673                  -0.859425            0  \n",
       "29674                  -0.859425            0  \n",
       "29675                  -0.859425            0  \n",
       "\n",
       "[29676 rows x 7 columns]"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_df = scaler_house_data.drop(labels = [\"fan\"], axis = 1)\n",
    "working_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in = 1, n_out = 1, dropnan = True):\n",
    "    \n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    \n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    \n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-6)</th>\n",
       "      <th>var2(t-6)</th>\n",
       "      <th>var3(t-6)</th>\n",
       "      <th>var4(t-6)</th>\n",
       "      <th>var5(t-6)</th>\n",
       "      <th>var6(t-6)</th>\n",
       "      <th>var7(t-6)</th>\n",
       "      <th>var1(t-5)</th>\n",
       "      <th>var2(t-5)</th>\n",
       "      <th>var3(t-5)</th>\n",
       "      <th>...</th>\n",
       "      <th>var5(t-1)</th>\n",
       "      <th>var6(t-1)</th>\n",
       "      <th>var7(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "      <th>var2(t)</th>\n",
       "      <th>var3(t)</th>\n",
       "      <th>var4(t)</th>\n",
       "      <th>var5(t)</th>\n",
       "      <th>var6(t)</th>\n",
       "      <th>var7(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.632689</td>\n",
       "      <td>1.422976</td>\n",
       "      <td>1.387394</td>\n",
       "      <td>2.632689</td>\n",
       "      <td>1.422976</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.225278</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.424799</td>\n",
       "      <td>-0.225278</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>1.387394</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.346315</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225278</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.917909</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.424799</td>\n",
       "      <td>0.917909</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.346315</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>1.424799</td>\n",
       "      <td>0.346315</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>...</td>\n",
       "      <td>0.917909</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.462204</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.424799</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.368465</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>...</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.462204</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.368465</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.424799</td>\n",
       "      <td>-1.368465</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>...</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.917909</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.462204</td>\n",
       "      <td>0.917909</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29671</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>3.238960</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>...</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.295068</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29672</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>3.295068</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.632689</td>\n",
       "      <td>-0.605825</td>\n",
       "      <td>...</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.388582</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29673</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.632689</td>\n",
       "      <td>-0.605825</td>\n",
       "      <td>3.295068</td>\n",
       "      <td>2.632689</td>\n",
       "      <td>-0.605825</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.632689</td>\n",
       "      <td>-0.605825</td>\n",
       "      <td>...</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.388582</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29674</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.632689</td>\n",
       "      <td>-0.605825</td>\n",
       "      <td>3.295068</td>\n",
       "      <td>2.632689</td>\n",
       "      <td>-0.605825</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.605825</td>\n",
       "      <td>...</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.388582</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29675</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.605825</td>\n",
       "      <td>3.295068</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.605825</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>...</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.388582</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29670 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       var1(t-6)  var2(t-6)  var3(t-6)  var4(t-6)  var5(t-6)  var6(t-6)  \\\n",
       "6            0.0   2.632689   1.422976   1.387394   2.632689   1.422976   \n",
       "7            0.0   1.489502   1.930176   1.387394   1.489502   1.930176   \n",
       "8            0.0   0.346315   1.930176   1.424799   0.346315   1.930176   \n",
       "9            0.0  -0.796872   2.183776   1.424799  -0.796872   2.183776   \n",
       "10           0.0  -1.368465   2.183776   1.424799  -1.368465   2.183776   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "29671        0.0   3.204282  -0.098625   3.238960   3.204282  -0.098625   \n",
       "29672        0.0   3.204282  -0.098625   3.295068   3.204282  -0.098625   \n",
       "29673        0.0   2.632689  -0.605825   3.295068   2.632689  -0.605825   \n",
       "29674        0.0   2.632689  -0.605825   3.295068   2.632689  -0.605825   \n",
       "29675        0.0   2.061095  -0.605825   3.295068   2.061095  -0.605825   \n",
       "\n",
       "      var7(t-6)  var1(t-5)  var2(t-5)  var3(t-5)  ...  var5(t-1)  var6(t-1)  \\\n",
       "6             0        0.0   1.489502   1.930176  ...  -0.796872   2.183776   \n",
       "7             0        0.0   0.346315   1.930176  ...  -0.225278   2.183776   \n",
       "8             0        0.0  -0.796872   2.183776  ...   0.917909   2.183776   \n",
       "9             9        0.0  -1.368465   2.183776  ...   1.489502   2.183776   \n",
       "10           20        0.0  -0.796872   2.183776  ...   1.489502   2.183776   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "29671         0        0.0   3.204282  -0.098625  ...   2.061095  -0.859425   \n",
       "29672         0        0.0   2.632689  -0.605825  ...   2.061095  -0.859425   \n",
       "29673         0        0.0   2.632689  -0.605825  ...   1.489502  -0.859425   \n",
       "29674         0        0.0   2.061095  -0.605825  ...   1.489502  -0.859425   \n",
       "29675         0        0.0   2.061095  -0.859425  ...   1.489502  -0.859425   \n",
       "\n",
       "       var7(t-1) var1(t)   var2(t)   var3(t)   var4(t)   var5(t)   var6(t)  \\\n",
       "6             20     0.0 -0.225278  2.183776  1.424799 -0.225278  2.183776   \n",
       "7             20     0.0  0.917909  2.183776  1.424799  0.917909  2.183776   \n",
       "8              3     0.0  1.489502  2.183776  1.462204  1.489502  2.183776   \n",
       "9              0     0.0  1.489502  2.183776  1.462204  1.489502  2.183776   \n",
       "10             0     0.0  0.917909  2.183776  1.462204  0.917909  2.183776   \n",
       "...          ...     ...       ...       ...       ...       ...       ...   \n",
       "29671          0     0.0  2.061095 -0.859425  3.295068  2.061095 -0.859425   \n",
       "29672          0     0.0  1.489502 -0.859425  3.388582  1.489502 -0.859425   \n",
       "29673          0     0.0  1.489502 -0.859425  3.388582  1.489502 -0.859425   \n",
       "29674          0     0.0  1.489502 -0.859425  3.388582  1.489502 -0.859425   \n",
       "29675          0     0.0  1.489502 -0.859425  3.388582  1.489502 -0.859425   \n",
       "\n",
       "       var7(t)  \n",
       "6           20  \n",
       "7            3  \n",
       "8            0  \n",
       "9            0  \n",
       "10           0  \n",
       "...        ...  \n",
       "29671        0  \n",
       "29672        0  \n",
       "29673        0  \n",
       "29674        0  \n",
       "29675        0  \n",
       "\n",
       "[29670 rows x 49 columns]"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reframed = series_to_supervised(working_df, 6, 1)\n",
    "reframed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_auxHeat = reframed['var7(t)']\n",
    "y_auxHeat = to_categorical(y_auxHeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_auxHeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.argmax(y_auxHeat, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0, 15207],\n",
       "       [    1,   382],\n",
       "       [    2,   391],\n",
       "       [    3,   409],\n",
       "       [    4,   398],\n",
       "       [    5,   389],\n",
       "       [    6,   374],\n",
       "       [    7,   387],\n",
       "       [    8,   377],\n",
       "       [    9,   404],\n",
       "       [   10,   385],\n",
       "       [   11,   392],\n",
       "       [   12,   360],\n",
       "       [   13,   360],\n",
       "       [   14,   394],\n",
       "       [   15,   388],\n",
       "       [   16,   410],\n",
       "       [   17,   420],\n",
       "       [   18,   425],\n",
       "       [   19,   369],\n",
       "       [   20,  7049]], dtype=int64)"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(unique, counts) = np.unique(test, return_counts = True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(frequencies)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = class_weight.compute_class_weight('balanced', classes = np.unique(test), y = test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = reframed.drop(labels = ['var7(t)'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_auxHeat, test_size = 0.2, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smote =RandomUnderSampler(sampling_strategy = 'all')\n",
    "# X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "# X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.argmax(y_train, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "(unique, counts) = np.unique(test, return_counts = True)\n",
    "frequencies = np.asarray((unique, counts)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23736, 48), (5934, 48))"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values\n",
    "X_test = X_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(float)\n",
    "X_test = X_test.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "371/371 [==============================] - 2s 4ms/step - loss: 1.3728 - accuracy: 0.7021 - val_loss: 1.0380 - val_accuracy: 0.7383\n",
      "Epoch 2/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.9675 - accuracy: 0.7462 - val_loss: 0.9510 - val_accuracy: 0.7422\n",
      "Epoch 3/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.9053 - accuracy: 0.7498 - val_loss: 0.9041 - val_accuracy: 0.7459\n",
      "Epoch 4/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.8710 - accuracy: 0.7529 - val_loss: 0.8849 - val_accuracy: 0.7481\n",
      "Epoch 5/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.8498 - accuracy: 0.7543 - val_loss: 0.8689 - val_accuracy: 0.7492\n",
      "Epoch 6/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.8387 - accuracy: 0.7549 - val_loss: 0.8574 - val_accuracy: 0.7509\n",
      "Epoch 7/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.8290 - accuracy: 0.7558 - val_loss: 0.8481 - val_accuracy: 0.7496\n",
      "Epoch 8/50\n",
      "371/371 [==============================] - 1s 1ms/step - loss: 0.8207 - accuracy: 0.7556 - val_loss: 0.8416 - val_accuracy: 0.7504\n",
      "Epoch 9/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.8159 - accuracy: 0.7567 - val_loss: 0.8418 - val_accuracy: 0.7497\n",
      "Epoch 10/50\n",
      "371/371 [==============================] - 1s 1ms/step - loss: 0.8122 - accuracy: 0.7571 - val_loss: 0.8327 - val_accuracy: 0.7508\n",
      "Epoch 11/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.8081 - accuracy: 0.7579 - val_loss: 0.8566 - val_accuracy: 0.7482\n",
      "Epoch 12/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.8044 - accuracy: 0.7572 - val_loss: 0.8360 - val_accuracy: 0.7499\n",
      "Epoch 13/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.8034 - accuracy: 0.7581 - val_loss: 0.8327 - val_accuracy: 0.7528\n",
      "Epoch 14/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7985 - accuracy: 0.7571 - val_loss: 0.8394 - val_accuracy: 0.7508\n",
      "Epoch 15/50\n",
      "371/371 [==============================] - 1s 3ms/step - loss: 0.7954 - accuracy: 0.7577 - val_loss: 0.8264 - val_accuracy: 0.7528\n",
      "Epoch 16/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7943 - accuracy: 0.7582 - val_loss: 0.8242 - val_accuracy: 0.7545\n",
      "Epoch 17/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7931 - accuracy: 0.7580 - val_loss: 0.8173 - val_accuracy: 0.7526\n",
      "Epoch 18/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7926 - accuracy: 0.7576 - val_loss: 0.8218 - val_accuracy: 0.7548\n",
      "Epoch 19/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7875 - accuracy: 0.7586 - val_loss: 0.8163 - val_accuracy: 0.7511\n",
      "Epoch 20/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7871 - accuracy: 0.7586 - val_loss: 0.8165 - val_accuracy: 0.7516\n",
      "Epoch 21/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7867 - accuracy: 0.7587 - val_loss: 0.8144 - val_accuracy: 0.7543\n",
      "Epoch 22/50\n",
      "371/371 [==============================] - 1s 3ms/step - loss: 0.7857 - accuracy: 0.7590 - val_loss: 0.8137 - val_accuracy: 0.7553\n",
      "Epoch 23/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7823 - accuracy: 0.7601 - val_loss: 0.8132 - val_accuracy: 0.7546\n",
      "Epoch 24/50\n",
      "371/371 [==============================] - 1s 3ms/step - loss: 0.7801 - accuracy: 0.7594 - val_loss: 0.8147 - val_accuracy: 0.7529\n",
      "Epoch 25/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7794 - accuracy: 0.7599 - val_loss: 0.8129 - val_accuracy: 0.7558\n",
      "Epoch 26/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7788 - accuracy: 0.7607 - val_loss: 0.8116 - val_accuracy: 0.7529\n",
      "Epoch 27/50\n",
      "371/371 [==============================] - 1s 3ms/step - loss: 0.7786 - accuracy: 0.7589 - val_loss: 0.8071 - val_accuracy: 0.7546\n",
      "Epoch 28/50\n",
      "371/371 [==============================] - 1s 4ms/step - loss: 0.7768 - accuracy: 0.7594 - val_loss: 0.8049 - val_accuracy: 0.7526\n",
      "Epoch 29/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7760 - accuracy: 0.7598 - val_loss: 0.8180 - val_accuracy: 0.7541\n",
      "Epoch 30/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7749 - accuracy: 0.7596 - val_loss: 0.8299 - val_accuracy: 0.7518\n",
      "Epoch 31/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7739 - accuracy: 0.7603 - val_loss: 0.8045 - val_accuracy: 0.7558\n",
      "Epoch 32/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7718 - accuracy: 0.7614 - val_loss: 0.8052 - val_accuracy: 0.7535\n",
      "Epoch 33/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7711 - accuracy: 0.7606 - val_loss: 0.8073 - val_accuracy: 0.7565\n",
      "Epoch 34/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7700 - accuracy: 0.7602 - val_loss: 0.8108 - val_accuracy: 0.7556\n",
      "Epoch 35/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7702 - accuracy: 0.7608 - val_loss: 0.8056 - val_accuracy: 0.7528\n",
      "Epoch 36/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7709 - accuracy: 0.7617 - val_loss: 0.8059 - val_accuracy: 0.7524\n",
      "Epoch 37/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7706 - accuracy: 0.7616 - val_loss: 0.8016 - val_accuracy: 0.7540\n",
      "Epoch 38/50\n",
      "371/371 [==============================] - 1s 3ms/step - loss: 0.7687 - accuracy: 0.7615 - val_loss: 0.8035 - val_accuracy: 0.7553\n",
      "Epoch 39/50\n",
      "371/371 [==============================] - 1s 3ms/step - loss: 0.7681 - accuracy: 0.7607 - val_loss: 0.8040 - val_accuracy: 0.7545\n",
      "Epoch 40/50\n",
      "371/371 [==============================] - 1s 3ms/step - loss: 0.7683 - accuracy: 0.7607 - val_loss: 0.8048 - val_accuracy: 0.7565\n",
      "Epoch 41/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7671 - accuracy: 0.7626 - val_loss: 0.8052 - val_accuracy: 0.7551\n",
      "Epoch 42/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7652 - accuracy: 0.7608 - val_loss: 0.8149 - val_accuracy: 0.7524\n",
      "Epoch 43/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7649 - accuracy: 0.7636 - val_loss: 0.8035 - val_accuracy: 0.7562\n",
      "Epoch 44/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7655 - accuracy: 0.7628 - val_loss: 0.8128 - val_accuracy: 0.7529\n",
      "Epoch 45/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7630 - accuracy: 0.7632 - val_loss: 0.8037 - val_accuracy: 0.7553\n",
      "Epoch 46/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7640 - accuracy: 0.7627 - val_loss: 0.8032 - val_accuracy: 0.7562\n",
      "Epoch 47/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7608 - accuracy: 0.7626 - val_loss: 0.8027 - val_accuracy: 0.7573\n",
      "Epoch 48/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7613 - accuracy: 0.7616 - val_loss: 0.8016 - val_accuracy: 0.7568\n",
      "Epoch 49/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7610 - accuracy: 0.7629 - val_loss: 0.7999 - val_accuracy: 0.7538\n",
      "Epoch 50/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7598 - accuracy: 0.7629 - val_loss: 0.8134 - val_accuracy: 0.7550\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units = 24, kernel_initializer = 'uniform', activation = 'relu', input_dim = 48))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 24, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 21, kernel_initializer = 'uniform', activation = 'softmax'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy']) \n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "history = classifier.fit(X_train, y_train, validation_data = (X_test, y_test), batch_size = 64, epochs = 50, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_225\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_675 (Dense)            (None, 24)                1176      \n",
      "_________________________________________________________________\n",
      "dense_676 (Dense)            (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_677 (Dense)            (None, 21)                525       \n",
      "=================================================================\n",
      "Total params: 2,301\n",
      "Trainable params: 2,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label = 'train')\n",
    "plt.plot(history.history['val_loss'], label = 'test')\n",
    "plt.legend()\n",
    "plt.savefig(\"8.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], label = 'train')\n",
    "plt.plot(history.history['val_accuracy'], label = 'test')\n",
    "plt.legend()\n",
    "plt.savefig(\"9.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 15,  9, ...,  7,  0,  0], dtype=int64)"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted = np.argmax(y_predicted, axis = 1)\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.argmax(y_test, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sum = 0\n",
    "for i in range(len(y_test)):\n",
    "    test_sum += (y_test[i] * 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "658965"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_sum = 0\n",
    "for i in range(len(y_predicted)):\n",
    "    predicted_sum += (y_predicted[i] * 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "664050"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Percentage in predicted values is : 0.7716646559377205 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Error Percentage in predicted values is : {} %\".format(np.absolute((predicted_sum - test_sum)/test_sum)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error,f1_score,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predicted = classifier.predict(X_train)\n",
    "y_train_predicted = np.argmax(y_train_predicted, axis = 1)\n",
    "y_train = np.argmax(y_train, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7293476980033778"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_train, y_train_predicted, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.762891809908999"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, y_train_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0218233906302663"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_train, y_train_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0389282103134478"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7549713515335356"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7217813710487606"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_predicted, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-12)</th>\n",
       "      <th>var2(t-12)</th>\n",
       "      <th>var3(t-12)</th>\n",
       "      <th>var4(t-12)</th>\n",
       "      <th>var5(t-12)</th>\n",
       "      <th>var6(t-12)</th>\n",
       "      <th>var7(t-12)</th>\n",
       "      <th>var1(t-11)</th>\n",
       "      <th>var2(t-11)</th>\n",
       "      <th>var3(t-11)</th>\n",
       "      <th>...</th>\n",
       "      <th>var5(t-1)</th>\n",
       "      <th>var6(t-1)</th>\n",
       "      <th>var7(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "      <th>var2(t)</th>\n",
       "      <th>var3(t)</th>\n",
       "      <th>var4(t)</th>\n",
       "      <th>var5(t)</th>\n",
       "      <th>var6(t)</th>\n",
       "      <th>var7(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.632689</td>\n",
       "      <td>1.422976</td>\n",
       "      <td>1.387394</td>\n",
       "      <td>2.632689</td>\n",
       "      <td>1.422976</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346315</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.225278</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.462204</td>\n",
       "      <td>-0.225278</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>1.387394</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.346315</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225278</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.225278</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.462204</td>\n",
       "      <td>-0.225278</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.346315</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>1.424799</td>\n",
       "      <td>0.346315</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225278</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.443502</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.424799</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.368465</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.443502</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.368465</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.424799</td>\n",
       "      <td>-1.368465</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.346315</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.443502</td>\n",
       "      <td>0.346315</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29671</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>3.145447</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>...</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.295068</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29672</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>3.238960</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>...</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.388582</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29673</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>3.238960</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>...</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.388582</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29674</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>3.238960</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>...</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.388582</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29675</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>3.238960</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>...</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.388582</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29664 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       var1(t-12)  var2(t-12)  var3(t-12)  var4(t-12)  var5(t-12)  var6(t-12)  \\\n",
       "12            0.0    2.632689    1.422976    1.387394    2.632689    1.422976   \n",
       "13            0.0    1.489502    1.930176    1.387394    1.489502    1.930176   \n",
       "14            0.0    0.346315    1.930176    1.424799    0.346315    1.930176   \n",
       "15            0.0   -0.796872    2.183776    1.424799   -0.796872    2.183776   \n",
       "16            0.0   -1.368465    2.183776    1.424799   -1.368465    2.183776   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "29671         0.0    3.204282   -0.098625    3.145447    3.204282   -0.098625   \n",
       "29672         0.0    3.204282   -0.098625    3.238960    3.204282   -0.098625   \n",
       "29673         0.0    3.204282   -0.098625    3.238960    3.204282   -0.098625   \n",
       "29674         0.0    3.204282   -0.098625    3.238960    3.204282   -0.098625   \n",
       "29675         0.0    3.204282   -0.098625    3.238960    3.204282   -0.098625   \n",
       "\n",
       "      var7(t-12)  var1(t-11)  var2(t-11)  var3(t-11)  ...  var5(t-1)  \\\n",
       "12             0         0.0    1.489502    1.930176  ...   0.346315   \n",
       "13             0         0.0    0.346315    1.930176  ...  -0.225278   \n",
       "14             0         0.0   -0.796872    2.183776  ...  -0.225278   \n",
       "15             9         0.0   -1.368465    2.183776  ...  -0.796872   \n",
       "16            20         0.0   -0.796872    2.183776  ...  -0.796872   \n",
       "...          ...         ...         ...         ...  ...        ...   \n",
       "29671          0         0.0    3.204282   -0.098625  ...   2.061095   \n",
       "29672          0         0.0    3.204282   -0.098625  ...   2.061095   \n",
       "29673          0         0.0    3.204282   -0.098625  ...   1.489502   \n",
       "29674          0         0.0    3.204282   -0.098625  ...   1.489502   \n",
       "29675          0         0.0    3.204282   -0.098625  ...   1.489502   \n",
       "\n",
       "       var6(t-1)  var7(t-1) var1(t)   var2(t)   var3(t)   var4(t)   var5(t)  \\\n",
       "12      2.183776          0     0.0 -0.225278  2.183776  1.462204 -0.225278   \n",
       "13      2.183776          0     0.0 -0.225278  2.183776  1.462204 -0.225278   \n",
       "14      2.183776          0     0.0 -0.796872  2.183776  1.443502 -0.796872   \n",
       "15      2.183776         17     0.0 -0.796872  2.183776  1.443502 -0.796872   \n",
       "16      2.183776         20     0.0  0.346315  2.183776  1.443502  0.346315   \n",
       "...          ...        ...     ...       ...       ...       ...       ...   \n",
       "29671  -0.859425          0     0.0  2.061095 -0.859425  3.295068  2.061095   \n",
       "29672  -0.859425          0     0.0  1.489502 -0.859425  3.388582  1.489502   \n",
       "29673  -0.859425          0     0.0  1.489502 -0.859425  3.388582  1.489502   \n",
       "29674  -0.859425          0     0.0  1.489502 -0.859425  3.388582  1.489502   \n",
       "29675  -0.859425          0     0.0  1.489502 -0.859425  3.388582  1.489502   \n",
       "\n",
       "        var6(t)  var7(t)  \n",
       "12     2.183776        0  \n",
       "13     2.183776        0  \n",
       "14     2.183776       17  \n",
       "15     2.183776       20  \n",
       "16     2.183776        6  \n",
       "...         ...      ...  \n",
       "29671 -0.859425        0  \n",
       "29672 -0.859425        0  \n",
       "29673 -0.859425        0  \n",
       "29674 -0.859425        0  \n",
       "29675 -0.859425        0  \n",
       "\n",
       "[29664 rows x 91 columns]"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reframed_2 = series_to_supervised(working_df, 12, 1)\n",
    "reframed_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29670, 48)"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_auxHeat = reframed_2['var7(t)']\n",
    "y_auxHeat = to_categorical(y_auxHeat)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = reframed_2.drop(labels = ['var7(t)'], axis = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_auxHeat, test_size = 0.2, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23731, 90)"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.astype(float)\n",
    "X_test = X_test.astype(float)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "371/371 [==============================] - 2s 3ms/step - loss: 1.4048 - accuracy: 0.6597 - val_loss: 1.0490 - val_accuracy: 0.7335\n",
      "Epoch 2/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.9728 - accuracy: 0.7451 - val_loss: 0.9426 - val_accuracy: 0.7413\n",
      "Epoch 3/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.9036 - accuracy: 0.7503 - val_loss: 0.9071 - val_accuracy: 0.7452\n",
      "Epoch 4/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.8688 - accuracy: 0.7533 - val_loss: 0.8663 - val_accuracy: 0.7482\n",
      "Epoch 5/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.8451 - accuracy: 0.7550 - val_loss: 0.8520 - val_accuracy: 0.7490\n",
      "Epoch 6/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.8343 - accuracy: 0.7572 - val_loss: 0.8507 - val_accuracy: 0.7511\n",
      "Epoch 7/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.8283 - accuracy: 0.7570 - val_loss: 0.8389 - val_accuracy: 0.7480\n",
      "Epoch 8/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.8163 - accuracy: 0.7575 - val_loss: 0.8313 - val_accuracy: 0.7505\n",
      "Epoch 9/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.8125 - accuracy: 0.7579 - val_loss: 0.8298 - val_accuracy: 0.7534\n",
      "Epoch 10/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.8075 - accuracy: 0.7578 - val_loss: 0.8215 - val_accuracy: 0.7546\n",
      "Epoch 11/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.8021 - accuracy: 0.7590 - val_loss: 0.8202 - val_accuracy: 0.7526\n",
      "Epoch 12/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7992 - accuracy: 0.7586 - val_loss: 0.8172 - val_accuracy: 0.7519\n",
      "Epoch 13/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7969 - accuracy: 0.7580 - val_loss: 0.8248 - val_accuracy: 0.7529\n",
      "Epoch 14/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7943 - accuracy: 0.7584 - val_loss: 0.8212 - val_accuracy: 0.7521\n",
      "Epoch 15/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7919 - accuracy: 0.7596 - val_loss: 0.8227 - val_accuracy: 0.7531\n",
      "Epoch 16/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7883 - accuracy: 0.7607 - val_loss: 0.8197 - val_accuracy: 0.7553\n",
      "Epoch 17/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7836 - accuracy: 0.7603 - val_loss: 0.8060 - val_accuracy: 0.7549\n",
      "Epoch 18/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7833 - accuracy: 0.7604 - val_loss: 0.8047 - val_accuracy: 0.7551\n",
      "Epoch 19/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7788 - accuracy: 0.7616 - val_loss: 0.8100 - val_accuracy: 0.7538\n",
      "Epoch 20/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7784 - accuracy: 0.7619 - val_loss: 0.8072 - val_accuracy: 0.7543\n",
      "Epoch 21/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7763 - accuracy: 0.7625 - val_loss: 0.8200 - val_accuracy: 0.7521\n",
      "Epoch 22/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7777 - accuracy: 0.7611 - val_loss: 0.7963 - val_accuracy: 0.7543\n",
      "Epoch 23/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7720 - accuracy: 0.7609 - val_loss: 0.7983 - val_accuracy: 0.7559\n",
      "Epoch 24/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7699 - accuracy: 0.7620 - val_loss: 0.8178 - val_accuracy: 0.7512\n",
      "Epoch 25/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7706 - accuracy: 0.7627 - val_loss: 0.7964 - val_accuracy: 0.7554\n",
      "Epoch 26/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7680 - accuracy: 0.7623 - val_loss: 0.7980 - val_accuracy: 0.7539\n",
      "Epoch 27/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7661 - accuracy: 0.7625 - val_loss: 0.7948 - val_accuracy: 0.7546\n",
      "Epoch 28/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7653 - accuracy: 0.7645 - val_loss: 0.7977 - val_accuracy: 0.7559\n",
      "Epoch 29/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7658 - accuracy: 0.7642 - val_loss: 0.7929 - val_accuracy: 0.7548\n",
      "Epoch 30/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7647 - accuracy: 0.7629 - val_loss: 0.8051 - val_accuracy: 0.7538\n",
      "Epoch 31/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7617 - accuracy: 0.7644 - val_loss: 0.8229 - val_accuracy: 0.7539\n",
      "Epoch 32/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7611 - accuracy: 0.7647 - val_loss: 0.8007 - val_accuracy: 0.7548\n",
      "Epoch 33/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7613 - accuracy: 0.7620 - val_loss: 0.7943 - val_accuracy: 0.7551\n",
      "Epoch 34/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7575 - accuracy: 0.7642 - val_loss: 0.8080 - val_accuracy: 0.7551\n",
      "Epoch 35/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7571 - accuracy: 0.7651 - val_loss: 0.7909 - val_accuracy: 0.7566\n",
      "Epoch 36/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7567 - accuracy: 0.7655 - val_loss: 0.7935 - val_accuracy: 0.7544\n",
      "Epoch 37/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7554 - accuracy: 0.7653 - val_loss: 0.7898 - val_accuracy: 0.7558\n",
      "Epoch 38/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7540 - accuracy: 0.7652 - val_loss: 0.8079 - val_accuracy: 0.7538\n",
      "Epoch 39/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7545 - accuracy: 0.7647 - val_loss: 0.8002 - val_accuracy: 0.7539\n",
      "Epoch 40/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7547 - accuracy: 0.7652 - val_loss: 0.8057 - val_accuracy: 0.7549\n",
      "Epoch 41/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7521 - accuracy: 0.7647 - val_loss: 0.8100 - val_accuracy: 0.7563\n",
      "Epoch 42/50\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.7552 - accuracy: 0.76 - 1s 2ms/step - loss: 0.7535 - accuracy: 0.7641 - val_loss: 0.7929 - val_accuracy: 0.7548\n",
      "Epoch 43/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7516 - accuracy: 0.7653 - val_loss: 0.7953 - val_accuracy: 0.7563\n",
      "Epoch 44/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7517 - accuracy: 0.7650 - val_loss: 0.7947 - val_accuracy: 0.7570\n",
      "Epoch 45/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7508 - accuracy: 0.7660 - val_loss: 0.7943 - val_accuracy: 0.7543\n",
      "Epoch 46/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7521 - accuracy: 0.7654 - val_loss: 0.8139 - val_accuracy: 0.7556\n",
      "Epoch 47/50\n",
      "371/371 [==============================] - 1s 3ms/step - loss: 0.7521 - accuracy: 0.7648 - val_loss: 0.7985 - val_accuracy: 0.7590\n",
      "Epoch 48/50\n",
      "371/371 [==============================] - 1s 3ms/step - loss: 0.7464 - accuracy: 0.7665 - val_loss: 0.8073 - val_accuracy: 0.7511\n",
      "Epoch 49/50\n",
      "371/371 [==============================] - 1s 2ms/step - loss: 0.7472 - accuracy: 0.7648 - val_loss: 0.8020 - val_accuracy: 0.7521\n",
      "Epoch 50/50\n",
      "371/371 [==============================] - 1s 3ms/step - loss: 0.7486 - accuracy: 0.7647 - val_loss: 0.7953 - val_accuracy: 0.7539\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units = 24, kernel_initializer = 'uniform', activation = 'relu', input_dim = 90))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 24, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 21, kernel_initializer = 'uniform', activation = 'softmax'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy']) \n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "history = classifier.fit(X_train, y_train, validation_data = (X_test, y_test), batch_size = 64, epochs = 50, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_226\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_678 (Dense)            (None, 24)                2184      \n",
      "_________________________________________________________________\n",
      "dense_679 (Dense)            (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_680 (Dense)            (None, 21)                525       \n",
      "=================================================================\n",
      "Total params: 3,309\n",
      "Trainable params: 3,309\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deZxcVZ338c+v1u7qPd2dtRMSQ0gIEAKETRABQRJQEFEERGdcJjqjDD4zOIozI6Az8zAzjuM4o/KgT0RF8GFEBAVGDAYDIoYEAgaSkJCFdLbe0ul9qarz/HGqO52ll6Sru1JV3/fr1a9bXffWrXMb8r3nnnPuueacQ0REsl8g0wUQEZH0UKCLiOQIBbqISI5QoIuI5AgFuohIjghl6ourqqrczJkzM/X1IiJZac2aNQ3OueojrctYoM+cOZPVq1dn6utFRLKSmW0fbJ2aXEREcoQCXUQkRyjQRURyRMba0EVEjkVvby+1tbV0dXVluihjqqCggJqaGsLh8Ig/o0AXkaxSW1tLSUkJM2fOxMwyXZwx4ZyjsbGR2tpaZs2aNeLPqclFRLJKV1cXlZWVORvmAGZGZWXlUV+FKNBFJOvkcpj3OZZjHDbQzWyZmdWZ2bphtjvbzBJm9oGjLsVR2Linla/9aiONbd1j+TUiIllnJDX0+4DFQ21gZkHgn4FfpaFMQ9pS38Z/rdhMXasCXUTGX3NzM9/+9reP+nNXXnklzc3NY1CiA4YNdOfcSqBpmM1uAR4G6tJRqKEURX0/bnt3fKy/SkTkMIMFeiKRGPJzTzzxBOXl5WNVLCANo1zMbBpwLXApcPYw2y4FlgLMmDHjmL6vKBoEoL1n6D+eiMhY+OIXv8ibb77JwoULCYfDFBcXM2XKFNauXcvrr7/O+973Pnbs2EFXVxe33norS5cuBQ5Md9LW1saSJUu48MILef7555k2bRqPPvoohYWFoy5bOoYtfgP4gnMuMVwjvnPuXuBegEWLFh3Ts+9iEV/kDtXQRfLeXb94jdd3taR1n/OnlnLHe08ZdP3dd9/NunXrWLt2Lc888wxXXXUV69at6x9euGzZMiZMmEBnZydnn3021113HZWVlQftY9OmTTz44IN897vf5frrr+fhhx/m5ptvHnXZ0xHoi4CfpMK8CrjSzOLOuZ+nYd+HKUoFumroInI8OOeccw4aK/7Nb36TRx55BIAdO3awadOmwwJ91qxZLFy4EICzzjqLbdu2paUsow5051z/kZjZfcAvxyrMYUCTi2roInlvqJr0eCkqKup//cwzz7B8+XJ+//vfE4vFuPjii484ljwajfa/DgaDdHZ2pqUswwa6mT0IXAxUmVktcAcQBnDO3ZOWUhyF/k7RHgW6iIy/kpISWltbj7hu//79VFRUEIvF2LBhAy+88MK4lm3YQHfO3TjSnTnn/nRUpRmBaChAwKCjW00uIjL+KisrueCCCzj11FMpLCxk0qRJ/esWL17MPffcw4IFC5g7dy7nnXfeuJYt6+ZyMTOKIiHV0EUkYx544IEjvh+NRnnyySePuK6vnbyqqop16w7cp3nbbbelrVxZeet/UTSkNnQRkUNkZaDHokGNchEROURWBnpRJKRx6CIih8jKQI9FgrSrU1RE5CBZGejFUXWKiogcKisDPRYN0aE2dBGRg2RloBdFghrlIiIZcazT5wJ84xvfoKOjI80lOiArAz0W0bBFEcmM4znQs+7GIoDiaJCO3gTJpCMQyP1HUYnI8WPg9LmXX345EydO5KGHHqK7u5trr72Wu+66i/b2dq6//npqa2tJJBL8/d//PXv37mXXrl1ccsklVFVVsWLFirSXLSsDPRYN4Rx0xRP90+mKSB568ouw54/p3efk02DJ3YOuHjh97lNPPcVPf/pTVq1ahXOOq6++mpUrV1JfX8/UqVN5/PHHAT/HS1lZGV//+tdZsWIFVVVV6S1zSlY2uRRF+mZcVMeoiGTOU089xVNPPcUZZ5zBmWeeyYYNG9i0aROnnXYay5cv5wtf+ALPPvssZWVl41KerKze9tXK27vjVJdEh9laRHLWEDXp8eCc4/bbb+dTn/rUYevWrFnDE088we2338673/1uvvzlL495ebKzhq4pdEUkQwZOn3vFFVewbNky2traANi5cyd1dXXs2rWLWCzGzTffzG233cZLL7102GfHQlbW0PsecqGx6CIy3gZOn7tkyRJuuukmzj//fACKi4u5//772bx5M5///OcJBAKEw2G+853vALB06VKWLFnClClT1CnaZ2CTi4jIeDt0+txbb731oN9nz57NFVdccdjnbrnlFm655ZYxK1eWNrmoU1RE5FDZGegRtaGLiBwqOwM91SmqKXRF8pNzLtNFGHPHcoxZGeixvnHo6hQVyTsFBQU0NjbmdKg752hsbKSgoOCoPpeVnaLRUIBgwNQpKpKHampqqK2tpb6+PtNFGVMFBQXU1NQc1WeGDXQzWwa8B6hzzp16hPXXAF8FkkAc+Jxz7rmjKsVR8g+KDmrYokgeCofDzJo1K9PFOC6NpMnlPmDxEOufBk53zi0EPg58Lw3lGpYeFC0icrBhA905txJoGmJ9mzvQmFUEjEvDVkw1dBGRg6SlU9TMrjWzDcDj+Fr6YNstNbPVZrZ6tO1fRdEQbaqhi4j0S0ugO+cecc7NA96Hb08fbLt7nXOLnHOLqqurR/WdRZEQHRqHLiLSL63DFlPNM7PNbGwm+x2gKBrUnaIiIgOMOtDN7EQzs9TrM4EI0Dja/Q4nphq6iMhBRjJs8UHgYqDKzGqBO4AwgHPuHuA64KNm1gt0Ah9y4zDi37ehq4YuItJn2EB3zt04zPp/Bv45bSUaIT8OXTV0EZE+WXnrP/jninb0+AdFi4hIFgd633NFO3vV7CIiAtkc6FE95EJEZKAsDnTNuCgiMlDWBroeQycicrCsDfQiBbqIyEGyN9BTTS6aoEtExMviQNdzRUVEBsraQO97DF2H7hYVEQGyOND72tA1ha6IiJe9gZ5qctHt/yIiXtYGeiQUIBw0jUMXEUnJ2kCH1BS6anIREQGyPNCLIkFNoSsikpLdgR7VQy5ERPpkdaDHoiG1oYuIpGR1oBdFgmpDFxFJyepAj0VCGocuIpKS1YFeHA1qLhcRkZSsDvSYOkVFRPpldaAXRYK0a9iiiAgwgkA3s2VmVmdm6wZZ/2EzezX187yZnZ7+Yh5ZLBKiszdBQg+KFhEZUQ39PmDxEOu3Au90zi0Avgrcm4ZyjUix5nMREek3bKA751YCTUOsf945ty/16wtATZrKNqyYHnIhItIv3W3onwCeHGylmS01s9Vmtrq+vn7UX6bH0ImIHJC2QDezS/CB/oXBtnHO3eucW+ScW1RdXT3q7+x7yIU6RkVEIJSOnZjZAuB7wBLnXGM69jkSxXoMnYhIv1HX0M1sBvAz4CPOuTdGX6SRi6lTVESk37A1dDN7ELgYqDKzWuAOIAzgnLsH+DJQCXzbzADizrlFY1XggYrU5CIi0m/YQHfO3TjM+k8Cn0xbiY5CXw1dnaIiIll+p2hx3ygXDVsUEcnuQC9MNbloCl0RkSwP9EgoQCQYUA1dRIQsD3SAomhQbegiIuRAoMciIY1DFxEhBwK9KBqkQ8MWRUSyP9BVQxcR8bI+0IujIbWhi4iQA4Eei+i5oiIikAOBXhRVk4uICORAoMf0XFERESAHAl1t6CIiXtYHeiwSojueJJ5IZrooIiIZlfWBXtT3XNFeNbuISH7L+kCP6bmiIiJADgR6Xw1dHaMiku+yP9AjegydiAjkQKDHVEMXEQFyINCL1IYuIgLkQqD3PVdUTS4ikudyINBTwxY1n4uI5LlhA93MlplZnZmtG2T9PDP7vZl1m9lt6S/i0DRsUUTEG0kN/T5g8RDrm4C/BL6WjgIdraKIOkVFRGAEge6cW4kP7cHW1znnXgR601mwkQoFA0RDAQ1bFJG8N65t6Ga21MxWm9nq+vr6tO1XU+iKiIxzoDvn7nXOLXLOLaqurk7bfmMRPVdURCTrR7mAH4vepk5REclzuRHoUT2GTkQkNNwGZvYgcDFQZWa1wB1AGMA5d4+ZTQZWA6VA0sw+B8x3zrWMWakPURRVDV1EZNhAd87dOMz6PUBN2kp0DGKRIHUt3ZksgohIxuVGk4va0EVEciTQoyGNQxeRvJcTgR6LBmlXp6iI5LmcCPSiSIieeJJePShaRPJYTgR6LDWfi24uEpF8lhOBXqw50UVEciPQY1E9V1REJCcCvW8K3TY1uYhIHsu+QN/+PNx/HXQcmNG37zF0HRqLLiJ5LPsCPdEDm5fD7lf63+p/ULSGLopIHsu+QJ+8wC8HBHqs/7miqqGLSP7KvkCPTYCyGbDn1f63+mrouv1fRPJZ9gU6wJQFBze5RDUOXUQkSwN9ITRuhi4/Q28sonHoIiJZGuipdvS96wAIBoyCcEAPuRCRvJalgX66X+4+uB1dbegiks+yM9BLJkPxpEPa0UMahy4ieS07Ax18LX3g0MWIptAVkfyW3YFevwF6OwE95EJEJHsDffICcAmoex3wNXTN5SIi+Sx7A72/Y9Q3uxSrDV1E8tywgW5my8yszszWDbLezOybZrbZzF41szPTX8wjKJ8BBeX9gR6LhDRsUUTy2khq6PcBi4dYvwSYk/pZCnxn9MUaAbODOkaLokHdWCQieW3YQHfOrQSahtjkGuCHznsBKDezKekq4JCmLIC9r0Gil1gkRLuaXEQkj6WjDX0asGPA77Wp9w5jZkvNbLWZra6vrx/9N09Z6KfTrd9IcTRIb8LRE9eDokUkP6Uj0O0I77kjbeicu9c5t8g5t6i6unr03zygY7RvPhcNXRSRfJWOQK8Fpg/4vQbYlYb9Dm/CbIgUw+5X+mdc1M1FIpKv0hHojwEfTY12OQ/Y75zbnYb9Di8QgMmnHVRDVzu6iOSr0HAbmNmDwMVAlZnVAncAYQDn3D3AE8CVwGagA/jYWBX2iCYvgJfvpzjiz00KdBHJV8MGunPuxmHWO+AzaSvR0ZpyOqz6P0zo8v2yGosuIvkqe+8U7ZPqGJ3Qsh5QDV1E8lf2B3r1XAhGKdn3GqDniopI/sr+QA+GYdJ8SprXUxgOsnZHc6ZLJCKSEdkf6ABTTie45xUumF3J0+vr8M36IiL5JWcCna5mrp4ZZ2dzJxv3tma6RCIi4y53Ah24qMTfz/T0+rpMlkZEJCNyI9AnngIWpHz/ek6bVsbT6/dmukQiIuMuNwI9XADV82D3K7zr5Im8vKOZhrbuTJdKRGRc5UagQ//c6JedPAnn4JmNaZjNUUQki+RWoLft5ZSSDiaVRtXsIiJ5J7cCHbBdL3PpvEmsfKOe7rimARCR/JE7gT51IRRNhOf+ncvmVdHek2DV1qEetCQikltyJ9DDhXDZnVC7ind0riAaCmj4oojkldwJdIDTb4RpZxFZcReXvS3G0xv26q5REckbuRXogQAs+Rdo28NfhB5lR1Mnm+raMl0qEZFxkVuBDlCzCE6/kfnbf8QJtoflGu0iInki9wId4LI7sWCEfyn+Cb9RO7qI5IncDPSSyXDR5zm3dxVFO56hqb0n0yUSERlzuRnoAOf9Od2lM/n70I/47fqdmS6NiMiYy91AD0UJX3k3JwZ2kXjh3kyXRkRkzOVuoAOBuYvZUHweV9R/n57mPZkujojImBpRoJvZYjPbaGabzeyLR1hfYWaPmNmrZrbKzE5Nf1GPgRmNF95JAT00PX5npksjIjKmhg10MwsC3wKWAPOBG81s/iGbfQlY65xbAHwU+I90F/RYnXHm2Tzk3kX1podg3/ZMF0dEZMyMpIZ+DrDZObfFOdcD/AS45pBt5gNPAzjnNgAzzWxSWkt6jGKREHWnf4a4C9D05D9lujgiImNmJIE+Ddgx4Pfa1HsDvQK8H8DMzgFOAGoO3ZGZLTWz1Wa2ur5+/OYr/8RVF/CzwOWUvfEQyYYt4/a9IiLjaSSBbkd479AJUu4GKsxsLXAL8DIQP+xDzt3rnFvknFtUXV191IU9VqUFYUou+xt6XZC3fn7nuH2viMh4Gkmg1wLTB/xeA+wauIFzrsU59zHn3EJ8G3o1sDVtpUyDK89fyFOx9zC99he07lyf6eKIiKTdSAL9RWCOmc0yswhwA/DYwA3MrDy1DuCTwErnXEt6izo6gYAx5/1/R48LsfXhL2e6OCIiaTdsoDvn4sBngV8B64GHnHOvmdmnzezTqc1OBl4zsw340TC3jlWBR+PkOSfy4sQPcErjr9myfk2miyMiklaWqfnCFy1a5FavXj3u39tcv4vItxbycsF5vP0Lj2J2pC4CEZHjk5mtcc4tOtK6nL5T9EjKq6ey5W03c37nSlY8+9tMF0dEJG3yLtABTn7/39IVKMCtuJu27sMG44iIZKW8DPRgcSXNC/6Md7nf88Cjj2e6OCIiaZGXgQ4wdfFf0Rko5sx1/8CTv38l08URERm1vA10CisIvfdrLAhs5Zz/eQ8bVjyQ6RKJiIxK/gY6ED7jRro/voKmYBXzfvvn7H/wz6DruBo+LyIyYnkd6AAlM06j8C9W8H8D11G88ackvv122PpsposlInLUQpkuwPGgpqqccz7+73z43oV8ve3bTPnBe7HTb4TK2VBQBoUVfllQBsUToWJmpossInIYBXrKaTVlfOqmG7j8B9P4ZtXPufT1n2O9HUfeeO5V8O6v+sAXETlOKNAHuGTeRP72fWfziUcK+OBZt/GVq+ZQmGyDrv2pn2bY+TL87hvwrXPh3E/BRZ+HwvJMF11EJP9u/R+Jf3tqI//5m81Ul0T5y0tP5ENnzyASGtDd0LoXVvwDvPQjiE2AS74EZ/4pBHV+FJGxNdSt/wr0Qby4rYl//Z+NrNrWRE1FIZ+77CSuPWMawcCAuV92vwq/+hJsexaqT4a33wLzr4ZoSeYKLiI5TYF+jJxzrNzUwL/+agPrdrZw4sRi/tdlJ3H5/EkHauzOwYbH4em7oOENCMfg5PfC6TfCrIsgEMzsQYhITlGgj5Jzjv9Zt4d/+/UbbK5roygS5IITq7h03kQunjuRyWUFPth3rIJXHoR1P4Pu/VA6DRZcDzPOh8IJvnmmb8SMgl5EjoECPU0SScczG+t4ekMdKzbUsXt/FwDzp5Ry6byJ3HjuDKaVF0JvF7zxJKx9EDYvB5c4ZE/mO1KrToIzPgKnvh8iReN/QCKSdRToY8A5x8a9razYUM+KDXWseWsf4aDx6XfO5lMXzaYwkqqBtzfCvq3Q0QSdTdC578DrrSt9M020DE7/EJz1MZg0Pz0FTCbhrd9DTztMPBnKakBzv4tkPQX6ONjZ3Mk/PbGex1/dzbTyQm6/ch5XnTZl6AdoOAfbn4c134fXH4VED0w/F077IJRM9k0z0VIoKPWhX1AKwfDQBalbD6/8BP7439Cy88D70VIf7BPn+5/iif7k0n+SSb3u7YTy6TBhth9nP+FtUDELIrH0/KFkZFr3wpOfh3nvhQUfzHRp5DiiQB9Hf9jSyJ2/eJ31u1s4Z9YE7njvfE6ZWjb8B9sbffv7mu9D4+ZBNjLfLl/5tgGBO9vXvrc964N8z6tgQTjxXbDgQ1A61Yd83et+ufc1P55+oFBhqn1/AoQisG87dDQcvE3ZdLjwc3DWxyEwTjNGOOf/Jiu/BhfdBgtvGt3+ertgfy1UnZie8o2VuvXw4+th/1tgAfjgfTD/mkyXSo4TCvRxlkg6fvLiW3ztVxtp7uzl7bMrmT+llJOnlDJvciknTiw+eFz7QM5B81s+dLtaoLsldVNTi69B79sGjW9C05u+Zj3QlIVw+g1w6nW+Bj7Y/lv3+MAurPAhfqTad9d+aNrifxq3wJZnYPtzMPMdcM1/jf30B/Ub4Zd/5b8zWuqbjj783/5EdSw69/mQrH0Rrv0/vonrePTmCnjoTyBcAB9YBsvvgt1r4ab/B7MvzXTpcl+821eIjuN7ShToGbK/o5fv/PZNfre5gY17W+mJJwEIB43Z1cWcNq2Ms2dN4JyZEzihMnb0zzftaPKBu28bTDoVJs5L/0H0cQ5e/hH86m8hmYDL74JFn0h/bb2309fIf/cfvqP48rtg/vvg+1f6E93Hn4TJpx3dPtvq4Efvh4aNUD0P9q7zYXnKtekt+2i99EP45f/yneU3/T8on+FPRPe9B5q2wkcfhelnZ7qUuavxTfjR+yBU4K+KJp2S6RIdkQL9OBBPJNna0M7ru1tYv7uV9btbeLW2mX0dvQBUl0Q5Z+YEzpnlf+ZOKiEQOA47MffXwmN/CW8+DSdcCNf8p29nH0pPO7z1gm8W2rrS76N8hm+br5gJE2b515374Fe3+xPUghvg3f8AxdWp790J37vMv/7kciibNrLyNu+AH14Drbvhhh/7Por7r/M19et/CPOuOta/RPokk/Cbr8JzX/e18A/e5/tP+rTuhWVX+Cu0jz159EHT0w471/irq7HqGO9u9R38UxYe/ZDc7lbY/QrsfMmXc88fYeYFsORf/ZXKeNj7ug/zZNzX0Ltb4Mp/9aPQhusH62iEoqrxKSdpCHQzWwz8BxAEvuecu/uQ9WXA/cAM/PwwX3POfX+ofeZboB9JMul4s76NP2xt4sVtTaza2tQ/FLKyKMLbT6ziwhMrueDEKmoqjqNOSefg5fv9XbLJuA+Kvtko+39KfQhvXen/kSZ7IRCCaWdB5Ymwfwc0bYOWWnDJA/uunAPv+bq/KetQe/4Iy5ZAxQk+2ApKhy5nw2Yf5t2t8OGHYMZ5/v2uFvjRtT5EbngATnp32v40R61rP/ziVnjtETjrT+HKrx2543vfdh/qLumPfaQTw219Fh77rD9JnnodXP1f6e/gbtoKP/6A7/spmeL7bhbeBNVzj7x96x7Y8lvYthJq10D9BiCVQ+Uz/BXK5uX+/5UP/RhKp6S3vIfa+RLc/34IRv1VUGEF/OzPYOtv4bTr4T3/DtHigz/T3eb7d1bd609k5TP8/7Oz3umXJZPHrLijCnQzCwJvAJcDtcCLwI3OudcHbPMloMw59wUzqwY2ApOdcz2D7VeBfjjnHLX7OnlhSyPPv9nIc5sbqG/tBmBmZYzzZ1cxd1IxJ1QWcUJljJqK2OBt8eNh/05YfqdvyuifwGz/gYC2AEw9wwf+rHfA9PMO/4cR7/Hhvm+rD965V0IoOvh3bl7u28Lf9k646aHBR/3sftX/I3UOPvIzmHL6wes7m+GHV0PdhlT79CXH/Gc4JskkrP2xv8O4vcE3Lb39L4euDdZtgO8v8X/Dj/3P0Fcp3W2w/A548Xv+6mfulfDCt/3f4cYHfWd5OtSugQeu9yf2i2+HLStg06/9vRdTz/TBPufdvplryzM+yBs2+s8WVkDN2T64p54J0848UNPd8Dg8/Gf+pH3DA37dWNj+vP//KVYBH33MXy2Cb1Z89t/gmf/tBx588D6YfKo/ea36rq/QdO/3/3/Puwp2rYVtzx0YcFA11wf73CV+OdzotKMw2kA/H7jTOXdF6vfbAZxz/3vANrcD04HPADOBXwMnOTew6nUwBfrwnHNsqmvjuU0N/G5zA6u2NdHaFe9fHzCYVlHICROKmFZeyJTyAqaUFTClrNAvywspjo5z545z/hK/q/nAkMt0e+mH8Ngt/nL46v9MXfY2+Jpf215o3g7Lv+KD76OPQtWcI++noynVPr0Fbn7YX+b3dvmmjf77Bpp9B3PlHCiqHLpcvV3+u13S/4MerH+hdg08cRvsesk3AS35F5i6cGTHvnMN/OBqP8R11kU+qOcuOTig31zhm8X274Dz/gIu/TtfK9/4JDz8SYgU+5CsOWtk3zmYDU/ATz/u/z43P3zg79xW54fNrn3AB3mfcMzfNf22d/qa7OQFQ/fB7H0NHrzB7++ab8FpHxhdeQ+1+Wn4yYf9KLGPPnrkE+TWZ+HhT/iKyozz/AkpEPT9Oud+GmoWHTgJJxP+KnLrSv+z/XfQ2+GvWE9a4ud5mn0phAtHVezRBvoHgMXOuU+mfv8IcK5z7rMDtikBHgPmASXAh5xzjx9hX0uBpQAzZsw4a/v27cd2RHnKOUdjew/bG9vZ1tDB9qYO/7qxg13NnTS0dXPof87SghA1FTFqKgqZPsEvaypiTCsvZGp5AWWF4aPvjD0ePP1VePZrUDTRB28yfvD6yjm+Zl4+Y+j9tNXDfVf5UA9GoLd98G0LJ/jQqpzjhz4mE/7KommbX7bsor/pIFrmOzCnn+t/ahb5E93yu2Dt/VA8GS7/ip8a4mj//nXrfQ1xw+P+e8HXFOde5UP8pR/4Zq1rvg0zzj34s3tf9yHZuseH5LGOcV/1XXjyb3yN/6aHBh9VtftVX3Odcrr/Gwx19XUk7Q3w0Ed9OL7jr+GSv0u9X+f7Yvbv8FeKHY1+36Go79QcuAyEfXNfcMCyaQs8/tf+xPuRRw701RxJWz08+hl/clr4YVj08ZE1A/V2+quS1x+DjU/4Sk44BnMuhzP/5JhHbI020D8IXHFIoJ/jnLtlwDYfAC4A/gqYja+hn+6cG/QBnaqhp19PPMneli72tHSxq7mT3fv9snZfJ7X7OtjR1Eln78HTEBSGg0wpK2ByqmY/raKQuZNKmDelhJmVRQfPLnk8cc53Ija+CcWTfNttySQflCWToLRm5EPPWvfAc//uO8NiFRCrPDD3TkGZ75RseAMaN/l2+YY3fKCA/+6KWamO3Zn+dTIOtavgrT9A/Xq/nQX9CSMZh/M/48fVj3ZWTuf88M6NT/if2tX+5HD+Z/2UzoPVBNsbUyH5nG/mmXamH0HU/JbvRG5+ywdlYYXvgJ043y8nneo7wFf8gx+FdNJiP1porKetiPf4K5qXfgBF1f6qKdl78DYWPMIUG8OYtghu/qk/zrGW6PUntvWPwfpfpp6lcNsx7Wo8mlweB+52zj2b+v03wBedc6sG268Cffw552hq76F2Xyc7U4G/u2+53y/3tnSR7KtkhgKcNKmEeZNLmDellIXTyzhlahkFYU0sRtd+X9sbLsw69/mg3fEHX9s8/7Njd2NT615IdA9/VQI+JJ/8PKy578B7BWVQfoL/fNl034y19zV/Auu7AuoLzkWf8BsvX58AAAofSURBVE1F4zVeu68jftuzvnmprMaXsXSaf11Q5rdJdEO8y48n71smev0JIBFPLXsB56+cRtn8cUySCd9kdozfPdpAD+E7Rd8F7MR3it7knHttwDbfAfY65+40s0nAS/gaesOR9gkK9ONVV2+CzXVtbNzTyoY9LWzY08r63a00tPnO2UgwwCnTSjlrRgVnnlDBmTMqmFQazc5mm3znHOx62TdBlE0f/Mlb8W4f6ntf880OVXPhjJs1N1CGpGPY4pXAN/DDFpc55/7RzD4N4Jy7x8ymAvcBUwDD19bvH2qfCvTsUtfaxctvNfPSW/t4afs+Xqnd33+jFPgO2lAgQDBghAJGMGhMLImycHo5Z8yo4IwZ5cyZWHL8NuGIZAndWCRp1xNP8vruFl5+ax8tnXHiySTxpCORdMQTjngyyY6mDl7e0Uxz6uapokiQBTXlnDTJT30QDAQIBYxQ0J8EIqEA1SVRJpUWMLnUt+vHIgdf0vcmkuzv7KW5o5f9nb3UVBQyqXScbj4ROQ4MFejH74QFclyLhAIsnF7OwulDPyDbOcf2xg5e3rGPl99q5uW3mvnZSzt9+Dt/AkgkB69UlBSEqC6J0t3rg7ytO37YNvMml3DRSdVcNKeaRTMr1MYveUs1dMk4lwr2rniSutQonb0tXb6Tdn8X9W3dFISDlBdGKI+FKY+FKSsMU1IQ4o29bax8o57V2/bRk0hSEA5w3tsqOXNGBZNLC5hY6mv8k0oLqIgdPEQznkjSFU/S1ZsgkXRUFkUIBTN4o5bICKjJRXJeR0+cF7Y0svKNBn77Rj1bGw4fTx4OGmWFYbp7k3TFE/QmDv5/PxgwppQVML0ixvQJhalljIklUapKolQVRykvDB+fc+xI3lCTi+S8WCTEpfMmcem8SYAfrVPf2k1daxd7W7rZ2+KX+zt7iYYCFEaCFISCFEYCFISDBMzYs7+LHfs62NHUwYqN9f3TLgwUChgTiiJUFUcpKwxTGAlSGA4etAwGjJ54kt6E/+mOJ+lNOJJJR1E0SHE0THFBiJJoiKJoiNJCf/PXrMoiymLpu0Vc8o8CXXJSQTjI9Am+hn2sunoT1O7rpK61i4a2Hhpau2lo6/vpoa0rTn1rNx09cbp6k3T2JujsSRBPJokEA4RDAb8MBoiEAhjQ3hOnvTtxxL4AgPJYmJmVRcyq8vP1lBeGiYSCREMBouEA0dTrgBkJ50g6f6JIOj8PfywSZN7kEqpLNJQ0HynQRQZREA5y4sRiTpxYPPzGRymZdP3h3tzZw46mTrY1tLO1sZ1tDe2s2trEz9fuPGwqh5GqLIqkHqhSwslT/ENVCsJBQkEjHAj4kUWp1+FQgHDqtZqTspsCXSQDAgGjpCBMSUGYyWUFzJt8+CRm3fEEHd0JuuNJuuN+2ZPqxHX4sf8BMwJmBAN+2dzZw8Y9fr799btb+eEL2w+6X2A4fcNIw8EARRHfHFRa4DugS1Md0WWFYcoLI5TFwpQXhimP+c7qwnCQnoQvY19Zu+MJehNJEklIOodzvhM86cDhqCqOMn1CjMmlBbpHIQ0U6CLHKd+8cvRDMN8++8DDFuKJJNsa29na0EFPPEk86dvz44kkvUm/jCccPanlwHb/jp44rV1xWrp6aWjrYWtDO/s7e2npig851PRYhIPG1PLC/g5pf3LqZX9HL82dPf6+g45eHP5hMFXFkdQySnVxlPJYGIe/+TXZd8JIXd4UhIPEIkFikRBFUf+6MByiK56gJXU8ftlLS2ec3oQ/AQ48vZhBRVGEC0+s4tSpZcftlYxGuYjIUXHO0dYd77+5q+9Gr/aeuG/rD/k+g2goSCTk+xCCZljfFUXAL52DvS2+I7p2Xyc7mjrYsa+Tnfs6cI6DrgDKCv1QVaC/H6O+1fdl7O/sHabEIxcOGtFQkIG52Peqo8dP/lURC3PhnGoumlPFO+ZUM7ns4BvbEklHR0+czp7EQX+f/Z29qZNUD2fNnMA7TxpihschaJSLiKSN2YHmoumj3NfcyaOccRLfNNXSGSdgvmwDlw7fud3RnaA9FbLtPQk6e+JEw0FKC8KUpZqVSgvDREOBQTuT61u7+d3mBla+Uc/KTQ384pVdAEwrLyTpHB09CTp7EyNq4vqLi2cfc6APRTV0EZGj5Jxj/e5Wnt1Uz2u7WoiGAr4pJxKiMNXEUxgJ9l9ZlBUOvCEuPKr+AtXQRUTSyMyYP7WU+VPH4Ilco6D7nEVEcoQCXUQkRyjQRURyhAJdRCRHKNBFRHKEAl1EJEco0EVEcoQCXUQkR2TsTlEzqwe2H+PHq4CGNBYnm+Trseu484uOe3AnOOeOOG9AxgJ9NMxs9WC3vua6fD12HXd+0XEfGzW5iIjkCAW6iEiOyNZAvzfTBcigfD12HXd+0XEfg6xsQxcRkcNlaw1dREQOoUAXEckRWRfoZrbYzDaa2WYz+2KmyzNWzGyZmdWZ2boB700ws1+b2abUsiKTZRwLZjbdzFaY2Xoze83Mbk29n9PHbmYFZrbKzF5JHfddqfdz+rj7mFnQzF42s1+mfs/54zazbWb2RzNba2arU++N6rizKtDNLAh8C1gCzAduNLP5mS3VmLkPWHzIe18EnnbOzQGeTv2ea+LAXzvnTgbOAz6T+m+c68feDVzqnDsdWAgsNrPzyP3j7nMrsH7A7/ly3Jc45xYOGHs+quPOqkAHzgE2O+e2OOd6gJ8A12S4TGPCObcSaDrk7WuAH6Re/wB437gWahw453Y7515KvW7F/yOfRo4fu/PaUr+GUz+OHD9uADOrAa4Cvjfg7Zw/7kGM6rizLdCnATsG/F6bei9fTHLO7QYffMDEDJdnTJnZTOAM4A/kwbGnmh3WAnXAr51zeXHcwDeAvwGSA97Lh+N2wFNmtsbMlqbeG9VxZ9tDoo/0qGyNu8xBZlYMPAx8zjnXYnbsT0nPFs65BLDQzMqBR8zs1EyXaayZ2XuAOufcGjO7ONPlGWcXOOd2mdlE4NdmtmG0O8y2GnotMH3A7zXArgyVJRP2mtkUgNSyLsPlGRNmFsaH+Y+dcz9LvZ0Xxw7gnGsGnsH3oeT6cV8AXG1m2/BNqJea2f3k/nHjnNuVWtYBj+CblEd13NkW6C8Cc8xslplFgBuAxzJcpvH0GPAnqdd/AjyawbKMCfNV8f8LrHfOfX3Aqpw+djOrTtXMMbNC4DJgAzl+3M65251zNc65mfh/z79xzt1Mjh+3mRWZWUnfa+DdwDpGedxZd6eomV2Jb3MLAsucc/+Y4SKNCTN7ELgYP53mXuAO4OfAQ8AM4C3gg865QztOs5qZXQg8C/yRA22qX8K3o+fssZvZAnwnWBBf0XrIOfcVM6skh497oFSTy23Ouffk+nGb2dvwtXLwTd8POOf+cbTHnXWBLiIiR5ZtTS4iIjIIBbqISI5QoIuI5AgFuohIjlCgi4jkCAW6iEiOUKCLiOSI/w/FyE4bEi+V8wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label = 'train')\n",
    "plt.plot(history.history['val_loss'], label = 'test')\n",
    "plt.legend()\n",
    "plt.savefig(\"10.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], label = 'train')\n",
    "plt.plot(history.history['val_accuracy'], label = 'test')\n",
    "plt.legend()\n",
    "plt.savefig(\"11.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 11,  0, ...,  0,  0, 20], dtype=int64)"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted = classifier.predict(X_test)\n",
    "y_predicted = np.argmax(y_predicted, axis = 1)\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.argmax(y_test, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "635385"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sum = 0\n",
    "for i in range(len(y_test)):\n",
    "    test_sum += (y_test[i] * 15)\n",
    "test_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_sum = 0\n",
    "for i in range(len(y_predicted)):\n",
    "    predicted_sum += (y_predicted[i] * 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Percentage in predicted values is : 2.7172501711560706 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Error Percentage in predicted values is : {} %\".format(np.absolute((predicted_sum - test_sum)/test_sum)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 20, 19, ...,  0,  0, 20], dtype=int64)"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_predicted = classifier.predict(X_train)\n",
    "y_train_predicted = np.argmax(y_train_predicted, axis = 1)\n",
    "y_train_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.argmax(y_train, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7306096239207006"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_train, y_train_predicted, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9616113943786608"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_train, y_train_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7667186380683494"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, y_train_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7148701513741895"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_predicted, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0279790999494354"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7539187594808697"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-6)</th>\n",
       "      <th>var2(t-6)</th>\n",
       "      <th>var3(t-6)</th>\n",
       "      <th>var4(t-6)</th>\n",
       "      <th>var5(t-6)</th>\n",
       "      <th>var6(t-6)</th>\n",
       "      <th>var7(t-6)</th>\n",
       "      <th>var1(t-5)</th>\n",
       "      <th>var2(t-5)</th>\n",
       "      <th>var3(t-5)</th>\n",
       "      <th>...</th>\n",
       "      <th>var5(t-1)</th>\n",
       "      <th>var6(t-1)</th>\n",
       "      <th>var7(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "      <th>var2(t)</th>\n",
       "      <th>var3(t)</th>\n",
       "      <th>var4(t)</th>\n",
       "      <th>var5(t)</th>\n",
       "      <th>var6(t)</th>\n",
       "      <th>var7(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.632689</td>\n",
       "      <td>1.422976</td>\n",
       "      <td>1.387394</td>\n",
       "      <td>2.632689</td>\n",
       "      <td>1.422976</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.225278</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.424799</td>\n",
       "      <td>-0.225278</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>1.387394</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.346315</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225278</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.917909</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.424799</td>\n",
       "      <td>0.917909</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.346315</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>1.424799</td>\n",
       "      <td>0.346315</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>...</td>\n",
       "      <td>0.917909</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.462204</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.424799</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.368465</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>...</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.462204</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.368465</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.424799</td>\n",
       "      <td>-1.368465</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>...</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.917909</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.462204</td>\n",
       "      <td>0.917909</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29671</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>3.238960</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>...</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.295068</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29672</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>3.295068</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.632689</td>\n",
       "      <td>-0.605825</td>\n",
       "      <td>...</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.388582</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29673</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.632689</td>\n",
       "      <td>-0.605825</td>\n",
       "      <td>3.295068</td>\n",
       "      <td>2.632689</td>\n",
       "      <td>-0.605825</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.632689</td>\n",
       "      <td>-0.605825</td>\n",
       "      <td>...</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.388582</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29674</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.632689</td>\n",
       "      <td>-0.605825</td>\n",
       "      <td>3.295068</td>\n",
       "      <td>2.632689</td>\n",
       "      <td>-0.605825</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.605825</td>\n",
       "      <td>...</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.388582</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29675</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.605825</td>\n",
       "      <td>3.295068</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.605825</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>...</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.388582</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29670 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       var1(t-6)  var2(t-6)  var3(t-6)  var4(t-6)  var5(t-6)  var6(t-6)  \\\n",
       "6            0.0   2.632689   1.422976   1.387394   2.632689   1.422976   \n",
       "7            0.0   1.489502   1.930176   1.387394   1.489502   1.930176   \n",
       "8            0.0   0.346315   1.930176   1.424799   0.346315   1.930176   \n",
       "9            0.0  -0.796872   2.183776   1.424799  -0.796872   2.183776   \n",
       "10           0.0  -1.368465   2.183776   1.424799  -1.368465   2.183776   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "29671        0.0   3.204282  -0.098625   3.238960   3.204282  -0.098625   \n",
       "29672        0.0   3.204282  -0.098625   3.295068   3.204282  -0.098625   \n",
       "29673        0.0   2.632689  -0.605825   3.295068   2.632689  -0.605825   \n",
       "29674        0.0   2.632689  -0.605825   3.295068   2.632689  -0.605825   \n",
       "29675        0.0   2.061095  -0.605825   3.295068   2.061095  -0.605825   \n",
       "\n",
       "      var7(t-6)  var1(t-5)  var2(t-5)  var3(t-5)  ...  var5(t-1)  var6(t-1)  \\\n",
       "6             0        0.0   1.489502   1.930176  ...  -0.796872   2.183776   \n",
       "7             0        0.0   0.346315   1.930176  ...  -0.225278   2.183776   \n",
       "8             0        0.0  -0.796872   2.183776  ...   0.917909   2.183776   \n",
       "9             9        0.0  -1.368465   2.183776  ...   1.489502   2.183776   \n",
       "10           20        0.0  -0.796872   2.183776  ...   1.489502   2.183776   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "29671         0        0.0   3.204282  -0.098625  ...   2.061095  -0.859425   \n",
       "29672         0        0.0   2.632689  -0.605825  ...   2.061095  -0.859425   \n",
       "29673         0        0.0   2.632689  -0.605825  ...   1.489502  -0.859425   \n",
       "29674         0        0.0   2.061095  -0.605825  ...   1.489502  -0.859425   \n",
       "29675         0        0.0   2.061095  -0.859425  ...   1.489502  -0.859425   \n",
       "\n",
       "       var7(t-1) var1(t)   var2(t)   var3(t)   var4(t)   var5(t)   var6(t)  \\\n",
       "6             20     0.0 -0.225278  2.183776  1.424799 -0.225278  2.183776   \n",
       "7             20     0.0  0.917909  2.183776  1.424799  0.917909  2.183776   \n",
       "8              3     0.0  1.489502  2.183776  1.462204  1.489502  2.183776   \n",
       "9              0     0.0  1.489502  2.183776  1.462204  1.489502  2.183776   \n",
       "10             0     0.0  0.917909  2.183776  1.462204  0.917909  2.183776   \n",
       "...          ...     ...       ...       ...       ...       ...       ...   \n",
       "29671          0     0.0  2.061095 -0.859425  3.295068  2.061095 -0.859425   \n",
       "29672          0     0.0  1.489502 -0.859425  3.388582  1.489502 -0.859425   \n",
       "29673          0     0.0  1.489502 -0.859425  3.388582  1.489502 -0.859425   \n",
       "29674          0     0.0  1.489502 -0.859425  3.388582  1.489502 -0.859425   \n",
       "29675          0     0.0  1.489502 -0.859425  3.388582  1.489502 -0.859425   \n",
       "\n",
       "       var7(t)  \n",
       "6           20  \n",
       "7            3  \n",
       "8            0  \n",
       "9            0  \n",
       "10           0  \n",
       "...        ...  \n",
       "29671        0  \n",
       "29672        0  \n",
       "29673        0  \n",
       "29674        0  \n",
       "29675        0  \n",
       "\n",
       "[29670 rows x 49 columns]"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reframed = series_to_supervised(working_df, 6, 1)\n",
    "reframed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_auxHeat = reframed['var7(t)']\n",
    "y_auxHeat = to_categorical(y_auxHeat).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29670, 48)"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = reframed.drop(labels = ['var7(t)'], axis = 1).astype(float)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier(optimizer):\n",
    "\n",
    "    classifier = Sequential()\n",
    "\n",
    "    # Adding the input layer and the first hidden layer\n",
    "    classifier.add(Dense(units = 24, kernel_initializer = 'uniform', activation = 'relu', input_dim = 48))\n",
    "\n",
    "    # Adding the second hidden layer\n",
    "    classifier.add(Dense(units = 24, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "    # Adding the output layer\n",
    "    classifier.add(Dense(units = 21, kernel_initializer = 'uniform', activation = 'softmax'))\n",
    "\n",
    "    # Compiling the ANN\n",
    "    classifier.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KerasClassifier(build_fn = build_classifier, batch_size = 10, nb_epoch = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'acc': 'accuracy'}\n",
    "\n",
    "parameters = {'batch_size' : [10, 64,100],\n",
    "              'epochs' : [10, 50],\n",
    "              'optimizer' : ['adam', 'rmsprop']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = scoring,\n",
    "                           refit = False,\n",
    "                           cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2671/2671 [==============================] - 4s 1ms/step - loss: 1.0158 - accuracy: 0.7367\n",
      "Epoch 2/10\n",
      "2671/2671 [==============================] - 4s 1ms/step - loss: 0.8485 - accuracy: 0.7550\n",
      "Epoch 3/10\n",
      "2671/2671 [==============================] - 4s 2ms/step - loss: 0.8195 - accuracy: 0.7571\n",
      "Epoch 4/10\n",
      "2671/2671 [==============================] - 6s 2ms/step - loss: 0.8068 - accuracy: 0.7569\n",
      "Epoch 5/10\n",
      "2671/2671 [==============================] - 5s 2ms/step - loss: 0.7976 - accuracy: 0.7588\n",
      "Epoch 6/10\n",
      "2671/2671 [==============================] - 5s 2ms/step - loss: 0.7917 - accuracy: 0.7584\n",
      "Epoch 7/10\n",
      "2671/2671 [==============================] - 4s 1ms/step - loss: 0.7842 - accuracy: 0.7620\n",
      "Epoch 8/10\n",
      "2671/2671 [==============================] - 4s 1ms/step - loss: 0.7826 - accuracy: 0.7604\n",
      "Epoch 9/10\n",
      "2671/2671 [==============================] - 4s 1ms/step - loss: 0.7795 - accuracy: 0.7612\n",
      "Epoch 10/10\n",
      "2671/2671 [==============================] - 3s 1ms/step - loss: 0.7744 - accuracy: 0.7628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:700: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 88, in __call__\n",
      "    *args, **kwargs)\n",
      "  File \"c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 243, in _score\n",
      "    **self._kwargs)\n",
      "  File \"c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 202, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 93, in _check_targets\n",
      "    \"and {1} targets\".format(type_true, type_pred))\n",
      "ValueError: Classification metrics can't handle a mix of multilabel-indicator and multiclass targets\n",
      "\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2671/2671 [==============================] - 4s 1ms/step - loss: 1.0170 - accuracy: 0.7402\n",
      "Epoch 2/10\n",
      "2671/2671 [==============================] - 4s 1ms/step - loss: 0.8400 - accuracy: 0.7604\n",
      "Epoch 3/10\n",
      "2671/2671 [==============================] - 4s 1ms/step - loss: 0.8104 - accuracy: 0.7616\n",
      "Epoch 4/10\n",
      "2671/2671 [==============================] - 4s 1ms/step - loss: 0.7995 - accuracy: 0.7615\n",
      "Epoch 5/10\n",
      "2671/2671 [==============================] - 3s 1ms/step - loss: 0.7907 - accuracy: 0.7626\n",
      "Epoch 6/10\n",
      "2671/2671 [==============================] - 3s 1ms/step - loss: 0.7857 - accuracy: 0.7629\n",
      "Epoch 7/10\n",
      "2671/2671 [==============================] - 3s 1ms/step - loss: 0.7804 - accuracy: 0.7633\n",
      "Epoch 8/10\n",
      "2671/2671 [==============================] - 4s 1ms/step - loss: 0.7765 - accuracy: 0.7632\n",
      "Epoch 9/10\n",
      "2671/2671 [==============================] - 4s 2ms/step - loss: 0.7745 - accuracy: 0.7646\n",
      "Epoch 10/10\n",
      "2671/2671 [==============================] - 3s 1ms/step - loss: 0.7724 - accuracy: 0.7637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:700: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 88, in __call__\n",
      "    *args, **kwargs)\n",
      "  File \"c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 243, in _score\n",
      "    **self._kwargs)\n",
      "  File \"c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 202, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 93, in _check_targets\n",
      "    \"and {1} targets\".format(type_true, type_pred))\n",
      "ValueError: Classification metrics can't handle a mix of multilabel-indicator and multiclass targets\n",
      "\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2671/2671 [==============================] - 4s 1ms/step - loss: 1.0253 - accuracy: 0.7416\n",
      "Epoch 2/10\n",
      "2671/2671 [==============================] - 4s 1ms/step - loss: 0.8656 - accuracy: 0.7549\n",
      "Epoch 3/10\n",
      "2671/2671 [==============================] - 4s 1ms/step - loss: 0.8358 - accuracy: 0.7562\n",
      "Epoch 4/10\n",
      "2671/2671 [==============================] - 3s 1ms/step - loss: 0.8226 - accuracy: 0.7575\n",
      "Epoch 5/10\n",
      "2671/2671 [==============================] - 3s 1ms/step - loss: 0.8113 - accuracy: 0.7574\n",
      "Epoch 6/10\n",
      "2671/2671 [==============================] - 3s 1ms/step - loss: 0.8041 - accuracy: 0.7607\n",
      "Epoch 7/10\n",
      "2671/2671 [==============================] - 3s 1ms/step - loss: 0.7969 - accuracy: 0.7602\n",
      "Epoch 8/10\n",
      "2671/2671 [==============================] - 4s 2ms/step - loss: 0.7922 - accuracy: 0.7603\n",
      "Epoch 9/10\n",
      "2671/2671 [==============================] - 4s 1ms/step - loss: 0.7880 - accuracy: 0.7604\n",
      "Epoch 10/10\n",
      "2671/2671 [==============================] - 5s 2ms/step - loss: 0.7848 - accuracy: 0.7613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:700: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 88, in __call__\n",
      "    *args, **kwargs)\n",
      "  File \"c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 243, in _score\n",
      "    **self._kwargs)\n",
      "  File \"c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 202, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 93, in _check_targets\n",
      "    \"and {1} targets\".format(type_true, type_pred))\n",
      "ValueError: Classification metrics can't handle a mix of multilabel-indicator and multiclass targets\n",
      "\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2671/2671 [==============================] - 4s 1ms/step - loss: 1.0295 - accuracy: 0.7386\n",
      "Epoch 2/10\n",
      "2671/2671 [==============================] - 4s 2ms/step - loss: 0.8590 - accuracy: 0.7547\n",
      "Epoch 3/10\n",
      "2671/2671 [==============================] - 4s 2ms/step - loss: 0.8336 - accuracy: 0.7562\n",
      "Epoch 4/10\n",
      "2671/2671 [==============================] - 6s 2ms/step - loss: 0.8184 - accuracy: 0.7569\n",
      "Epoch 5/10\n",
      "2671/2671 [==============================] - 4s 1ms/step - loss: 0.8070 - accuracy: 0.7581\n",
      "Epoch 6/10\n",
      "2671/2671 [==============================] - 4s 2ms/step - loss: 0.8029 - accuracy: 0.7584\n",
      "Epoch 7/10\n",
      "2671/2671 [==============================] - 4s 1ms/step - loss: 0.7960 - accuracy: 0.7588\n",
      "Epoch 8/10\n",
      "2671/2671 [==============================] - 4s 1ms/step - loss: 0.7911 - accuracy: 0.7590\n",
      "Epoch 9/10\n",
      "1251/2671 [=============>................] - ETA: 5s - loss: 0.7886 - accuracy: 0.7575"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-517-606c2280d5fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_auxHeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1295\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1296\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    807\u001b[0m                                    (split_idx, (train, test)) in product(\n\u001b[0;32m    808\u001b[0m                                    \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 809\u001b[1;33m                                    enumerate(cv.split(X, y, groups))))\n\u001b[0m\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    833\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 835\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    596\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    599\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    218\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Invalid shape for y: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 3024\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1961\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    597\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid_search.fit(X, y_auxHeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_results = pd.DataFrame(grid_search.cv_results_, columns = list(grid_search.cv_results_.keys()))\n",
    "grid_search_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier_relu():\n",
    "\n",
    "    classifier = Sequential()\n",
    "\n",
    "    # Adding the input layer and the first hidden layer\n",
    "    classifier.add(Dense(units = 24, kernel_initializer = 'uniform', activation = 'relu', input_dim = 48))\n",
    "\n",
    "    # Adding the second hidden layer\n",
    "    classifier.add(Dense(units = 24, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "    # Adding the output layer\n",
    "    classifier.add(Dense(units = 21, kernel_initializer = 'uniform', activation = 'softmax'))\n",
    "\n",
    "    # Compiling the ANN\n",
    "    classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KerasClassifier(build_fn = build_classifier_relu, batch_size = 64, nb_epoch = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scoring = {'acc': 'accuracy',\n",
    "#            }\n",
    "#scoring = ['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_funcs = ['relu', 'logistic', 'tanh']\n",
    "ac_funcs_score_time = []\n",
    "ac_funcs_acc = []\n",
    "ac_funcs_f1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype(float)\n",
    "y_auxHeat = y_auxHeat.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418/418 [==============================] - 1s 2ms/step - loss: 1.3260 - accuracy: 0.7159\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 1.2531 - accuracy: 0.6967\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 1.3354 - accuracy: 0.7078\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 1.2871 - accuracy: 0.6828\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 1.3399 - accuracy: 0.6903\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 1.0977 - accuracy: 0.7159\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 1.3551 - accuracy: 0.7123\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 1.0708 - accuracy: 0.7290\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 1.3469 - accuracy: 0.6952\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 1.0714 - accuracy: 0.7162\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 1.3519 - accuracy: 0.7092\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.0120 - accuracy: 0.7395\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 1.3629 - accuracy: 0.6966\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.9812 - accuracy: 0.7526\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 1.3505 - accuracy: 0.7029\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.8671 - accuracy: 0.7779\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 1.3420 - accuracy: 0.7096\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.8081 - accuracy: 0.8008\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 1.3818 - accuracy: 0.6979\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.7996 - accuracy: 0.8005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([1.45613742, 1.34741712, 1.30852008, 1.23070812, 1.23672771,\n",
       "        1.2367177 , 1.38033819, 1.25666094, 1.27360797, 1.34641027]),\n",
       " 'score_time': array([0.30617738, 0.27826047, 0.27726436, 0.26429558, 0.26926851,\n",
       "        0.323138  , 0.26228786, 0.24534416, 0.25332212, 0.30319262]),\n",
       " 'test_score': array([0.69666332, 0.68284464, 0.71587461, 0.72901922, 0.71621168,\n",
       "        0.7394675 , 0.75261205, 0.77789015, 0.80080891, 0.80047184])}"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_validate(estimator = classifier, X = X, y = y_auxHeat, cv = 10)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_funcs_score_time.append(scores['score_time'])\n",
    "ac_funcs_acc.append(scores['test_score'])\n",
    "#ac_funcs_f1.append(scores['test_f1_weighted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier_sigmoid():\n",
    "\n",
    "    classifier = Sequential()\n",
    "\n",
    "    # Adding the input layer and the first hidden layer\n",
    "    classifier.add(Dense(units = 24, kernel_initializer = 'uniform', activation = 'sigmoid', input_dim = 48))\n",
    "\n",
    "    # Adding the second hidden layer\n",
    "    classifier.add(Dense(units = 24, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "    # Adding the output layer\n",
    "    classifier.add(Dense(units = 21, kernel_initializer = 'uniform', activation = 'softmax'))\n",
    "\n",
    "    # Compiling the ANN\n",
    "    classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29670, 48), (29670, 21))"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y_auxHeat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418/418 [==============================] - 2s 2ms/step - loss: 1.8041 - accuracy: 0.4787\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.7299 - accuracy: 0.4584\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 1.7867 - accuracy: 0.5128\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 1.7820 - accuracy: 0.4772\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 1.8063 - accuracy: 0.4730\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 1.6568 - accuracy: 0.4968\n",
      "418/418 [==============================] - 2s 3ms/step - loss: 1.8044 - accuracy: 0.5040\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 1.5948 - accuracy: 0.5261\n",
      "418/418 [==============================] - 2s 3ms/step - loss: 1.8110 - accuracy: 0.4730\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 1.7190 - accuracy: 0.4402\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 1.8011 - accuracy: 0.5110\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.6902 - accuracy: 0.4301\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 1.8013 - accuracy: 0.5181\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.7011 - accuracy: 0.4294\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 1.8367 - accuracy: 0.4687\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.4369 - accuracy: 0.5740\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 1.8416 - accuracy: 0.4955\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.3027 - accuracy: 0.6299\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 1.8373 - accuracy: 0.4946\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.2727 - accuracy: 0.6633\n"
     ]
    }
   ],
   "source": [
    "classifier = KerasClassifier(build_fn = build_classifier_sigmoid, batch_size = 64, nb_epoch = 50)\n",
    "\n",
    "scoring = {'acc': 'accuracy',\n",
    "           'f1_weighted': 'f1_weighted'}\n",
    "\n",
    "\n",
    "scores = cross_validate(estimator = classifier, X = X, y = y_auxHeat, cv = 10)\n",
    "ac_funcs_score_time.append(scores['score_time'])\n",
    "ac_funcs_acc.append(scores['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier_tanh():\n",
    "\n",
    "    classifier = Sequential()\n",
    "\n",
    "    # Adding the input layer and the first hidden layer\n",
    "    classifier.add(Dense(units = 24, kernel_initializer = 'uniform', activation = 'tanh', input_dim = 48))\n",
    "\n",
    "    # Adding the second hidden layer\n",
    "    classifier.add(Dense(units = 24, kernel_initializer = 'uniform', activation = 'tanh'))\n",
    "\n",
    "    # Adding the output layer\n",
    "    classifier.add(Dense(units = 21, kernel_initializer = 'uniform', activation = 'softmax'))\n",
    "\n",
    "    # Compiling the ANN\n",
    "    classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418/418 [==============================] - 2s 3ms/step - loss: 1.4256 - accuracy: 0.6849\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 1.1650 - accuracy: 0.7145\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 1.5527 - accuracy: 0.6223\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.3224 - accuracy: 0.6771\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 1.5176 - accuracy: 0.6470\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.1306 - accuracy: 0.7152\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 1.4075 - accuracy: 0.7013\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 1.0477 - accuracy: 0.7324\n",
      "418/418 [==============================] - 2s 3ms/step - loss: 1.3887 - accuracy: 0.7167\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.0472 - accuracy: 0.7230\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 1.5245 - accuracy: 0.6319\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 1.0894 - accuracy: 0.7246\n",
      "418/418 [==============================] - 2s 2ms/step - loss: 1.4760 - accuracy: 0.6866\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 1.0775 - accuracy: 0.7385\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 1.5278 - accuracy: 0.6586\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.8995 - accuracy: 0.7799\n",
      "418/418 [==============================] - 2s 3ms/step - loss: 1.4290 - accuracy: 0.7125\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.7806 - accuracy: 0.7995\n",
      "418/418 [==============================] - 1s 2ms/step - loss: 1.5160 - accuracy: 0.6649\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.7791 - accuracy: 0.8022\n"
     ]
    }
   ],
   "source": [
    "classifier = KerasClassifier(build_fn = build_classifier_tanh, batch_size = 64, nb_epoch = 50)\n",
    "\n",
    "scoring = {'acc': 'accuracy',\n",
    "           }\n",
    "\n",
    "scores = cross_validate(estimator = classifier, X = X, y = y_auxHeat, cv = 10)\n",
    "ac_funcs_score_time.append(scores['score_time'])\n",
    "ac_funcs_acc.append(scores['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.69666332, 0.68284464, 0.71587461, 0.72901922, 0.71621168,\n",
       "        0.7394675 , 0.75261205, 0.77789015, 0.80080891, 0.80047184]),\n",
       " array([0.45837545, 0.47724974, 0.4967981 , 0.52612066, 0.44017527,\n",
       "        0.43006405, 0.42938995, 0.57398045, 0.62992924, 0.66329628]),\n",
       " array([0.71452647, 0.6771149 , 0.71520054, 0.73238963, 0.72295249,\n",
       "        0.72463769, 0.73845637, 0.77991235, 0.79946071, 0.80215704])]"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac_funcs_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df = pd.DataFrame(ac_funcs_acc)\n",
    "acc_df = acc_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df = acc_df.rename(columns = {0:'ReLu', 1:'Sigmoid', 2:'Tanh'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReLu</th>\n",
       "      <th>Sigmoid</th>\n",
       "      <th>Tanh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.696663</td>\n",
       "      <td>0.458375</td>\n",
       "      <td>0.714526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.682845</td>\n",
       "      <td>0.477250</td>\n",
       "      <td>0.677115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.715875</td>\n",
       "      <td>0.496798</td>\n",
       "      <td>0.715201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.729019</td>\n",
       "      <td>0.526121</td>\n",
       "      <td>0.732390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.716212</td>\n",
       "      <td>0.440175</td>\n",
       "      <td>0.722952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.739468</td>\n",
       "      <td>0.430064</td>\n",
       "      <td>0.724638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.752612</td>\n",
       "      <td>0.429390</td>\n",
       "      <td>0.738456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.777890</td>\n",
       "      <td>0.573980</td>\n",
       "      <td>0.779912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.800809</td>\n",
       "      <td>0.629929</td>\n",
       "      <td>0.799461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.800472</td>\n",
       "      <td>0.663296</td>\n",
       "      <td>0.802157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ReLu   Sigmoid      Tanh\n",
       "0  0.696663  0.458375  0.714526\n",
       "1  0.682845  0.477250  0.677115\n",
       "2  0.715875  0.496798  0.715201\n",
       "3  0.729019  0.526121  0.732390\n",
       "4  0.716212  0.440175  0.722952\n",
       "5  0.739468  0.430064  0.724638\n",
       "6  0.752612  0.429390  0.738456\n",
       "7  0.777890  0.573980  0.779912\n",
       "8  0.800809  0.629929  0.799461\n",
       "9  0.800472  0.663296  0.802157"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12, 10))\n",
    "ax = sns.boxplot(data = acc_df)\n",
    "ax.set(ylabel = \"Accuracy\", xlabel = \"Activation Function Used\")\n",
    "plt.savefig(\"12.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "min() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-606-706a3dda7aa4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mboxplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mylabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Weighted F1-Score\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Activation Function Used\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"13.png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\seaborn\\categorical.py\u001b[0m in \u001b[0;36mboxplot\u001b[1;34m(x, y, hue, data, order, hue_order, orient, color, palette, saturation, width, dodge, fliersize, linewidth, whis, ax, **kwargs)\u001b[0m\n\u001b[0;32m   2233\u001b[0m     plotter = _BoxPlotter(x, y, hue, data, order, hue_order,\n\u001b[0;32m   2234\u001b[0m                           \u001b[0morient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaturation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2235\u001b[1;33m                           width, dodge, fliersize, linewidth)\n\u001b[0m\u001b[0;32m   2236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2237\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0max\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\seaborn\\categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, hue, data, order, hue_order, orient, color, palette, saturation, width, dodge, fliersize, linewidth)\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestablish_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhue_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 437\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestablish_colors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaturation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdodge\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdodge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\seaborn\\categorical.py\u001b[0m in \u001b[0;36mestablish_colors\u001b[1;34m(self, color, palette, saturation)\u001b[0m\n\u001b[0;32m    314\u001b[0m         \u001b[1;31m# Determine the gray color to use for the lines framing the plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m         \u001b[0mlight_vals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcolorsys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrgb_to_hls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrgb_colors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m         \u001b[0mlum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlight_vals\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m.6\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m         \u001b[0mgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrgb2hex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: min() arg is an empty sequence"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# f1_df = pd.DataFrame(ac_funcs_f1)\n",
    "# f1_df = f1_df.T\n",
    "\n",
    "# f1_df = f1_df.rename(columns = {0:'ReLu', 1:'Sigmoid', 2:'Tanh'})\n",
    "\n",
    "# plt.figure(figsize = (12, 10))\n",
    "# ax = sns.boxplot(data = f1_df)\n",
    "# ax.set(ylabel = \"Weighted F1-Score\", xlabel = \"Activation Function Used\")\n",
    "# plt.savefig(\"13.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "time_df = pd.DataFrame(ac_funcs_score_time)\n",
    "time_df = time_df.T\n",
    "\n",
    "time_df = time_df.rename(columns = {0:'ReLu', 1:'Sigmoid', 2:'Tanh'})\n",
    "\n",
    "plt.figure(figsize = (12, 10))\n",
    "ax = sns.boxplot(data = time_df)\n",
    "ax.set(ylabel = \"Time Taken for Prediction\", xlabel = \"Activation Function Used\")\n",
    "plt.savefig(\"14.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
