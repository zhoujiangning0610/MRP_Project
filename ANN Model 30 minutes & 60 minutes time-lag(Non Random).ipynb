{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.utils import class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>System Setting</th>\n",
       "      <th>System Mode</th>\n",
       "      <th>Calendar Event</th>\n",
       "      <th>Program Mode</th>\n",
       "      <th>Cool Set Temp (C)</th>\n",
       "      <th>Heat Set Temp (C)</th>\n",
       "      <th>Current Temp (C)</th>\n",
       "      <th>...</th>\n",
       "      <th>Thermostat Humidity (%RH)</th>\n",
       "      <th>Thermostat Motion</th>\n",
       "      <th>Bedroom (C)</th>\n",
       "      <th>Bedroom2</th>\n",
       "      <th>3rd floor landing (C)</th>\n",
       "      <th>3rd floor landing2</th>\n",
       "      <th>3rd floor room (C)</th>\n",
       "      <th>3rd floor room2</th>\n",
       "      <th>Basement (C)</th>\n",
       "      <th>Basement2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-12-10</td>\n",
       "      <td>12:50:00</td>\n",
       "      <td>2020/12/10 12:50:00</td>\n",
       "      <td>heat</td>\n",
       "      <td>heatOff</td>\n",
       "      <td>auto</td>\n",
       "      <td>Home</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.3</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-12-10</td>\n",
       "      <td>12:55:00</td>\n",
       "      <td>2020/12/10 12:55:00</td>\n",
       "      <td>heat</td>\n",
       "      <td>heatOff</td>\n",
       "      <td>auto</td>\n",
       "      <td>Home</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.1</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-12-10</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>2020/12/10 13:00:00</td>\n",
       "      <td>heat</td>\n",
       "      <td>heatOff</td>\n",
       "      <td>auto</td>\n",
       "      <td>Home</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-12-10</td>\n",
       "      <td>13:05:00</td>\n",
       "      <td>2020/12/10 13:05:00</td>\n",
       "      <td>heat</td>\n",
       "      <td>heatOff</td>\n",
       "      <td>auto</td>\n",
       "      <td>Home</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.7</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-12-10</td>\n",
       "      <td>13:10:00</td>\n",
       "      <td>2020/12/10 13:10:00</td>\n",
       "      <td>heat</td>\n",
       "      <td>heatStage1On</td>\n",
       "      <td>auto</td>\n",
       "      <td>Home</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.6</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29671</th>\n",
       "      <td>2021-03-23</td>\n",
       "      <td>14:25:00</td>\n",
       "      <td>2021/3/23 14:25:00</td>\n",
       "      <td>heat</td>\n",
       "      <td>heatOff</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Home</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29672</th>\n",
       "      <td>2021-03-23</td>\n",
       "      <td>14:30:00</td>\n",
       "      <td>2021/3/23 14:30:00</td>\n",
       "      <td>heat</td>\n",
       "      <td>heatOff</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Home</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.1</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29673</th>\n",
       "      <td>2021-03-23</td>\n",
       "      <td>14:35:00</td>\n",
       "      <td>2021/3/23 14:35:00</td>\n",
       "      <td>heat</td>\n",
       "      <td>heatOff</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Home</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.1</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29674</th>\n",
       "      <td>2021-03-23</td>\n",
       "      <td>14:40:00</td>\n",
       "      <td>2021/3/23 14:40:00</td>\n",
       "      <td>heat</td>\n",
       "      <td>heatOff</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Home</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.1</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29675</th>\n",
       "      <td>2021-03-23</td>\n",
       "      <td>14:45:00</td>\n",
       "      <td>2021/3/23 14:45:00</td>\n",
       "      <td>heat</td>\n",
       "      <td>heatOff</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Home</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.1</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29676 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date      Time             DateTime System Setting   System Mode  \\\n",
       "0     2020-12-10  12:50:00  2020/12/10 12:50:00           heat       heatOff   \n",
       "1     2020-12-10  12:55:00  2020/12/10 12:55:00           heat       heatOff   \n",
       "2     2020-12-10  13:00:00  2020/12/10 13:00:00           heat       heatOff   \n",
       "3     2020-12-10  13:05:00  2020/12/10 13:05:00           heat       heatOff   \n",
       "4     2020-12-10  13:10:00  2020/12/10 13:10:00           heat  heatStage1On   \n",
       "...          ...       ...                  ...            ...           ...   \n",
       "29671 2021-03-23  14:25:00   2021/3/23 14:25:00           heat       heatOff   \n",
       "29672 2021-03-23  14:30:00   2021/3/23 14:30:00           heat       heatOff   \n",
       "29673 2021-03-23  14:35:00   2021/3/23 14:35:00           heat       heatOff   \n",
       "29674 2021-03-23  14:40:00   2021/3/23 14:40:00           heat       heatOff   \n",
       "29675 2021-03-23  14:45:00   2021/3/23 14:45:00           heat       heatOff   \n",
       "\n",
       "      Calendar Event Program Mode  Cool Set Temp (C)  Heat Set Temp (C)  \\\n",
       "0               auto         Home               21.0               21.0   \n",
       "1               auto         Home               21.0               21.0   \n",
       "2               auto         Home               21.0               21.0   \n",
       "3               auto         Home               21.0               21.0   \n",
       "4               auto         Home               21.0               21.0   \n",
       "...              ...          ...                ...                ...   \n",
       "29671            NaN         Home               21.0               21.0   \n",
       "29672            NaN         Home               21.0               21.0   \n",
       "29673            NaN         Home               21.0               21.0   \n",
       "29674            NaN         Home               21.0               21.0   \n",
       "29675            NaN         Home               21.0               21.0   \n",
       "\n",
       "       Current Temp (C)  ...  Thermostat Humidity (%RH)  Thermostat Motion  \\\n",
       "0                  21.3  ...                       30.0                1.0   \n",
       "1                  21.1  ...                       32.0                1.0   \n",
       "2                  20.9  ...                       32.0                0.0   \n",
       "3                  20.7  ...                       33.0                0.0   \n",
       "4                  20.6  ...                       33.0                1.0   \n",
       "...                 ...  ...                        ...                ...   \n",
       "29671              21.2  ...                       21.0                0.0   \n",
       "29672              21.1  ...                       21.0                0.0   \n",
       "29673              21.1  ...                       21.0                0.0   \n",
       "29674              21.1  ...                       21.0                0.0   \n",
       "29675              21.1  ...                       21.0                1.0   \n",
       "\n",
       "       Bedroom (C)  Bedroom2  3rd floor landing (C)  3rd floor landing2  \\\n",
       "0             21.6       0.0                   20.9                 0.0   \n",
       "1             21.6       0.0                   20.9                 0.0   \n",
       "2             21.6       0.0                   20.8                 0.0   \n",
       "3             21.6       0.0                   20.8                 0.0   \n",
       "4             21.6       0.0                   20.8                 0.0   \n",
       "...            ...       ...                    ...                 ...   \n",
       "29671         21.9       0.0                   21.8                 0.0   \n",
       "29672         21.9       0.0                   21.8                 0.0   \n",
       "29673         21.9       0.0                   21.8                 1.0   \n",
       "29674         21.9       0.0                   21.8                 1.0   \n",
       "29675         21.9       0.0                   21.8                 0.0   \n",
       "\n",
       "       3rd floor room (C)  3rd floor room2  Basement (C)  Basement2  \n",
       "0                    21.0              0.0          22.8        0.0  \n",
       "1                    20.9              0.0          22.7        1.0  \n",
       "2                    20.8              0.0          22.7        1.0  \n",
       "3                    20.8              0.0          22.8        0.0  \n",
       "4                    20.8              0.0          22.8        0.0  \n",
       "...                   ...              ...           ...        ...  \n",
       "29671                21.3              0.0          22.0        1.0  \n",
       "29672                21.3              0.0          22.1        0.0  \n",
       "29673                21.3              0.0          22.1        0.0  \n",
       "29674                21.3              0.0          22.1        0.0  \n",
       "29675                21.3              0.0          22.1        1.0  \n",
       "\n",
       "[29676 rows x 27 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_data = pd.read_excel(\"Clean_Data.xlsx\")\n",
    "house_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = preprocessing.OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                              0\n",
       "Time                              0\n",
       "DateTime                          0\n",
       "System Setting                    0\n",
       "System Mode                       0\n",
       "Calendar Event                29548\n",
       "Program Mode                      0\n",
       "Cool Set Temp (C)                 0\n",
       "Heat Set Temp (C)                 0\n",
       "Current Temp (C)                  0\n",
       "Current Humidity (%RH)            0\n",
       "Outdoor Temp (C)                  0\n",
       "Wind Speed (km/h)                 0\n",
       "Cool Stage 1 (sec)                0\n",
       "Heat Stage 1 (sec)                0\n",
       "Fan (sec)                         0\n",
       "Thermostat Temperature (C)        0\n",
       "Thermostat Humidity (%RH)         0\n",
       "Thermostat Motion                 0\n",
       "Bedroom (C)                       0\n",
       "Bedroom2                          0\n",
       "3rd floor landing (C)             0\n",
       "3rd floor landing2                0\n",
       "3rd floor room (C)                0\n",
       "3rd floor room2                   0\n",
       "Basement (C)                      0\n",
       "Basement2                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_data = house_data.fillna(method = \"bfill\")\n",
    "house_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### same as approch b, build new datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_vars = ['Heat Set Temp (C)', 'Current Temp (C)', 'Current Humidity (%RH)', 'Outdoor Temp (C)','Thermostat Temperature (C)', 'Thermostat Humidity (%RH)']\n",
    "sc = StandardScaler()\n",
    "sc.fit(house_data[numerical_vars])\n",
    "scalar_data = sc.transform(house_data[numerical_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_auxHeat = house_data['Heat Stage 1 (sec)'].to_numpy()\n",
    "oe = OrdinalEncoder()\n",
    "y_auxHeat = oe.fit_transform(y_auxHeat.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_house_data = house_data[numerical_vars].copy()\n",
    "scaler_house_data[numerical_vars] = scalar_data\n",
    "scaler_house_data[\"Heat Stage 1\"] = y_auxHeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Heat Set Temp (C)</th>\n",
       "      <th>Current Temp (C)</th>\n",
       "      <th>Current Humidity (%RH)</th>\n",
       "      <th>Outdoor Temp (C)</th>\n",
       "      <th>Thermostat Temperature (C)</th>\n",
       "      <th>Thermostat Humidity (%RH)</th>\n",
       "      <th>Heat Stage 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.632689</td>\n",
       "      <td>1.422976</td>\n",
       "      <td>1.387394</td>\n",
       "      <td>2.632689</td>\n",
       "      <td>1.422976</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>1.387394</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.346315</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>1.424799</td>\n",
       "      <td>0.346315</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.424799</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.368465</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.424799</td>\n",
       "      <td>-1.368465</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29671</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.295068</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29672</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.388582</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29673</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.388582</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29674</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.388582</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29675</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.388582</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29676 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Heat Set Temp (C)  Current Temp (C)  Current Humidity (%RH)  \\\n",
       "0                    0.0          2.632689                1.422976   \n",
       "1                    0.0          1.489502                1.930176   \n",
       "2                    0.0          0.346315                1.930176   \n",
       "3                    0.0         -0.796872                2.183776   \n",
       "4                    0.0         -1.368465                2.183776   \n",
       "...                  ...               ...                     ...   \n",
       "29671                0.0          2.061095               -0.859425   \n",
       "29672                0.0          1.489502               -0.859425   \n",
       "29673                0.0          1.489502               -0.859425   \n",
       "29674                0.0          1.489502               -0.859425   \n",
       "29675                0.0          1.489502               -0.859425   \n",
       "\n",
       "       Outdoor Temp (C)  Thermostat Temperature (C)  \\\n",
       "0              1.387394                    2.632689   \n",
       "1              1.387394                    1.489502   \n",
       "2              1.424799                    0.346315   \n",
       "3              1.424799                   -0.796872   \n",
       "4              1.424799                   -1.368465   \n",
       "...                 ...                         ...   \n",
       "29671          3.295068                    2.061095   \n",
       "29672          3.388582                    1.489502   \n",
       "29673          3.388582                    1.489502   \n",
       "29674          3.388582                    1.489502   \n",
       "29675          3.388582                    1.489502   \n",
       "\n",
       "       Thermostat Humidity (%RH)  Heat Stage 1  \n",
       "0                       1.422976           0.0  \n",
       "1                       1.930176           0.0  \n",
       "2                       1.930176           0.0  \n",
       "3                       2.183776           9.0  \n",
       "4                       2.183776          20.0  \n",
       "...                          ...           ...  \n",
       "29671                  -0.859425           0.0  \n",
       "29672                  -0.859425           0.0  \n",
       "29673                  -0.859425           0.0  \n",
       "29674                  -0.859425           0.0  \n",
       "29675                  -0.859425           0.0  \n",
       "\n",
       "[29676 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_house_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### use time-Lag build predictor. this function used to build time-lag datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in = 1, n_out = 1, dropnan = True):\n",
    "    \n",
    "    n_vars = data.shape[1]\n",
    "    columns = data.columns\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    df_new = pd.DataFrame()\n",
    "    \n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        for j in range(n_vars):\n",
    "            df_new['var%d(t-%d)' % (j+1, i)] = df.shift(i)[columns[j]]\n",
    "   \n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        \n",
    "        for j in range(n_vars):\n",
    "            if i == 0:\n",
    "                name = 'var%d(t)' % (j+1)\n",
    "            else:\n",
    "                name = 'var%d(t+%d)' % (j+1, i)\n",
    "            df_new[name] = df.shift(-i)[columns[j]]\n",
    "    \n",
    "    if dropnan:\n",
    "        df_new.dropna(inplace=True)\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate 30-minutes time-lag datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-6)</th>\n",
       "      <th>var2(t-6)</th>\n",
       "      <th>var3(t-6)</th>\n",
       "      <th>var4(t-6)</th>\n",
       "      <th>var5(t-6)</th>\n",
       "      <th>var6(t-6)</th>\n",
       "      <th>var7(t-6)</th>\n",
       "      <th>var1(t-5)</th>\n",
       "      <th>var2(t-5)</th>\n",
       "      <th>var3(t-5)</th>\n",
       "      <th>...</th>\n",
       "      <th>var5(t-1)</th>\n",
       "      <th>var6(t-1)</th>\n",
       "      <th>var7(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "      <th>var2(t)</th>\n",
       "      <th>var3(t)</th>\n",
       "      <th>var4(t)</th>\n",
       "      <th>var5(t)</th>\n",
       "      <th>var6(t)</th>\n",
       "      <th>var7(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.632689</td>\n",
       "      <td>1.422976</td>\n",
       "      <td>1.387394</td>\n",
       "      <td>2.632689</td>\n",
       "      <td>1.422976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.225278</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.424799</td>\n",
       "      <td>-0.225278</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>1.387394</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.346315</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225278</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.917909</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.424799</td>\n",
       "      <td>0.917909</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.346315</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>1.424799</td>\n",
       "      <td>0.346315</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>...</td>\n",
       "      <td>0.917909</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.462204</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.424799</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.368465</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>...</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.462204</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.368465</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.424799</td>\n",
       "      <td>-1.368465</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>...</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.917909</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.462204</td>\n",
       "      <td>0.917909</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29671</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>3.238960</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>...</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.295068</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29672</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>3.295068</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.632689</td>\n",
       "      <td>-0.605825</td>\n",
       "      <td>...</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.388582</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29673</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.632689</td>\n",
       "      <td>-0.605825</td>\n",
       "      <td>3.295068</td>\n",
       "      <td>2.632689</td>\n",
       "      <td>-0.605825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.632689</td>\n",
       "      <td>-0.605825</td>\n",
       "      <td>...</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.388582</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29674</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.632689</td>\n",
       "      <td>-0.605825</td>\n",
       "      <td>3.295068</td>\n",
       "      <td>2.632689</td>\n",
       "      <td>-0.605825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.605825</td>\n",
       "      <td>...</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.388582</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29675</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.605825</td>\n",
       "      <td>3.295068</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.605825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>...</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.388582</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29670 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       var1(t-6)  var2(t-6)  var3(t-6)  var4(t-6)  var5(t-6)  var6(t-6)  \\\n",
       "6            0.0   2.632689   1.422976   1.387394   2.632689   1.422976   \n",
       "7            0.0   1.489502   1.930176   1.387394   1.489502   1.930176   \n",
       "8            0.0   0.346315   1.930176   1.424799   0.346315   1.930176   \n",
       "9            0.0  -0.796872   2.183776   1.424799  -0.796872   2.183776   \n",
       "10           0.0  -1.368465   2.183776   1.424799  -1.368465   2.183776   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "29671        0.0   3.204282  -0.098625   3.238960   3.204282  -0.098625   \n",
       "29672        0.0   3.204282  -0.098625   3.295068   3.204282  -0.098625   \n",
       "29673        0.0   2.632689  -0.605825   3.295068   2.632689  -0.605825   \n",
       "29674        0.0   2.632689  -0.605825   3.295068   2.632689  -0.605825   \n",
       "29675        0.0   2.061095  -0.605825   3.295068   2.061095  -0.605825   \n",
       "\n",
       "       var7(t-6)  var1(t-5)  var2(t-5)  var3(t-5)  ...  var5(t-1)  var6(t-1)  \\\n",
       "6            0.0        0.0   1.489502   1.930176  ...  -0.796872   2.183776   \n",
       "7            0.0        0.0   0.346315   1.930176  ...  -0.225278   2.183776   \n",
       "8            0.0        0.0  -0.796872   2.183776  ...   0.917909   2.183776   \n",
       "9            9.0        0.0  -1.368465   2.183776  ...   1.489502   2.183776   \n",
       "10          20.0        0.0  -0.796872   2.183776  ...   1.489502   2.183776   \n",
       "...          ...        ...        ...        ...  ...        ...        ...   \n",
       "29671        0.0        0.0   3.204282  -0.098625  ...   2.061095  -0.859425   \n",
       "29672        0.0        0.0   2.632689  -0.605825  ...   2.061095  -0.859425   \n",
       "29673        0.0        0.0   2.632689  -0.605825  ...   1.489502  -0.859425   \n",
       "29674        0.0        0.0   2.061095  -0.605825  ...   1.489502  -0.859425   \n",
       "29675        0.0        0.0   2.061095  -0.859425  ...   1.489502  -0.859425   \n",
       "\n",
       "       var7(t-1)  var1(t)   var2(t)   var3(t)   var4(t)   var5(t)   var6(t)  \\\n",
       "6           20.0      0.0 -0.225278  2.183776  1.424799 -0.225278  2.183776   \n",
       "7           20.0      0.0  0.917909  2.183776  1.424799  0.917909  2.183776   \n",
       "8            3.0      0.0  1.489502  2.183776  1.462204  1.489502  2.183776   \n",
       "9            0.0      0.0  1.489502  2.183776  1.462204  1.489502  2.183776   \n",
       "10           0.0      0.0  0.917909  2.183776  1.462204  0.917909  2.183776   \n",
       "...          ...      ...       ...       ...       ...       ...       ...   \n",
       "29671        0.0      0.0  2.061095 -0.859425  3.295068  2.061095 -0.859425   \n",
       "29672        0.0      0.0  1.489502 -0.859425  3.388582  1.489502 -0.859425   \n",
       "29673        0.0      0.0  1.489502 -0.859425  3.388582  1.489502 -0.859425   \n",
       "29674        0.0      0.0  1.489502 -0.859425  3.388582  1.489502 -0.859425   \n",
       "29675        0.0      0.0  1.489502 -0.859425  3.388582  1.489502 -0.859425   \n",
       "\n",
       "       var7(t)  \n",
       "6         20.0  \n",
       "7          3.0  \n",
       "8          0.0  \n",
       "9          0.0  \n",
       "10         0.0  \n",
       "...        ...  \n",
       "29671      0.0  \n",
       "29672      0.0  \n",
       "29673      0.0  \n",
       "29674      0.0  \n",
       "29675      0.0  \n",
       "\n",
       "[29670 rows x 49 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reframed = series_to_supervised(scaler_house_data, 6, 1)\n",
    "reframed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_auxHeat = reframed['var7(t)']\n",
    "y_auxHeat = to_categorical(y_auxHeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_auxHeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.argmax(y_auxHeat, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check target variable distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0, 15207],\n",
       "       [    1,   382],\n",
       "       [    2,   391],\n",
       "       [    3,   409],\n",
       "       [    4,   398],\n",
       "       [    5,   389],\n",
       "       [    6,   374],\n",
       "       [    7,   387],\n",
       "       [    8,   377],\n",
       "       [    9,   404],\n",
       "       [   10,   385],\n",
       "       [   11,   392],\n",
       "       [   12,   360],\n",
       "       [   13,   360],\n",
       "       [   14,   394],\n",
       "       [   15,   388],\n",
       "       [   16,   410],\n",
       "       [   17,   420],\n",
       "       [   18,   425],\n",
       "       [   19,   369],\n",
       "       [   20,  7049]], dtype=int64)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(unique, counts) = np.unique(test, return_counts = True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(frequencies)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = reframed.drop(labels = ['var7(t)'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X.iloc[:23680,]\n",
    "y_train = y_auxHeat[:23680,]\n",
    "X_test = X.iloc[23680:]\n",
    "y_test = y_auxHeat[23680:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.argmax(y_train, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "(unique, counts) = np.unique(test, return_counts = True)\n",
    "frequencies = np.asarray((unique, counts)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23680, 48), (5990, 48))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values\n",
    "X_test = X_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(float)\n",
    "X_test = X_test.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 1.4500 - accuracy: 0.6658 - val_loss: 0.8351 - val_accuracy: 0.7982\n",
      "Epoch 2/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 1.0140 - accuracy: 0.7310 - val_loss: 0.7448 - val_accuracy: 0.8052\n",
      "Epoch 3/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.9459 - accuracy: 0.7359 - val_loss: 0.7050 - val_accuracy: 0.8073\n",
      "Epoch 4/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.9153 - accuracy: 0.7380 - val_loss: 0.6978 - val_accuracy: 0.8047\n",
      "Epoch 5/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.9007 - accuracy: 0.7391 - val_loss: 0.6732 - val_accuracy: 0.8092\n",
      "Epoch 6/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8867 - accuracy: 0.7394 - val_loss: 0.6787 - val_accuracy: 0.8085\n",
      "Epoch 7/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8794 - accuracy: 0.7406 - val_loss: 0.6741 - val_accuracy: 0.8088\n",
      "Epoch 8/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8706 - accuracy: 0.7403 - val_loss: 0.6698 - val_accuracy: 0.8127\n",
      "Epoch 9/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8646 - accuracy: 0.7414 - val_loss: 0.6783 - val_accuracy: 0.8104\n",
      "Epoch 10/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8573 - accuracy: 0.7422 - val_loss: 0.6912 - val_accuracy: 0.8092\n",
      "Epoch 11/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8528 - accuracy: 0.7418 - val_loss: 0.6850 - val_accuracy: 0.8105\n",
      "Epoch 12/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8485 - accuracy: 0.7431 - val_loss: 0.6642 - val_accuracy: 0.8110\n",
      "Epoch 13/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8448 - accuracy: 0.7423 - val_loss: 0.6591 - val_accuracy: 0.8107\n",
      "Epoch 14/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8430 - accuracy: 0.7440 - val_loss: 0.6648 - val_accuracy: 0.8117\n",
      "Epoch 15/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8388 - accuracy: 0.7437 - val_loss: 0.6769 - val_accuracy: 0.8117\n",
      "Epoch 16/50\n",
      "370/370 [==============================] - 1s 3ms/step - loss: 0.8371 - accuracy: 0.7444 - val_loss: 0.6624 - val_accuracy: 0.8115\n",
      "Epoch 17/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8342 - accuracy: 0.7443 - val_loss: 0.6713 - val_accuracy: 0.8102\n",
      "Epoch 18/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8303 - accuracy: 0.7435 - val_loss: 0.6654 - val_accuracy: 0.8102\n",
      "Epoch 19/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8294 - accuracy: 0.7454 - val_loss: 0.6797 - val_accuracy: 0.8093\n",
      "Epoch 20/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8263 - accuracy: 0.7448 - val_loss: 0.6848 - val_accuracy: 0.8112\n",
      "Epoch 21/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8289 - accuracy: 0.7443 - val_loss: 0.6840 - val_accuracy: 0.8109\n",
      "Epoch 22/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8250 - accuracy: 0.7454 - val_loss: 0.6641 - val_accuracy: 0.8110\n",
      "Epoch 23/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8249 - accuracy: 0.7454 - val_loss: 0.6594 - val_accuracy: 0.8114\n",
      "Epoch 24/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8241 - accuracy: 0.7451 - val_loss: 0.6758 - val_accuracy: 0.8114\n",
      "Epoch 25/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8203 - accuracy: 0.7457 - val_loss: 0.6673 - val_accuracy: 0.8119\n",
      "Epoch 26/50\n",
      "370/370 [==============================] - 1s 3ms/step - loss: 0.8179 - accuracy: 0.7470 - val_loss: 0.6678 - val_accuracy: 0.8112\n",
      "Epoch 27/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8184 - accuracy: 0.7459 - val_loss: 0.6648 - val_accuracy: 0.8122\n",
      "Epoch 28/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8168 - accuracy: 0.7466 - val_loss: 0.6953 - val_accuracy: 0.8082\n",
      "Epoch 29/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8170 - accuracy: 0.7469 - val_loss: 0.6796 - val_accuracy: 0.8120\n",
      "Epoch 30/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8139 - accuracy: 0.7481 - val_loss: 0.6733 - val_accuracy: 0.8105\n",
      "Epoch 31/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8117 - accuracy: 0.7462 - val_loss: 0.6734 - val_accuracy: 0.8090\n",
      "Epoch 32/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8151 - accuracy: 0.7453 - val_loss: 0.6864 - val_accuracy: 0.8082\n",
      "Epoch 33/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8112 - accuracy: 0.7477 - val_loss: 0.6786 - val_accuracy: 0.8117\n",
      "Epoch 34/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8115 - accuracy: 0.7467 - val_loss: 0.6708 - val_accuracy: 0.8115\n",
      "Epoch 35/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8075 - accuracy: 0.7476 - val_loss: 0.6742 - val_accuracy: 0.8100\n",
      "Epoch 36/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8096 - accuracy: 0.7478 - val_loss: 0.6744 - val_accuracy: 0.8095\n",
      "Epoch 37/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8082 - accuracy: 0.7484 - val_loss: 0.6719 - val_accuracy: 0.8100\n",
      "Epoch 38/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8073 - accuracy: 0.7495 - val_loss: 0.6663 - val_accuracy: 0.8124\n",
      "Epoch 39/50\n",
      "370/370 [==============================] - 1s 3ms/step - loss: 0.8060 - accuracy: 0.7476 - val_loss: 0.6822 - val_accuracy: 0.8098\n",
      "Epoch 40/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8048 - accuracy: 0.7488 - val_loss: 0.6732 - val_accuracy: 0.8102\n",
      "Epoch 41/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8058 - accuracy: 0.7495 - val_loss: 0.6692 - val_accuracy: 0.8092\n",
      "Epoch 42/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8037 - accuracy: 0.7494 - val_loss: 0.6686 - val_accuracy: 0.8114\n",
      "Epoch 43/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8032 - accuracy: 0.7492 - val_loss: 0.6843 - val_accuracy: 0.8104\n",
      "Epoch 44/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8026 - accuracy: 0.7477 - val_loss: 0.6721 - val_accuracy: 0.8109\n",
      "Epoch 45/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8044 - accuracy: 0.7489 - val_loss: 0.6708 - val_accuracy: 0.8112\n",
      "Epoch 46/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8033 - accuracy: 0.7496 - val_loss: 0.6583 - val_accuracy: 0.8124\n",
      "Epoch 47/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8017 - accuracy: 0.7494 - val_loss: 0.6669 - val_accuracy: 0.8130\n",
      "Epoch 48/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.7989 - accuracy: 0.7489 - val_loss: 0.6583 - val_accuracy: 0.8112\n",
      "Epoch 49/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.7992 - accuracy: 0.7493 - val_loss: 0.6683 - val_accuracy: 0.8083\n",
      "Epoch 50/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.7986 - accuracy: 0.7491 - val_loss: 0.6519 - val_accuracy: 0.8117\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units = 24, kernel_initializer = 'uniform', activation = 'relu', input_dim = 48))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 24, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 21, kernel_initializer = 'uniform', activation = 'softmax'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy']) \n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "history = classifier.fit(X_train, y_train, validation_data = (X_test, y_test), batch_size = 64, epochs = 50, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 24)                1176      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 21)                525       \n",
      "=================================================================\n",
      "Total params: 2,301\n",
      "Trainable params: 2,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label = 'train')\n",
    "plt.plot(history.history['val_loss'], label = 'test')\n",
    "plt.legend()\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss/val_loss\")\n",
    "plt.savefig(\"8.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], label = 'train')\n",
    "plt.plot(history.history['val_accuracy'], label = 'test')\n",
    "plt.legend()\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy/val accuracy\")\n",
    "plt.savefig(\"9.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted = np.argmax(y_predicted, axis = 1)\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.argmax(y_test, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468105"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sum = y_test.sum()*15\n",
    "test_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_sum = y_predicted.sum()*15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "474255"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### caculate error percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Percentage in predicted values is : 1.3138077995321562 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Error Percentage in predicted values is : {} %\".format(np.absolute((predicted_sum - test_sum)/test_sum)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error,f1_score,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predicted = classifier.predict(X_train)\n",
    "y_train_predicted = np.argmax(y_train_predicted, axis = 1)\n",
    "y_train = np.argmax(y_train, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7077268514905571"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_train, y_train_predicted, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7512246621621622"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, y_train_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.015920608108108"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_train, y_train_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9158597662771285"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.811686143572621"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7803511927860369"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_predicted, average = 'weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate 60-minutes time-lag datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-12)</th>\n",
       "      <th>var2(t-12)</th>\n",
       "      <th>var3(t-12)</th>\n",
       "      <th>var4(t-12)</th>\n",
       "      <th>var5(t-12)</th>\n",
       "      <th>var6(t-12)</th>\n",
       "      <th>var7(t-12)</th>\n",
       "      <th>var1(t-11)</th>\n",
       "      <th>var2(t-11)</th>\n",
       "      <th>var3(t-11)</th>\n",
       "      <th>...</th>\n",
       "      <th>var5(t-1)</th>\n",
       "      <th>var6(t-1)</th>\n",
       "      <th>var7(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "      <th>var2(t)</th>\n",
       "      <th>var3(t)</th>\n",
       "      <th>var4(t)</th>\n",
       "      <th>var5(t)</th>\n",
       "      <th>var6(t)</th>\n",
       "      <th>var7(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.632689</td>\n",
       "      <td>1.422976</td>\n",
       "      <td>1.387394</td>\n",
       "      <td>2.632689</td>\n",
       "      <td>1.422976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346315</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.225278</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.462204</td>\n",
       "      <td>-0.225278</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>1.387394</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.346315</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225278</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.225278</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.462204</td>\n",
       "      <td>-0.225278</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.346315</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>1.424799</td>\n",
       "      <td>0.346315</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225278</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.443502</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.424799</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.368465</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.443502</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.368465</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.424799</td>\n",
       "      <td>-1.368465</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.346315</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.443502</td>\n",
       "      <td>0.346315</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29671</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>3.145447</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>...</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.295068</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29672</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>3.238960</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>...</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.388582</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29673</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>3.238960</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>...</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.388582</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29674</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>3.238960</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>...</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.388582</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29675</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>3.238960</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>...</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.388582</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29664 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       var1(t-12)  var2(t-12)  var3(t-12)  var4(t-12)  var5(t-12)  var6(t-12)  \\\n",
       "12            0.0    2.632689    1.422976    1.387394    2.632689    1.422976   \n",
       "13            0.0    1.489502    1.930176    1.387394    1.489502    1.930176   \n",
       "14            0.0    0.346315    1.930176    1.424799    0.346315    1.930176   \n",
       "15            0.0   -0.796872    2.183776    1.424799   -0.796872    2.183776   \n",
       "16            0.0   -1.368465    2.183776    1.424799   -1.368465    2.183776   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "29671         0.0    3.204282   -0.098625    3.145447    3.204282   -0.098625   \n",
       "29672         0.0    3.204282   -0.098625    3.238960    3.204282   -0.098625   \n",
       "29673         0.0    3.204282   -0.098625    3.238960    3.204282   -0.098625   \n",
       "29674         0.0    3.204282   -0.098625    3.238960    3.204282   -0.098625   \n",
       "29675         0.0    3.204282   -0.098625    3.238960    3.204282   -0.098625   \n",
       "\n",
       "       var7(t-12)  var1(t-11)  var2(t-11)  var3(t-11)  ...  var5(t-1)  \\\n",
       "12            0.0         0.0    1.489502    1.930176  ...   0.346315   \n",
       "13            0.0         0.0    0.346315    1.930176  ...  -0.225278   \n",
       "14            0.0         0.0   -0.796872    2.183776  ...  -0.225278   \n",
       "15            9.0         0.0   -1.368465    2.183776  ...  -0.796872   \n",
       "16           20.0         0.0   -0.796872    2.183776  ...  -0.796872   \n",
       "...           ...         ...         ...         ...  ...        ...   \n",
       "29671         0.0         0.0    3.204282   -0.098625  ...   2.061095   \n",
       "29672         0.0         0.0    3.204282   -0.098625  ...   2.061095   \n",
       "29673         0.0         0.0    3.204282   -0.098625  ...   1.489502   \n",
       "29674         0.0         0.0    3.204282   -0.098625  ...   1.489502   \n",
       "29675         0.0         0.0    3.204282   -0.098625  ...   1.489502   \n",
       "\n",
       "       var6(t-1)  var7(t-1)  var1(t)   var2(t)   var3(t)   var4(t)   var5(t)  \\\n",
       "12      2.183776        0.0      0.0 -0.225278  2.183776  1.462204 -0.225278   \n",
       "13      2.183776        0.0      0.0 -0.225278  2.183776  1.462204 -0.225278   \n",
       "14      2.183776        0.0      0.0 -0.796872  2.183776  1.443502 -0.796872   \n",
       "15      2.183776       17.0      0.0 -0.796872  2.183776  1.443502 -0.796872   \n",
       "16      2.183776       20.0      0.0  0.346315  2.183776  1.443502  0.346315   \n",
       "...          ...        ...      ...       ...       ...       ...       ...   \n",
       "29671  -0.859425        0.0      0.0  2.061095 -0.859425  3.295068  2.061095   \n",
       "29672  -0.859425        0.0      0.0  1.489502 -0.859425  3.388582  1.489502   \n",
       "29673  -0.859425        0.0      0.0  1.489502 -0.859425  3.388582  1.489502   \n",
       "29674  -0.859425        0.0      0.0  1.489502 -0.859425  3.388582  1.489502   \n",
       "29675  -0.859425        0.0      0.0  1.489502 -0.859425  3.388582  1.489502   \n",
       "\n",
       "        var6(t)  var7(t)  \n",
       "12     2.183776      0.0  \n",
       "13     2.183776      0.0  \n",
       "14     2.183776     17.0  \n",
       "15     2.183776     20.0  \n",
       "16     2.183776      6.0  \n",
       "...         ...      ...  \n",
       "29671 -0.859425      0.0  \n",
       "29672 -0.859425      0.0  \n",
       "29673 -0.859425      0.0  \n",
       "29674 -0.859425      0.0  \n",
       "29675 -0.859425      0.0  \n",
       "\n",
       "[29664 rows x 91 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reframed_2 = series_to_supervised(scaler_house_data, 12, 1)\n",
    "reframed_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29670, 48)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_auxHeat = reframed_2['var7(t)']\n",
    "y_auxHeat = to_categorical(y_auxHeat)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = reframed_2.drop(labels = ['var7(t)'], axis = 1)\n",
    "\n",
    "X_train = X.iloc[:23680,]\n",
    "y_train = y_auxHeat[:23680,]\n",
    "X_test = X.iloc[23680:]\n",
    "y_test = y_auxHeat[23680:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23731, 90)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train = X_train.astype(float)\n",
    "# X_test = X_test.astype(float)\n",
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 1.4354 - accuracy: 0.6723 - val_loss: 0.8406 - val_accuracy: 0.7971\n",
      "Epoch 2/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 1.0244 - accuracy: 0.7304 - val_loss: 0.7490 - val_accuracy: 0.8038\n",
      "Epoch 3/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.9473 - accuracy: 0.7366 - val_loss: 0.7059 - val_accuracy: 0.8072\n",
      "Epoch 4/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.9089 - accuracy: 0.7385 - val_loss: 0.6935 - val_accuracy: 0.8072\n",
      "Epoch 5/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8899 - accuracy: 0.7396 - val_loss: 0.6813 - val_accuracy: 0.8078\n",
      "Epoch 6/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8785 - accuracy: 0.7416 - val_loss: 0.6834 - val_accuracy: 0.8088\n",
      "Epoch 7/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8668 - accuracy: 0.7424 - val_loss: 0.6779 - val_accuracy: 0.8097\n",
      "Epoch 8/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8602 - accuracy: 0.7422 - val_loss: 0.6632 - val_accuracy: 0.8092\n",
      "Epoch 9/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8564 - accuracy: 0.7417 - val_loss: 0.6687 - val_accuracy: 0.8103\n",
      "Epoch 10/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8498 - accuracy: 0.7441 - val_loss: 0.6733 - val_accuracy: 0.8100\n",
      "Epoch 11/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8492 - accuracy: 0.7433 - val_loss: 0.6627 - val_accuracy: 0.8087\n",
      "Epoch 12/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8445 - accuracy: 0.7443 - val_loss: 0.6615 - val_accuracy: 0.8095\n",
      "Epoch 13/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8405 - accuracy: 0.7430 - val_loss: 0.6710 - val_accuracy: 0.8077\n",
      "Epoch 14/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8368 - accuracy: 0.7445 - val_loss: 0.6682 - val_accuracy: 0.8088\n",
      "Epoch 15/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8370 - accuracy: 0.7446 - val_loss: 0.6570 - val_accuracy: 0.8088\n",
      "Epoch 16/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8322 - accuracy: 0.7448 - val_loss: 0.6654 - val_accuracy: 0.8083\n",
      "Epoch 17/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8300 - accuracy: 0.7462 - val_loss: 0.6511 - val_accuracy: 0.8090\n",
      "Epoch 18/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8279 - accuracy: 0.7440 - val_loss: 0.6581 - val_accuracy: 0.8107\n",
      "Epoch 19/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8244 - accuracy: 0.7469 - val_loss: 0.6591 - val_accuracy: 0.8112\n",
      "Epoch 20/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8248 - accuracy: 0.7450 - val_loss: 0.6503 - val_accuracy: 0.8108\n",
      "Epoch 21/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8236 - accuracy: 0.7453 - val_loss: 0.6622 - val_accuracy: 0.8105\n",
      "Epoch 22/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8206 - accuracy: 0.7462 - val_loss: 0.6581 - val_accuracy: 0.8085\n",
      "Epoch 23/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8166 - accuracy: 0.7465 - val_loss: 0.6486 - val_accuracy: 0.8110\n",
      "Epoch 24/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8165 - accuracy: 0.7475 - val_loss: 0.6489 - val_accuracy: 0.8095\n",
      "Epoch 25/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8123 - accuracy: 0.7480 - val_loss: 0.6450 - val_accuracy: 0.8107\n",
      "Epoch 26/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8114 - accuracy: 0.7466 - val_loss: 0.6454 - val_accuracy: 0.8120\n",
      "Epoch 27/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8084 - accuracy: 0.7472 - val_loss: 0.6476 - val_accuracy: 0.8098\n",
      "Epoch 28/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8087 - accuracy: 0.7489 - val_loss: 0.6378 - val_accuracy: 0.8113\n",
      "Epoch 29/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8089 - accuracy: 0.7482 - val_loss: 0.6488 - val_accuracy: 0.8095\n",
      "Epoch 30/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8044 - accuracy: 0.7485 - val_loss: 0.6509 - val_accuracy: 0.8108\n",
      "Epoch 31/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8049 - accuracy: 0.7480 - val_loss: 0.6441 - val_accuracy: 0.8113\n",
      "Epoch 32/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8032 - accuracy: 0.7482 - val_loss: 0.6524 - val_accuracy: 0.8105\n",
      "Epoch 33/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8025 - accuracy: 0.7486 - val_loss: 0.6526 - val_accuracy: 0.8118\n",
      "Epoch 34/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8006 - accuracy: 0.7492 - val_loss: 0.6522 - val_accuracy: 0.8108\n",
      "Epoch 35/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8008 - accuracy: 0.7475 - val_loss: 0.6418 - val_accuracy: 0.8103\n",
      "Epoch 36/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.8010 - accuracy: 0.7497 - val_loss: 0.6419 - val_accuracy: 0.8112\n",
      "Epoch 37/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.7996 - accuracy: 0.7488 - val_loss: 0.6421 - val_accuracy: 0.8125\n",
      "Epoch 38/50\n",
      "370/370 [==============================] - 1s 3ms/step - loss: 0.7994 - accuracy: 0.7496 - val_loss: 0.6495 - val_accuracy: 0.8097\n",
      "Epoch 39/50\n",
      "370/370 [==============================] - 1s 3ms/step - loss: 0.7980 - accuracy: 0.7500 - val_loss: 0.6619 - val_accuracy: 0.8115\n",
      "Epoch 40/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.7984 - accuracy: 0.7495 - val_loss: 0.6604 - val_accuracy: 0.8087\n",
      "Epoch 41/50\n",
      "370/370 [==============================] - 1s 3ms/step - loss: 0.7961 - accuracy: 0.7495 - val_loss: 0.6487 - val_accuracy: 0.8118\n",
      "Epoch 42/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.7974 - accuracy: 0.7492 - val_loss: 0.6603 - val_accuracy: 0.8085\n",
      "Epoch 43/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.7942 - accuracy: 0.7489 - val_loss: 0.6491 - val_accuracy: 0.8108\n",
      "Epoch 44/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.7938 - accuracy: 0.7514 - val_loss: 0.6559 - val_accuracy: 0.8102\n",
      "Epoch 45/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.7950 - accuracy: 0.7495 - val_loss: 0.6446 - val_accuracy: 0.8087\n",
      "Epoch 46/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.7936 - accuracy: 0.7496 - val_loss: 0.6401 - val_accuracy: 0.8107\n",
      "Epoch 47/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.7904 - accuracy: 0.7504 - val_loss: 0.6422 - val_accuracy: 0.8107\n",
      "Epoch 48/50\n",
      "370/370 [==============================] - 1s 3ms/step - loss: 0.7915 - accuracy: 0.7506 - val_loss: 0.6523 - val_accuracy: 0.8075\n",
      "Epoch 49/50\n",
      "370/370 [==============================] - 1s 3ms/step - loss: 0.7899 - accuracy: 0.7500 - val_loss: 0.6411 - val_accuracy: 0.8118\n",
      "Epoch 50/50\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.7897 - accuracy: 0.7520 - val_loss: 0.6691 - val_accuracy: 0.8097\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units = 24, kernel_initializer = 'uniform', activation = 'relu', input_dim = 90))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 24, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 21, kernel_initializer = 'uniform', activation = 'softmax'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy']) \n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "history = classifier.fit(X_train, y_train, validation_data = (X_test, y_test), batch_size = 64, epochs = 50, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 24)                1176      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 21)                525       \n",
      "=================================================================\n",
      "Total params: 2,301\n",
      "Trainable params: 2,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label = 'train')\n",
    "plt.plot(history.history['val_loss'], label = 'test')\n",
    "plt.legend()\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss/val_loss\")\n",
    "plt.savefig(\"10.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEGCAYAAACQO2mwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deXxc1ZXg8d/RvkvW4k2ysQzG2IAXUIzBrCGAze6EpIGQpCGJwwQCyQQ6kO6EkBkyTNNNEzokhCGGpMMSmiVAMMasJqy2bAxewUZeJMu2bO17larO/HGfrLKskqsslSRL5/v51Ef1tqrzSlXvvHvvu/eJqmKMMcb0JG6wAzDGGDN0WZIwxhgTliUJY4wxYVmSMMYYE5YlCWOMMWElDHYA/Sk/P18nTZo02GEYY8wRZdWqVftUtaCnZcMqSUyaNInS0tLBDsMYY44oIrI93DKrbjLGGBOWJQljjDFhWZIwxhgTliUJY4wxYVmSMMYYE5YlCWOMMWFZkjDGGBOWJQljzODxt8Jnr0DpI+65GXKGVWc6Y4a0pip3QNz8CqRkw7wfQv6UwY4qPF8zlL0FO1dBwTSYMAdyJoJI3163qQo+WwqfLoXP34AOLzm8959w6f0w6fRDv0YwAHHxkb/n1rdh32dw8rXRbTeUqMLqP7nvzrRLIW5gzvEtSZgjT1s91FdA/U5o8P42V0FyFqSOgrRcSMuDVO9vWq57npB0+O/ZvA/KV8BRp0FqTmTbqELVRvh0iTsoVpQCCllF0FoDHz0GJ3wFzrwVRh938PbBAGx/D9Y9A7s/geMuhpO+Cen5kcW7bzM07HSfVcPOrs8rLgHGnghjZ7jHmOMhKc1t17jbO4C/7BJER9uBr5s5ziWLCae4R97RkJITPnEEg1C7FXZ9DLvXuoP1zlXuc8ieALOvgakL3PRLP4ZHL3IH8vPudAfD7p9n+QpY+f9gw/MwcS5cfJ+LIZwOH7zxS5eAADa+CF9+GDJ6HIHiQE3edyox5dDrxpoqvPpzeO9+N11wnPveHL8w5klPhtOd6UpKSnTEDssR8LuD0O61kJIVcoAc5f4mZ/X9DHCwBDrg89fhoz+7A1d7w4HLJc7to68Z/C3hXycp00sg3mdTNAe+8O3eD7odPljxe1h+D7TXQ3wSHH0unPBld3BLzjxw/eZ9sHW5i/Pzt6B+h5s//iS3/tQFMOYEt977v4EV/8/FfPzl7kdfMA0qVrrEsOGv0LQHEtNciWPXx+79j18IX/guFJV0/U9VoWqDS0ifLoWd3X4HydmQXQhZhe7Av/sTl2w7P7+8Ke5guOtjNy9nIky90MU74RSXcMo/7HrU7eh67cT0rtfOLnRJsKXafRf3rANfk1svLsElpdDPIfQ76WuBN++CD34LGWPgonvhuAvd/LX/7ZLD7rXuu3zcRbDpJQj44JyfwtwbIL7bOe++zfDMt90+feE7Lhkuvd2dSFyx2CX8nuz9FF7/JWz6GyCQM8F9PvlTIO8Y9ygqOfh/35OKVe7Avv1d9z/qLjkTzvslTL80/GuowrJ/cd+Xkm/DpHnu+7h3o4vrzFvdyUb3/Y+CiKxS1ZIel1mSGILaGtyPa/da9yPIKoTsIvfIGOPOHDrPUsveco/t73b9GHsSn+TOvKZeCMfOh9zi8OsG/O6HkpwJo47q772L3L7NLjF8/CQ07XYH9mmXQO7RXQej7ELIGNv1A/G3QkuNO1NvqXEHq/3PO+dXu7PE3Z9AQirMuhpOveHAM1JVdxB69WdQUwbHnAdzvuvOhNc/587ME1Jgyvnuse8zKHvT/c/AHZQnnQ5TznOfd9a4nvexuRo+eAA+fAh8jZA+2pWK4pPdtid8BY69AJLSoWoTrHzYfR6+Rhg3E2Z9Hao/d2f+nQmp8GQ4dgEUzu76jLof0FShvhx2feJi7kwaR3/RfUdGT+v9pKJhl0tEtdu9kkpnyW6nS2xJGS4JjJvRVWopOC6ys/Kdq+CFm9xvYNIZXbGNPh7mfAdO/BokZ0BDJbx0C3z6EoybBZf+p3s/Vfe9efmfICEZLnvAJRVw+/rUt6B2G5z7czjtpq5qm7pyeOtu+Phxl/hOWeR+N/s2Q/Vm2LcF/M1u3c7//QlfcX87S2LgSk+bX3Gll+3vuu/CtIvdNt1VrHT7d/I/wgW/cv/n7v+npbfDh7+DOd+DBf/X/V+CQdj4Aiz/V6haD7mT4YxbYOZVh1UNZUliKGutdSWAXWu6frC1W8OvH5fgivwd7e5gAu7MZvLZ7lFY4s5MW2vdwbDzQNlQ6c7G925y2xRMc2dzx84HDbov6u5PXAx7N7nkBHDMl9xZ2JTzey/WNuyCytUQ7OhhoUB6gTtYZY6D+MSDV/G3uoNd549x8zKoWAES7w6Ws6+BKRf0rcqou6pN7uzsk7+4xDjtYjjtZncgW3o7bPs75E91P94pX+raLhh0Z9Prn4X1f3X/h7hEl4QnnwWTz3EHrWjO7Fpq4MMHXXLuPINPyep53fZGF/OKh93ZZEKKe8+p893/M3Ns3z6Xvurwue9pX+rMA3549z5X0pp0uvsOTjz14MSl6kpcS251n+G8m6Bmq5tXfCYs/D1kjT9wm7YGeOEHbp1j58P5d0HpYldSAZizCE7/n5Ced/B7Ne5yJ2efLe363yemu//XCV/uKiHu+8xVp839Ppz0jfCljg6fKz29+2tXUvnKH1yi63y/Jbe6uOZ+330Pu+9/MOiS5PL/6054vr3ssGoMLEkMFaruQFj+gVdsX9F10AYYVRxy5jXT/U1M6TpDC61bBig+A4rPcsXhSNWUueqIT5e4+m4NdC1Lyz/wzK/6c1j1iPth5EyEkutg9jfdj6etwZ0ldZZkQvejNxLnSkOdVRPtjS4p1JcDId/Fgmkw6yqYcSVkjol8/w5H425Y8ZA7S++sgknNddUYJ1/b+8E+GHAHjdzig88CY02162AUeiY7ErXUuCqZNY+5BPXFf3EJP1yiUnUJ6JWfQtDvvpczr4azb4v89xQMwLZ33MnChufdiRm43868m2H6ZT2fEPWk7C149nuupPulO+GU78GSW1zyOu0HcN7/6v3gr+o+g+6JLUKWJAZawO/OZqo3H1hU3fdp1xcpJdtr/PMaAcfNCn/mGCutte7LmZjmEkPmuIO/iAG/q3ZZ+bA7s45PhoKpsGe9SzAJqa5ud/LZ7kyvp4NVMODOuPYnu5AG56R0r653CuQf01XnO9AHXID2JneQaat3VUupowY+BtM3Oz5w352xJ0a2/s5V8MlT7mSgp4sHIhXwu6rIhBT3ezic9r/manj+BvjsZXdSVrfDXQH3pV/EvD3RkkR/a62FF3/oipw9CfhcFU6n9IKuhq/Ck11SyD92wC5h6zdVG12yqNroEsLks12SS0ge7MiMGR5U3W/s1Tvg1O/DOf88IBecWJLoT5UfuYavhp3ucsSe6hrjk10jaN4U9zfSSyaNMQai7wfSR70lCesnEanODP/KT90VKNcuhQlfGOyojDHD0RDq8GdJIhLtjfDize7a9Snnuysm0nIHOypjjIk5SxKHsmc9PPVNd1XQuXe4hqQjrS3BGGMOkyWJ3jTvgz9e6i6p+9aLkY0pY4wxw4glid68/E/ucsjvvQ1jpg92NMYYM+Cs3iScjX9zbRBn/cQShDFmxIp5khCR+SLyqYhsEZHbelieLSIvisjHIrJeRK6NdNuYaamBv/3Idcg5/YcD9rbGGDPUxDRJiEg88ACwAJgOXCUi3U/LbwA2qOpM4Gzg30UkKcJtY+OVn7ru8Zf9NvJu9cYYMwzFuiQxB9iiqmWq6gOeBC7rto4CmSIiQAZQA3REuG3/++wV+PgJN8BX50BbxhgzQsU6SRQC5SHTFd68UL8BpgGVwFrgZlUNRrgtIrJIREpFpHTv3r19i7at3g23UTANzrylb69ljDHDQKyTRE+DjnQfB+QCYA0wHpgF/EZEsiLcFlV9SFVLVLWkoCCCu0315pV/dvctuPwBG4/IGGOIfZKoAELH3S3ClRhCXQs8q84WYCtwXITb9p/P34CP/svdhKTw5Ji9jTHGHElinSRWAlNEpFhEkoArgRe6rbMDOBdARMYAU4GyCLftH+2N7k5YeVPg7Ntj8hbGGHMkimlnOlXtEJEbgVeAeGCxqq4Xkeu95Q8C/wt4VETW4qqYfqKq+wB62jYmgXb43K0gT7tpaNz03BhjhggbKtwYY0a43oYKtx7XxhhjwrIkYYwxJixLEsYYY8KyJGGMMSYsSxLGGGPCsiRhjDEmLEsSxhhjwrIkYYwxJixLEsYYY8KyJGGMMSYsSxLGGGPCsiRhjDEmLEsSxhhjwrIkYYwxJixLEsYYY8KyJGGMMSYsSxLGGGPCsiRhjDEmLEsSxhhjwop5khCR+SLyqYhsEZHbelh+q4is8R7rRCQgIrnesh+JyHpv/hMikhLreI0xxnSJaZIQkXjgAWABMB24SkSmh66jqveo6ixVnQXcDixX1RoRKQRuAkpU9QQgHrgylvEaY4w5UMRJovPsPkpzgC2qWqaqPuBJ4LJe1r8KeCJkOgFIFZEEIA2oPIwYjDHGHKZoShIfish/i8iFIiIRblMIlIdMV3jzDiIiacB84BkAVd0J/BuwA9gF1Kvqsh62WyQipSJSunfv3sj3xhhjzCFFkySOBR4CvgFsEZFficixh9imp2SiYda9BHhXVWsARGQUrtRRDIwH0kXkmoNeTPUhVS1R1ZKCgoIId8UYY0wkIk4S6ryqqlcB3wG+BawQkeUicmqYzSqACSHTRYSvMrqSA6uavgRsVdW9quoHngVOizReY4wxfRdNm0SeiNwsIqXALcAPgHzgx8DjYTZbCUwRkWIRScIlghd6eO1s4Czg+ZDZO4C5IpLmVW+dC2yMNF5jjDF9lxDFuu8D/wVcrqoVIfNLReTBnjZQ1Q4RuRF4BXd10mJVXS8i13vLO7dbCCxT1eaQbT8UkaeB1UAH8BGuussYY8wAEdVwTQTdVhQRjXTlQVJSUqKlpaWDHYYxxhxRRGSVqpb0tCyahutlIpIT8qKjROSVPkdnjDFmyIomSRSoal3nhKrWAqP7PyRjjDFDRTRJIiAiEzsnROQowl/OaowxZhiIpuH6n4F3RGS5N30msKj/QzLGGDNURJwkVHWpiJwEzMV1kvuRqu6LWWTGGGMGXTQlCYAAUAWkANNFBFV9u//DMsYYMxREnCRE5DvAzbhe02twJYr3gS/GJjRjjDGDLZqG65uBLwDbVfUcYDZgI+oZY8wwFk2SaFPVNgARSVbVTcDU2IRljDFmKIimTaLC60z3V+BVEanF7u9gjDHDWjRXNy30nv5CRN4EsoGlMYnKGGPMkBBRkhCROOAT7zaiqOryQ2xijDFmGIioTUJVg8DHoT2ujTHGDH/RtEmMA9aLyAogdEjvS/s9KmOMMUNCNEnizphFYYwxZkiKpuHa2iGMMWaEiabHdSNdo74mAYlAs6pmxSIwY4wxgy+akkRm6LSIXA7M6feIjDHGDBnR9Lg+gKr+FRu3yRhjhrVoqpu+HDIZB5QQwU2HRGQ+8GsgHnhYVe/utvxW4Osh8UzD3QWvxuvh/TBwgvde16nq+5HGbIwxpm+iubrpkpDnHcA24LLeNhCReOAB4DygAlgpIi+o6obOdVT1HuAeb/1LcPepqPEW/xpYqqpXiEgSkBZFvMYYY/oomjaJaw/j9ecAW1S1DEBEnsQllg1h1r8KeMJbNwt397t/9N7fB/gOIwZjjDGHKeI2CRH5o1f90zk9SkQWH2KzQqA8ZLrCm9fT66cB84FnvFmTcUORPyIiH4nIwyKS3sN2i0SkVERK9+61kcuNMaY/RdNwPUNV6zonVLUWd0+J3kgP88K1Y1wCvBtS1ZQAnAT8TlVn43p533bQi6k+pKolqlpSUFBwqH0wxhgThWiSRJyIjOqcEJFcDl1dVQFMCJkuIvzw4lfiVTWFbFuhqh9600/jkoYxxpgBEk3D9b8D74nI07jSwNeAuw6xzUpgiogUAztxieDq7iuJSDZwFnBN5zxV3S0i5SIyVVU/Bc4lfFuGMcaYGIim4fpPIlKK6xshwJdDr1IKs02HiNwIvIK7BHaxqq4Xkeu95Q96qy4Elqlqc7eX+AHwmHdlUxlwOI3nxhhjDpOoHrKrg1tRZC6wXlUbvelMYHpIddCgKykp0dLS0sEOwxhjjigiskpVS3paFk2bxO+AppDpZm+eMcaYYSqaJCEaUuzwbkQUTZuGMcaYI0w0SaJMRG4SkUTvcTOuncAYY8wwFU2SuB44DXeVUgVwCrAoFkEZY4wZGqK5uqkKdwmrMcaYIaSqsY3ymhZOPiq33187mlFgU4BvA8cDKZ3zVfW6fo/KGGOGIFVlTXkd+RnJTMgd/PFGt1c38/u3y3h6VQVjs1J465aziYvraaCLwxdNw/N/AZuAC4Bf4ob33tiv0RhjzBC1cVcD//ulDby7pZo4gQuOH8u3Ty/m5KNGIXJ4B2ZVxR9QWv0B2vwBWn0BWv0B2juCjMlKZkxmSo8H/fWV9Ty4vIyXPqkkIS6OK0qKWHTG5H5PEBBdkjhGVb8qIpep6h9F5HFcJzljjImpYFCpbfFR1djO3sZ29jW1k56cwNisFMZmp5CfkUx8DA6Q4Kpy7l32GU+VlpOVmsjPLp7OvqZ2Hv9wBy+v283MomyuO72YC08cR2J8+GbehjY/GyobWF/ZwPrKejZUNvD53ib8gfB91VIS45iUl+4e+ekUjkrltQ17WP7ZXjKSE/jumZP59rxiRmelhH2NvoqmM90KVZ0jIm8D3wd2AytUdXLMoouSdaYzJvbaOwKU17Sys66VEwuzyU1POuQ2739ezX2vfca26mZOLMxmZlEOMyfkMLMoh+y0xP3r1Tb72LirgY27G9m4q4HNexrZ0+CSQkcw/LEqPk4oyEhmTHYKWSkJiAhxAvEiiAjxcZAYH0dmSiKZKQlkJie4v970qPQkRqUlMSotkZy0JOLjhDZ/gD+8s5XfvrmF9o4g3zptEjd9ccr+eFt8HTyzeiePvLOVsn3NjM1K4dSj8/AFgvg63KO9I4CvI8i+Jh87alr2x1uQmczx47OYOiaTrNREUhLjSU2MJzUpjtTEeBLi4tjV0Ma2fc3uUd3MjpoW/AElLz2J604v5pq5R5GdmhjuI4lKb53pokkS38EN430i8CiQAfxMVX/fL1H2A0sSZrgpr2nh2dU7+aCsmrHZKd4ZZRrF+e7MMivFHSSCQaXJ10FTWweNbR00tftJT05gfE7q/nUiEfDO2KubfFQ3tbOv2UdVQxvbq1vYVt3M1n3NVNa10nm8ToqPY8GJY7l6zkTmFOceVO2yclsN9y77jPfLqhmTlczcyXms21nP53u7RuApzk+nMCeVzVUuIXTKz0hm6tgMxmenUpCZzOjMZAoyUxidlUxeehLN7QH2NLSxu6HN/a13z5vbOwgqBFUJqhIIumqd9o4gjW0dNLb5ae8Ihv0MRNj/mdW3+jlv+hh+euE0ivMPulPB/s/+rc+qeOTdbZTtbSY5MY7khHiSEuJIjo8jOTGOrNREpo/LYvr4LI4fn8XozOjP/ANBZVd9K/kZyaQkxke9fW/6JUlE8CbfUtU/9suLHSZLEmYwNbd3sKu+lcq6NirrWtnT0E5xQTpnHVsQ1Rlfc3sHL6/bzdOryvmgrAYRmD4ui9pmH5X1bQesm5OWSCDgEkS4n3JGcgLjc1IYl53K+JxUUhPjaWzze8mkY//zhjY/Nc0+ejphz0xJcIkpL51JeWlMyk9ndGYKr27YzbMf7aSxrYNjRmdw1ZyJfOWkQsr2NfMfr37G3zfvIz8jme+ffTRXnzJx/8Gtoc3P2op61pTX8XF5Hbvq2zhmdAbTxmVy3Ngspo3LoiAzOeLPLFq+juD+fW9o7aC2xecezT5qWvzUNvto8QX4ysmFnHZ0fsziGCoGKkmsVtVBHcrbkoQZCMGgUravidU76vhoRy2fVNRTUdtKfau/x/UT4oS5k/P40rTRfGn6GIpGpR3wWlWN7Wz3qhM+KKvh5XW7aPEFmJSXxhUnF7HwpCIKc1IBaPMH2F7dwlavCqK8poXE+DiyQqpOMlMSSU+Op6m9g111beysaz0gebV3BMlMSSAjpMolIyWBrJRECjKSyMtIJi8jibz0ZPIzksjPSCYnLTFs42yLr4O/fbKLxz7cwcfldSTGy/5qkevPOppr5h5FalL/nvma/jVQSeIj7+ZAg8aSxMjT5g9w32ubeeyD7Zx6dB7Xzitm7uSDqz2iEQgq9a3urLquxef99bOzrpWPyutYs6OWhrYOALJSEpg5IYdJeemMz0kNOWNPoSAzmXU761m2YQ+vbdizv4pl2rgsxmWnsL26mfLaVnwhVR8ZyQlcPGMcV5xc1KerZgbL+sp6nl29k9GZyVwz9yjSk23kniOBlSTMkNcRCPJReR2vb6zijU17iBPh26cXc/nswrBXjKzYWsNtz3xC2b5mzplawJryOmpb/Bw3NpNr503islmFh6y7bWjzs25nPWsr6lm7s551O+vZXtPSY9VNnMCxYzKZPXEUJ03MYfbEUUzOT4/4ssOyvU28tnEPr22ooqHNz1F5aUzMTWNiXjoTc9M4KjeNwlGpvV4hY0wsWEnCDCmqSps/SG2Lj9LttbyxcQ9vfbaXuhY/CXHCKZNzqWn2s3FXA4U5qVx/1mS+WjJh/wG/qb2Df126iT+9v50Juanc/eUZzDsmnzZ/gOfX7OSRd7exaXcjo9IS+YcvTKRwVOr+evfGNv/+xt2yfa4htlNhTiozirKZMjqD3PSk/Ve85KYnkZOWGJMGQ2OGgoFKEr9R1Rv75cUOkyWJ8JraO0hLjI/orLfF18HH5fUkxAuzJ+SQcIgz28Y2P8vW7+HdLftoDwQJBg+8qiSgSmNbB/Wt/v2P0CqW3PQkzpk6mnOnjeb0KflkpSSiqrz5aRW/eWMLq3e4Hq7fPaOY4vx07nxxA5X1rfzjaZO49YKppCUdWKWhqnxQVsOj723l1Q179jfEJsRJVx18cgITclOZUZTDCYXZEV/Kacxw1KckISL/s7flqnpvH2LrV5YkDrarvpV7l33G06srSEuMZ9o4dwne8eOzmT4+i2PHZLoz+m21lG6vYdX2WtZXNhDwjqzZqYmcdWwB504bzVnHFpCT5g6krb4Ab2yq4sWPK3nj0yp8HUHyM5LJTk0gTsQ94rxr1eOEjOQEslMT3SMtcf/z48ZmMWtCTtiOUJ0H/N++tYW/b94HwNEF6fzrFTMiGqemptlHRzBIVkoiyQlxR1wdvzEDoa9J4o7elqvqnX2IrV9ZkujS0Obnwbc+5w/vbEUVrpwzAQHWVzawYVcDLb4A4A7gnQkhJTGOmUU5lEwaRclRubT5A7y+qYo3N1VR3ewjTqDkqFwKspJ5c1MVLb4ABZnJXHTiOC6ZOZ6TJubE9CC8pryOzXsauWTmeKv2MaYfDUh101AwHJJEQ5ufT73epht3NdLc3kF6cgLpSfGkhfzNTk1kTGYyY7NTGJOVsv+g6esI8tiH27n/9c3Utvi5fNZ4fnz+1AMGIwsGlW3VzayvbGDjrgZy05MomZTL9HFZJCUcXLUUDCofV9TxxqYqXt9YxZ6GNs6bPoZLZ47nlMl5MRsOwRgzMPqrx/VhjQIrIvOBXwPxwMOqene35bfiBgsEN5bUNKBAVWu85fFAKbBTVS/u7b2OxCRR0+zjLyvLWbW9lk27G6iobd2/LCctkZzURJp9AVraO2j2zv57kpOWyNisFBrbOthZ18q8Y/K4fcE0TijMHojdMMYcwXpLEjEdBdY7wD8AnIe7UdFKEXlBVTd0rqOq9wD3eOtfAvyoM0F4bvbeJyuKWIe8HdUtPPxOGU+VltPmD3J0QTqzJuRw1ZyJTBuXybRxWYzNSjmg+iYYdKNFNvs6qG/xs9sbiqBzaILd9e34A0F+9eUTOXNKvtW/G2P6LNajwM4BtqhqGYCIPAlcBmwIs/5VwBOdEyJSBFwE3AX02oB+pFhbUc/v3/6cJWt3ER8nLJxdyHfPmMyUMZmH3DYuTlzVU3ICozNTItrGGGP6Ipok0TnmQJ2InIAbBXbSIbYpBMpDpjtve3oQEUkD5gOhl9HeB/wTEPZoKCKL8G6jOnHixEOEM/ACQWXjrgY+KKvmtY17+KCshkxviN/r5hUzJoZD/BpjTF9FkyQeEpFRwM+AF/BGgT3ENj3Vd4RrBLkEeDekLeJioEpVV4nI2eHeQFUfAh4C1yZxiHhiLhhU1le6pPDh1mo+3FpDozeEQ3F+Oj+98DiumjORzChG5jTGmMESTZJ4RFUDwHIg0ntIVAATQqaLgMow615JSFUTMA+4VEQuxDWUZ4nIn1X1mihiHjCNbX6eWVXBnz7YTpk3Rs/k/HQunjGeuZNzOaU4j7HZVmowxhxZokkSW0VkKfAX4A2N7LKolcAUESkGduISwdXdVxKRbOAsYH8CUNXbgdu95WcDtwzFBLF5TyN/en87z66uoNkXYNaEHP71ihmcdWyBVSUZY4540SSJqbgqoRuAxSLyIvCkqr4TbgNV7RCRG3EN3PHAYlVdLyLXe8sf9FZdCCxT1eYwLzXkfFJRx90vb+K9z6tJSojjkhnj+eapRzFzQs5gh2aMMf3msDrTeW0Tvwa+rqpDpuvrQPWTqG5q54L7/o4IXDtvEv9QMoG8jNjdIMUYY2Kpv/pJICJnAf8ALMBVJX2t7+EdWVSVnzyzloZWP8/fOI9p44ZV9w1jjDlAxElCRLYCa4CngFuPpKqh/vTkynJe27iHf7lomiUIY8ywd8gkISJXAcuAmaraEPuQhq6t+5r55YsbmHdMHtfNKx7scIwxJuYiKUkcBfw3kCgirwMvAysivLpp2PAHgvzwyY9ISojj3746M+K7kRljzJHskPdJVNW7VfWLwIXAx8B1wGoReVxEvikiY2Id5FDwn69v5uOKen618ETGZacOdjjGGDMgIm6TUNVG4DnvgYhMxzVg/wk36N+wVbqtht+8uYWvnFTERTPGDXY4xhgzYCK+47qIPCMiF4pIHICqblDVf1fVYZ0gGtv8/OipNRSOSuUXl9/uA5oAABOkSURBVE4f7HCMMWZARZwkgN/hhgffLCJ3i8hxMYppSPnVkk3srG3lP742y8ZbMsaMOBEnCVV9TVW/DpwEbANeFZH3RORaERm2R8+3P9vLghPHUTLp0PdTNsaY4SaakgQikgf8I/Ad4CNcr+uTgFf7PbIhorbFx1gbg8kYM0JF05nuWeA43B3qLlHVXd6iv4jIkXXP0Ai1+QO0+ALkpicNdijGGDMoohmW4zeq+kZPC8KN+XGkq2tx91nKSRu2tWnGGNOraKqbponI/iFORWSUiHw/BjENGbUtPgBy06wkYYwZmaJJEt9V1brOCVWtBb7b/yENHbXNLknkWJIwxoxQ0SSJOBHZPxaFiMQDw/roWetVN41Kt+omY8zIFE2bxCvAUyLyIO4+1dcDS2MS1RBRY9VNxpgRLpok8RPge8D/AAQ3MuzDsQhqqKiz6iZjzAgXzdhNQVyv69/FLpyhpbbFT0ZyAkkJUXUnMcaYYSOafhJTgP8DTAf29y5T1ckxiGtIqG3x2eWvxpgRLZpT5EdwpYgO4Bzc6K//FYughoraFp91pDPGjGjRJIlUVX0dEFXdrqq/AL54qI1EZL6IfCoiW0Tkth6W3yoia7zHOhEJiEiuiEwQkTdFZKOIrBeRm6OItV/UNvusPcIYM6JFkyTavGHCN4vIjSKyEBjd2wbeZbIP4O47MR24yrsPxX6qeo+qzlLVWcDtwHJVrcGVWH6sqtOAucAN3beNtdoWP6OsuskYM4JFkyR+CKQBNwEnA9cA3zrENnOALapapqo+4Engsl7Wvwp4AkBVd6nqau95I7ARKIwi3j6rbfYxykoSxpgRLKIk4ZUIvqaqTapaoarXqupXVPWDQ2xaCJSHTFcQ5kAvImnAfOCZHpZNAmYDH/awbJGIlIpI6d69eyPZnYj4A0Ea2zssSRhjRrSIkoSqBoCTQ3tcR6in9TXMupcA73pVTV0vIJKBSxw/VNWGHmJ7SFVLVLWkoKAgyvDC6xzcL9d6WxtjRrBoOtN9BDwvIv8NNHfOVNVne9mmApgQMl0EVIZZ90q8qqZO3s2MngEeO8T79LvOwf2s4doYM5JFkyRygWoOvKJJgd4O3iuBKSJSDOzEJYKru68kItnAWbh2js55AvwB2Kiq90YRZ7/oHNzPLoE1xoxk0fS4vjbaF1fVDhG5ETfuUzywWFXXi8j13vIHvVUXAstUtTlk83nAN4C1IrLGm/dTVV0SbRyHo6skYdVNxpiRK5oe14/QQ3uCql7X23beQX1Jt3kPdpt+FHi027x36LlNY0DsHwHWqpuMMSNYNNVNfwt5noI7+w/XvnDEq/GqmyxJGGNGsmiqmw64NFVEngBe6/eIhoi6Fh8piXGkJsUPdijGGDNo+jK86RRgYn8FMtTUtvjtPhLGmBEvmjaJRg5sk9iNu8fEsGTjNhljTHTVTZmxDGSosRFgjTEmiuomEVno9WfonM4RkctjE9bgq23x2+WvxpgRL5o2iTtUtb5zQlXrgDv6P6ShobbFBvczxphokkRP60ZzCe0RIxBU6lv9jLLqJmPMCBdNkigVkXtF5GgRmSwi/wGsilVgg6m+1Y8qdi8JY8yIF02S+AHgA/4CPAW0AjfEIqjB1jkkhzVcG2NGumiubmoGDrr96HDUObifXQJrjBnporm66VURyQmZHiUir8QmrMHVOW6TdaYzxox00VQ35XtXNAGgqrUc4h7XR6qukoS1SRhjRrZokkRQRPYPw+HdUjTcXeaOaJ1tEnZ1kzFmpIvmEtZ/Bt4RkeXe9JnAov4PafDVtPhIio8j3Qb3M8aMcNE0XC8VkRJcYlgDPI+7wmnYqWt2va2jv6W3McYML9EM8Pcd4GbcfarXAHOB9znwdqbDgo3bZIwxTjRtEjcDXwC2q+o5wGxgb0yiGmS1LT5rtDbGGKJLEm2q2gYgIsmqugmYGpuwBldti99KEsYYQ3RJosLrJ/FX4FUReZ4Ibl8qIvNF5FMR2SIiB3XGE5FbRWSN91gnIgERyY1k21ixe0kYY4wTTcP1Qu/pL0TkTSAbWNrbNiISDzwAnAdUACtF5AVV3RDyuvcA93jrXwL8SFVrItk2FoJBpa7Vb+M2GWMMhzmKq6ouP/RaAMwBtqhqGYCIPAlcBoQ70F8FPHGY2/aLxrYOAkG1YcKNMYa+3eM6EoVAech0hTfvICKSBswHnolmWxFZJCKlIlK6d2/f29H3d6SzJGGMMTFPEj11NAjXS/sS4F1VrYlmW1V9SFVLVLWkoKDgMMPsYiPAGmNMl1gniQpgQsh0EeEbu6+kq6op2m37TWeSsEtgjTEm9kliJTBFRIpFJAmXCF7ovpJ37+yzcL24o9q2v9U2eyPAWknCGGNie/tRVe0QkRuBV4B4YLGqrheR673lD3qrLgSWefes6HXbWMYLoSUJSxLGGBPze1Sr6hJgSbd5D3abfhR4NJJtY622xUd8nJCVMixv322MMVGJdXXTEaem2fWRsMH9jDHGksRB6lqst7UxxnSyJNFNbYvPbltqjDEeSxLd1Hr3kjDGGGNJ4iC1LT7rbW2MMR67hCeEqrokYX0kjBlR/H4/FRUVtLW1DXYoMZWSkkJRURGJiZHXlliSCNHsC+APqI0Aa8wIU1FRQWZmJpMmTRq2VzaqKtXV1VRUVFBcXBzxdlbdFKK22Rvcz0oSxowobW1t5OXlDdsEASAi5OXlRV1asiQRwkaANWbkGs4JotPh7KMliRC1LZ3jNll1kzHGgCWJA3RWN1lnOmPMQKqrq+O3v/1t1NtdeOGF1NXVxSCiLpYkQlh1kzFmMIRLEoFAoNftlixZQk5OTqzCAuzqpgPUNvsQgexUq24yZqS688X1bKhs6NfXnD4+izsuOT7s8ttuu43PP/+cWbNmkZiYSEZGBuPGjWPNmjVs2LCByy+/nPLyctra2rj55ptZtGgRAJMmTaK0tJSmpiYWLFjA6aefznvvvUdhYSHPP/88qampfY7dShIhalv8ZKcmEh83/BuwjDFDx913383RRx/NmjVruOeee1ixYgV33XUXGzZsAGDx4sWsWrWK0tJS7r//fqqrqw96jc2bN3PDDTewfv16cnJyeOaZZw5a53BYSSJEjY3bZMyI19sZ/0CZM2fOAX0Z7r//fp577jkAysvL2bx5M3l5eQdsU1xczKxZswA4+eST2bZtW7/EYkkihBsB1qqajDGDKz09ff/zt956i9dee43333+ftLQ0zj777B77OiQnJ+9/Hh8fT2tra7/EYtVNIWqb/XbbUmPMgMvMzKSxsbHHZfX19YwaNYq0tDQ2bdrEBx98MKCxWUkiRG2Lj+njswY7DGPMCJOXl8e8efM44YQTSE1NZcyYMfuXzZ8/nwcffJAZM2YwdepU5s6dO6CxWZII4UaAteomY8zAe/zxx3ucn5yczMsvv9zjss52h/z8fNatW7d//i233NJvccW8uklE5ovIpyKyRURuC7PO2SKyRkTWi8jykPk/8uatE5EnRCQlVnG2+gK0+YM2bpMxxoSIaZIQkXjgAWABMB24SkSmd1snB/gtcKmqHg981ZtfCNwElKjqCUA8cGWsYrWOdMYYc7BYlyTmAFtUtUxVfcCTwGXd1rkaeFZVdwCoalXIsgQgVUQSgDSgMlaB1jRbkjDGmO5inSQKgfKQ6QpvXqhjgVEi8paIrBKRbwKo6k7g34AdwC6gXlWXdX8DEVkkIqUiUrp3797DDrTOG9zP2iSMMaZLrJNET12Xtdt0AnAycBFwAfAzETlWREbhSh3FwHggXUSuOejFVB9S1RJVLSkoKDjsQDurm+wSWGOM6RLrq5sqgAkh00UcXGVUAexT1WagWUTeBmZ6y7aq6l4AEXkWOA34cywC7UwSNgKsMcZ0iXVJYiUwRUSKRSQJ1/D8Qrd1ngfOEJEEEUkDTgE24qqZ5opImrg7ZZzrzY+J2mZX3WQ9ro0xA+1whwoHuO+++2hpaenniLrENEmoagdwI/AK7gD/lKquF5HrReR6b52NwFLgE2AF8LCqrlPVD4GngdXAWi/Wh2IVa22Lj8yUBBLjrRO6MWZgDeUkEfPOdKq6BFjSbd6D3abvAe7pYds7gDtiGqDHdaSzqiZjRryXb4Pda/v3NceeCAvuDrs4dKjw8847j9GjR/PUU0/R3t7OwoULufPOO2lubuZrX/saFRUVBAIBfvazn7Fnzx4qKys555xzyM/P58033+zfuLEe1/vVNPusI50xZlDcfffdrFu3jjVr1rBs2TKefvppVqxYgapy6aWX8vbbb7N3717Gjx/PSy+9BLgxnbKzs7n33nt58803yc/Pj0lsliQ8dS1+8jIsSRgz4vVyxj8Qli1bxrJly5g9ezYATU1NbN68mTPOOINbbrmFn/zkJ1x88cWcccYZAxKPJQlPbYuPKaMzBjsMY8wIp6rcfvvtfO973zto2apVq1iyZAm33347559/Pj//+c9jHo+10npqm312+asxZlCEDhV+wQUXsHjxYpqamgDYuXMnVVVVVFZWkpaWxjXXXMMtt9zC6tWrD9o2FqwkAbR3BGj2Bay3tTFmUIQOFb5gwQKuvvpqTj31VAAyMjL485//zJYtW7j11luJi4sjMTGR3/3udwAsWrSIBQsWMG7cuJg0XItq9w7QR66SkhItLS2NervGNj+3P7uWhbMLOXfamENvYIwZVjZu3Mi0adMGO4wB0dO+isgqVS3paX0rSQCZKYn85uqTBjsMY4wZcqxNwhhjTFiWJIwxBndV0XB3OPtoScIYM+KlpKRQXV09rBOFqlJdXU1KSnQ3+LQ2CWPMiFdUVERFRQV9uSfNkSAlJYWioqKotrEkYYwZ8RITEykuLh7sMIYkq24yxhgTliUJY4wxYVmSMMYYE9aw6nEtInuB7X14iXxgXz+FcySx/R5ZbL9Hlkj2+yhVLehpwbBKEn0lIqXhuqYPZ7bfI4vt98jS1/226iZjjDFhWZIwxhgTliWJAz002AEMEtvvkcX2e2Tp035bm4QxxpiwrCRhjDEmLEsSxhhjwrIkAYjIfBH5VES2iMhtgx1PLInIYhGpEpF1IfNyReRVEdns/R01mDH2NxGZICJvishGEVkvIjd784f7fqeIyAoR+djb7zu9+cN6vzuJSLyIfCQif/OmR8p+bxORtSKyRkRKvXmHve8jPkmISDzwALAAmA5cJSLTBzeqmHoUmN9t3m3A66o6BXjdmx5OOoAfq+o0YC5wg/c/Hu773Q58UVVnArOA+SIyl+G/351uBjaGTI+U/QY4R1VnhfSPOOx9H/FJApgDbFHVMlX1AU8Clw1yTDGjqm8DNd1mXwb80Xv+R+DyAQ0qxlR1l6qu9p434g4chQz//VZVbfImE72HMsz3G0BEioCLgIdDZg/7/e7FYe+7JQl3sCgPma7w5o0kY1R1F7gDKjB6kOOJGRGZBMwGPmQE7LdX5bIGqAJeVdURsd/AfcA/AcGQeSNhv8GdCCwTkVUissibd9j7bveTAOlhnl0XPAyJSAbwDPBDVW0Q6elfP7yoagCYJSI5wHMicsJgxxRrInIxUKWqq0Tk7MGOZxDMU9VKERkNvCoim/ryYlaScCWHCSHTRUDlIMUyWPaIyDgA72/VIMfT70QkEZcgHlPVZ73Zw36/O6lqHfAWrj1quO/3POBSEdmGqz7+ooj8meG/3wCoaqX3twp4Dlelftj7bkkCVgJTRKRYRJKAK4EXBjmmgfYC8C3v+beA5wcxln4nrsjwB2Cjqt4bsmi473eBV4JARFKBLwGbGOb7raq3q2qRqk7C/Z7fUNVrGOb7DSAi6SKS2fkcOB9YRx/23XpcAyJyIa4OMx5YrKp3DXJIMSMiTwBn44YP3gPcAfwVeAqYCOwAvqqq3Ru3j1gicjrwd2AtXXXUP8W1Swzn/Z6Ba6SMx50QPqWqvxSRPIbxfofyqptuUdWLR8J+i8hkXOkBXHPC46p6V1/23ZKEMcaYsKy6yRhjTFiWJIwxxoRlScIYY0xYliSMMcaEZUnCGGNMWJYkjBlkInJ250ilxgw1liSMMcaEZUnCmAiJyDXe/RnWiMjvvcHzmkTk30VktYi8LiIF3rqzROQDEflERJ7rHL9fRI4Rkde8ezysFpGjvZfPEJGnRWSTiDzm9RJHRO4WkQ3e6/zbIO26GcEsSRgTARGZBvwDbvC0WUAA+DqQDqxW1ZOA5bge7AB/An6iqjNwPb075z8GPODd4+E0YJc3fzbwQ9w9TSYD80QkF1gIHO+9zv+O7V4aczBLEsZE5lzgZGClN/T2ubiDeRD4i7fOn4HTRSQbyFHV5d78PwJnemPqFKrqcwCq2qaqLd46K1S1QlWDwBpgEtAAtAEPi8iXgc51jRkwliSMiYwAf/Tu9jVLVaeq6i96WK+3cW56G5u8PeR5AEhQ1Q7cCJ7P4G4SszTKmI3pM0sSxkTmdeAKb4z+znsGH4X7DV3hrXM18I6q1gO1InKGN/8bwHJVbQAqRORy7zWSRSQt3Bt697/IVtUluKqoWbHYMWN6YzcdMiYCqrpBRP4Fd8evOMAP3AA0A8eLyCqgHtduAW445ge9JFAGXOvN/wbwexH5pfcaX+3lbTOB50UkBVcK+VE/75Yxh2SjwBrTByLSpKoZgx2HMbFi1U3GGGPCspKEMcaYsKwkYYwxJixLEsYYY8KyJGGMMSYsSxLGGGPCsiRhjDEmrP8PyICao3rDEHEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], label = 'train')\n",
    "plt.plot(history.history['val_accuracy'], label = 'test')\n",
    "plt.legend()\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy/val_accuracy\")\n",
    "plt.savefig(\"11.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20,  7,  0, ...,  0,  0,  0], dtype=int64)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted = classifier.predict(X_test)\n",
    "y_predicted = np.argmax(y_predicted, axis = 1)\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.argmax(y_test, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "467430"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sum = y_test.sum()*15\n",
    "test_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "497295"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_sum = y_predicted.sum()*15\n",
    "predicted_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Percentage in predicted values is : 6.389191964572236 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Error Percentage in predicted values is : {} %\".format(np.absolute((predicted_sum - test_sum)/test_sum)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0, 16, ...,  0, 10, 20], dtype=int64)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_predicted = classifier.predict(X_train)\n",
    "y_train_predicted = np.argmax(y_train_predicted, axis = 1)\n",
    "y_train_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.argmax(y_train, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7052414118852062"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_train, y_train_predicted, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0484797297297297"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_train, y_train_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7511824324324324"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, y_train_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7804334542778533"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_predicted, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.922292780748663"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8096590909090909"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search CV to tune parameters in 30-minutes time-lag model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-6)</th>\n",
       "      <th>var2(t-6)</th>\n",
       "      <th>var3(t-6)</th>\n",
       "      <th>var4(t-6)</th>\n",
       "      <th>var5(t-6)</th>\n",
       "      <th>var6(t-6)</th>\n",
       "      <th>var7(t-6)</th>\n",
       "      <th>var1(t-5)</th>\n",
       "      <th>var2(t-5)</th>\n",
       "      <th>var3(t-5)</th>\n",
       "      <th>...</th>\n",
       "      <th>var5(t-1)</th>\n",
       "      <th>var6(t-1)</th>\n",
       "      <th>var7(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "      <th>var2(t)</th>\n",
       "      <th>var3(t)</th>\n",
       "      <th>var4(t)</th>\n",
       "      <th>var5(t)</th>\n",
       "      <th>var6(t)</th>\n",
       "      <th>var7(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.632689</td>\n",
       "      <td>1.422976</td>\n",
       "      <td>1.387394</td>\n",
       "      <td>2.632689</td>\n",
       "      <td>1.422976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.225278</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.424799</td>\n",
       "      <td>-0.225278</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>1.387394</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.346315</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225278</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.917909</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.424799</td>\n",
       "      <td>0.917909</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.346315</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>1.424799</td>\n",
       "      <td>0.346315</td>\n",
       "      <td>1.930176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>...</td>\n",
       "      <td>0.917909</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.462204</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.424799</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.368465</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>...</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.462204</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.368465</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.424799</td>\n",
       "      <td>-1.368465</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.796872</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>...</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.917909</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>1.462204</td>\n",
       "      <td>0.917909</td>\n",
       "      <td>2.183776</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29671</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>3.238960</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>...</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.295068</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29672</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>3.295068</td>\n",
       "      <td>3.204282</td>\n",
       "      <td>-0.098625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.632689</td>\n",
       "      <td>-0.605825</td>\n",
       "      <td>...</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.388582</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29673</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.632689</td>\n",
       "      <td>-0.605825</td>\n",
       "      <td>3.295068</td>\n",
       "      <td>2.632689</td>\n",
       "      <td>-0.605825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.632689</td>\n",
       "      <td>-0.605825</td>\n",
       "      <td>...</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.388582</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29674</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.632689</td>\n",
       "      <td>-0.605825</td>\n",
       "      <td>3.295068</td>\n",
       "      <td>2.632689</td>\n",
       "      <td>-0.605825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.605825</td>\n",
       "      <td>...</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.388582</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29675</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.605825</td>\n",
       "      <td>3.295068</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.605825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.061095</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>...</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>3.388582</td>\n",
       "      <td>1.489502</td>\n",
       "      <td>-0.859425</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29670 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       var1(t-6)  var2(t-6)  var3(t-6)  var4(t-6)  var5(t-6)  var6(t-6)  \\\n",
       "6            0.0   2.632689   1.422976   1.387394   2.632689   1.422976   \n",
       "7            0.0   1.489502   1.930176   1.387394   1.489502   1.930176   \n",
       "8            0.0   0.346315   1.930176   1.424799   0.346315   1.930176   \n",
       "9            0.0  -0.796872   2.183776   1.424799  -0.796872   2.183776   \n",
       "10           0.0  -1.368465   2.183776   1.424799  -1.368465   2.183776   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "29671        0.0   3.204282  -0.098625   3.238960   3.204282  -0.098625   \n",
       "29672        0.0   3.204282  -0.098625   3.295068   3.204282  -0.098625   \n",
       "29673        0.0   2.632689  -0.605825   3.295068   2.632689  -0.605825   \n",
       "29674        0.0   2.632689  -0.605825   3.295068   2.632689  -0.605825   \n",
       "29675        0.0   2.061095  -0.605825   3.295068   2.061095  -0.605825   \n",
       "\n",
       "       var7(t-6)  var1(t-5)  var2(t-5)  var3(t-5)  ...  var5(t-1)  var6(t-1)  \\\n",
       "6            0.0        0.0   1.489502   1.930176  ...  -0.796872   2.183776   \n",
       "7            0.0        0.0   0.346315   1.930176  ...  -0.225278   2.183776   \n",
       "8            0.0        0.0  -0.796872   2.183776  ...   0.917909   2.183776   \n",
       "9            9.0        0.0  -1.368465   2.183776  ...   1.489502   2.183776   \n",
       "10          20.0        0.0  -0.796872   2.183776  ...   1.489502   2.183776   \n",
       "...          ...        ...        ...        ...  ...        ...        ...   \n",
       "29671        0.0        0.0   3.204282  -0.098625  ...   2.061095  -0.859425   \n",
       "29672        0.0        0.0   2.632689  -0.605825  ...   2.061095  -0.859425   \n",
       "29673        0.0        0.0   2.632689  -0.605825  ...   1.489502  -0.859425   \n",
       "29674        0.0        0.0   2.061095  -0.605825  ...   1.489502  -0.859425   \n",
       "29675        0.0        0.0   2.061095  -0.859425  ...   1.489502  -0.859425   \n",
       "\n",
       "       var7(t-1)  var1(t)   var2(t)   var3(t)   var4(t)   var5(t)   var6(t)  \\\n",
       "6           20.0      0.0 -0.225278  2.183776  1.424799 -0.225278  2.183776   \n",
       "7           20.0      0.0  0.917909  2.183776  1.424799  0.917909  2.183776   \n",
       "8            3.0      0.0  1.489502  2.183776  1.462204  1.489502  2.183776   \n",
       "9            0.0      0.0  1.489502  2.183776  1.462204  1.489502  2.183776   \n",
       "10           0.0      0.0  0.917909  2.183776  1.462204  0.917909  2.183776   \n",
       "...          ...      ...       ...       ...       ...       ...       ...   \n",
       "29671        0.0      0.0  2.061095 -0.859425  3.295068  2.061095 -0.859425   \n",
       "29672        0.0      0.0  1.489502 -0.859425  3.388582  1.489502 -0.859425   \n",
       "29673        0.0      0.0  1.489502 -0.859425  3.388582  1.489502 -0.859425   \n",
       "29674        0.0      0.0  1.489502 -0.859425  3.388582  1.489502 -0.859425   \n",
       "29675        0.0      0.0  1.489502 -0.859425  3.388582  1.489502 -0.859425   \n",
       "\n",
       "       var7(t)  \n",
       "6         20.0  \n",
       "7          3.0  \n",
       "8          0.0  \n",
       "9          0.0  \n",
       "10         0.0  \n",
       "...        ...  \n",
       "29671      0.0  \n",
       "29672      0.0  \n",
       "29673      0.0  \n",
       "29674      0.0  \n",
       "29675      0.0  \n",
       "\n",
       "[29670 rows x 49 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reframed = series_to_supervised(scaler_house_data, 6, 1)\n",
    "reframed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_auxHeat = reframed['var7(t)']\n",
    "y_auxHeat = to_categorical(y_auxHeat).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29670, 48)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = reframed.drop(labels = ['var7(t)'], axis = 1).astype(float)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier(optimizer):\n",
    "\n",
    "    classifier = Sequential()\n",
    "\n",
    "    # Adding the input layer and the first hidden layer\n",
    "    classifier.add(Dense(units = 24, kernel_initializer = 'uniform', activation = 'relu', input_dim = 48))\n",
    "\n",
    "    # Adding the second hidden layer\n",
    "    classifier.add(Dense(units = 24, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "    # Adding the output layer\n",
    "    classifier.add(Dense(units = 21, kernel_initializer = 'uniform', activation = 'softmax'))\n",
    "\n",
    "    # Compiling the ANN\n",
    "    classifier.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KerasClassifier(build_fn = build_classifier, batch_size = 10, nb_epoch = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'acc': 'accuracy'}\n",
    "\n",
    "parameters = {'batch_size' : [10, 64,100],\n",
    "              'epochs' : [10, 50],\n",
    "              'optimizer' : ['adam', 'rmsprop']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = scoring,\n",
    "                           refit = False,\n",
    "                           cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2671/2671 [==============================] - 4s 1ms/step - loss: 1.0199 - accuracy: 0.7404\n",
      "Epoch 2/10\n",
      "2671/2671 [==============================] - 3s 1ms/step - loss: 0.8553 - accuracy: 0.7557\n",
      "Epoch 3/10\n",
      "2671/2671 [==============================] - 3s 1ms/step - loss: 0.8237 - accuracy: 0.7561\n",
      "Epoch 4/10\n",
      "2671/2671 [==============================] - 3s 1ms/step - loss: 0.8071 - accuracy: 0.7581\n",
      "Epoch 5/10\n",
      "2671/2671 [==============================] - 3s 1ms/step - loss: 0.7971 - accuracy: 0.7584\n",
      "Epoch 6/10\n",
      "2671/2671 [==============================] - 3s 1ms/step - loss: 0.7909 - accuracy: 0.7594\n",
      "Epoch 7/10\n",
      "2671/2671 [==============================] - 3s 1ms/step - loss: 0.7850 - accuracy: 0.7602\n",
      "Epoch 8/10\n",
      "2671/2671 [==============================] - 3s 1ms/step - loss: 0.7803 - accuracy: 0.7613\n",
      "Epoch 9/10\n",
      "2671/2671 [==============================] - 3s 1ms/step - loss: 0.7770 - accuracy: 0.7599\n",
      "Epoch 10/10\n",
      "2671/2671 [==============================] - 3s 1ms/step - loss: 0.7722 - accuracy: 0.7619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:700: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 88, in __call__\n",
      "    *args, **kwargs)\n",
      "  File \"c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 243, in _score\n",
      "    **self._kwargs)\n",
      "  File \"c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 202, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 93, in _check_targets\n",
      "    \"and {1} targets\".format(type_true, type_pred))\n",
      "ValueError: Classification metrics can't handle a mix of multilabel-indicator and multiclass targets\n",
      "\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2671/2671 [==============================] - 4s 1ms/step - loss: 1.0089 - accuracy: 0.7455\n",
      "Epoch 2/10\n",
      "2671/2671 [==============================] - 3s 1ms/step - loss: 0.8407 - accuracy: 0.7579\n",
      "Epoch 3/10\n",
      "2671/2671 [==============================] - 4s 1ms/step - loss: 0.8130 - accuracy: 0.7603\n",
      "Epoch 4/10\n",
      "2671/2671 [==============================] - 3s 1ms/step - loss: 0.8016 - accuracy: 0.7621\n",
      "Epoch 5/10\n",
      "2671/2671 [==============================] - 3s 1ms/step - loss: 0.7932 - accuracy: 0.7620\n",
      "Epoch 6/10\n",
      "2671/2671 [==============================] - 3s 1ms/step - loss: 0.7846 - accuracy: 0.7630\n",
      "Epoch 7/10\n",
      "2671/2671 [==============================] - 3s 1ms/step - loss: 0.7809 - accuracy: 0.7622\n",
      "Epoch 8/10\n",
      "2671/2671 [==============================] - 3s 1ms/step - loss: 0.7773 - accuracy: 0.7645\n",
      "Epoch 9/10\n",
      "2671/2671 [==============================] - 3s 1ms/step - loss: 0.7719 - accuracy: 0.7647\n",
      "Epoch 10/10\n",
      "2671/2671 [==============================] - 3s 1ms/step - loss: 0.7697 - accuracy: 0.7655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:700: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 88, in __call__\n",
      "    *args, **kwargs)\n",
      "  File \"c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 243, in _score\n",
      "    **self._kwargs)\n",
      "  File \"c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 202, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 93, in _check_targets\n",
      "    \"and {1} targets\".format(type_true, type_pred))\n",
      "ValueError: Classification metrics can't handle a mix of multilabel-indicator and multiclass targets\n",
      "\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2671/2671 [==============================] - 3s 1ms/step - loss: 1.0298 - accuracy: 0.7368\n",
      "Epoch 2/10\n",
      "2671/2671 [==============================] - 3s 1ms/step - loss: 0.8578 - accuracy: 0.7558\n",
      "Epoch 3/10\n",
      "2671/2671 [==============================] - 3s 1ms/step - loss: 0.8285 - accuracy: 0.7556\n",
      "Epoch 4/10\n",
      "2671/2671 [==============================] - 3s 1ms/step - loss: 0.8155 - accuracy: 0.7578\n",
      "Epoch 5/10\n",
      "2671/2671 [==============================] - 3s 1ms/step - loss: 0.8052 - accuracy: 0.7586\n",
      "Epoch 6/10\n",
      "2671/2671 [==============================] - 3s 1ms/step - loss: 0.7960 - accuracy: 0.7594\n",
      "Epoch 7/10\n",
      "2671/2671 [==============================] - 3s 1ms/step - loss: 0.7899 - accuracy: 0.7594\n",
      "Epoch 8/10\n",
      "2671/2671 [==============================] - 4s 2ms/step - loss: 0.7865 - accuracy: 0.7615\n",
      "Epoch 9/10\n",
      "2671/2671 [==============================] - 5s 2ms/step - loss: 0.7803 - accuracy: 0.7614\n",
      "Epoch 10/10\n",
      "2671/2671 [==============================] - 5s 2ms/step - loss: 0.7784 - accuracy: 0.7614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:700: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 88, in __call__\n",
      "    *args, **kwargs)\n",
      "  File \"c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 243, in _score\n",
      "    **self._kwargs)\n",
      "  File \"c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 202, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 93, in _check_targets\n",
      "    \"and {1} targets\".format(type_true, type_pred))\n",
      "ValueError: Classification metrics can't handle a mix of multilabel-indicator and multiclass targets\n",
      "\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2671/2671 [==============================] - 4s 1ms/step - loss: 1.0395 - accuracy: 0.7382\n",
      "Epoch 2/10\n",
      "2671/2671 [==============================] - 3s 1ms/step - loss: 0.8623 - accuracy: 0.7534\n",
      "Epoch 3/10\n",
      "2671/2671 [==============================] - 3s 1ms/step - loss: 0.8306 - accuracy: 0.7554\n",
      "Epoch 4/10\n",
      "2671/2671 [==============================] - 3s 1ms/step - loss: 0.8147 - accuracy: 0.7572\n",
      "Epoch 5/10\n",
      "2671/2671 [==============================] - 3s 1ms/step - loss: 0.8081 - accuracy: 0.7573\n",
      "Epoch 6/10\n",
      "2671/2671 [==============================] - 3s 1ms/step - loss: 0.8011 - accuracy: 0.7577\n",
      "Epoch 7/10\n",
      "2671/2671 [==============================] - 3s 1ms/step - loss: 0.7960 - accuracy: 0.7584\n",
      "Epoch 8/10\n",
      "2671/2671 [==============================] - 4s 1ms/step - loss: 0.7929 - accuracy: 0.7600\n",
      "Epoch 9/10\n",
      "2671/2671 [==============================] - 4s 1ms/step - loss: 0.7871 - accuracy: 0.7576\n",
      "Epoch 10/10\n",
      "2671/2671 [==============================] - 5s 2ms/step - loss: 0.7830 - accuracy: 0.7599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:700: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 88, in __call__\n",
      "    *args, **kwargs)\n",
      "  File \"c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 243, in _score\n",
      "    **self._kwargs)\n",
      "  File \"c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 202, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"c:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 93, in _check_targets\n",
      "    \"and {1} targets\".format(type_true, type_pred))\n",
      "ValueError: Classification metrics can't handle a mix of multilabel-indicator and multiclass targets\n",
      "\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2671/2671 [==============================] - 5s 2ms/step - loss: 1.0197 - accuracy: 0.7395\n",
      "Epoch 2/10\n",
      "2671/2671 [==============================] - 6s 2ms/step - loss: 0.8592 - accuracy: 0.7532\n",
      "Epoch 3/10\n",
      "2671/2671 [==============================] - 5s 2ms/step - loss: 0.8315 - accuracy: 0.7555\n",
      "Epoch 4/10\n",
      "2671/2671 [==============================] - 4s 1ms/step - loss: 0.8183 - accuracy: 0.7562\n",
      "Epoch 5/10\n",
      "2671/2671 [==============================] - 5s 2ms/step - loss: 0.8082 - accuracy: 0.7575\n",
      "Epoch 6/10\n",
      "2671/2671 [==============================] - 3s 1ms/step - loss: 0.8018 - accuracy: 0.7589\n",
      "Epoch 7/10\n",
      "2671/2671 [==============================] - 4s 1ms/step - loss: 0.7958 - accuracy: 0.7583\n",
      "Epoch 8/10\n",
      "2671/2671 [==============================] - 3s 1ms/step - loss: 0.7920 - accuracy: 0.7591\n",
      "Epoch 9/10\n",
      "2671/2671 [==============================] - 4s 1ms/step - loss: 0.7875 - accuracy: 0.7586\n",
      "Epoch 10/10\n",
      "  31/2671 [..............................] - ETA: 4s - loss: 0.7426 - accuracy: 0.7742"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-606c2280d5fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_auxHeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1295\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1296\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    807\u001b[0m                                    (split_idx, (train, test)) in product(\n\u001b[0;32m    808\u001b[0m                                    \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 809\u001b[1;33m                                    enumerate(cv.split(X, y, groups))))\n\u001b[0m\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    833\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 835\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    596\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    599\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    218\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Invalid shape for y: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 3024\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1961\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    597\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\hongyliu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid_search.fit(X, y_auxHeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_results = pd.DataFrame(grid_search.cv_results_, columns = list(grid_search.cv_results_.keys()))\n",
    "grid_search_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier(ac_func):\n",
    "\n",
    "    classifier = Sequential()\n",
    "\n",
    "    # Adding the input layer and the first hidden layer\n",
    "    classifier.add(Dense(units = 24, kernel_initializer = 'uniform', activation = ac_func, input_dim = 48))\n",
    "\n",
    "    # Adding the second hidden layer\n",
    "    classifier.add(Dense(units = 24, kernel_initializer = 'uniform', activation = ac_func))\n",
    "\n",
    "    # Adding the output layer\n",
    "    classifier.add(Dense(units = 21, kernel_initializer = 'uniform', activation = 'softmax'))\n",
    "\n",
    "    # Compiling the ANN\n",
    "    classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_funcs = ['relu', 'sigmoid', 'tanh']\n",
    "ac_funcs_score_time = []\n",
    "ac_funcs_acc = []\n",
    "ac_funcs_f1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype(float)\n",
    "y_auxHeat = y_auxHeat.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KerasClassifier(build_fn = build_classifier,ac_func =ac_funcs[0],  batch_size = 64, nb_epoch = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(estimator = classifier, X = X, y = y_auxHeat, cv = 10)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_funcs_score_time.append(scores['score_time'])\n",
    "ac_funcs_acc.append(scores['test_score'])\n",
    "#ac_funcs_f1.append(scores['test_f1_weighted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape,y_auxHeat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KerasClassifier(build_fn = build_classifier,ac_func = ac_funcs[1], batch_size = 64, nb_epoch = 50)\n",
    "\n",
    "\n",
    "scores = cross_validate(estimator = classifier, X = X, y = y_auxHeat, cv = 10)\n",
    "ac_funcs_score_time.append(scores['score_time'])\n",
    "ac_funcs_acc.append(scores['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KerasClassifier(build_fn = build_classifier, batch_size = 64, nb_epoch = 50)\n",
    "\n",
    "scoring = {'acc': 'accuracy',\n",
    "           }\n",
    "\n",
    "scores = cross_validate(estimator = classifier, X = X, y = y_auxHeat, cv = 10)\n",
    "ac_funcs_score_time.append(scores['score_time'])\n",
    "ac_funcs_acc.append(scores['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_funcs_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df = pd.DataFrame(ac_funcs_acc)\n",
    "acc_df = acc_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df = acc_df.rename(columns = {0:'ReLu', 1:'Sigmoid', 2:'Tanh'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 10))\n",
    "ax = sns.boxplot(data = acc_df)\n",
    "ax.set(ylabel = \"Accuracy\", xlabel = \"Activation Function Used\")\n",
    "plt.savefig(\"12.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df = pd.DataFrame(ac_funcs_score_time)\n",
    "time_df = time_df.T\n",
    "\n",
    "time_df = time_df.rename(columns = {0:'ReLu', 1:'Sigmoid', 2:'Tanh'})\n",
    "\n",
    "plt.figure(figsize = (12, 10))\n",
    "ax = sns.boxplot(data = time_df)\n",
    "ax.set(ylabel = \"Time Taken for Prediction\", xlabel = \"Activation Function Used\")\n",
    "plt.savefig(\"14.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
